{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from pprint import pprint\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "num_evals = 5\n",
    "evals = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HIT Files: 261\n",
      "# Passed Test: 82 / 179 = 45.81 %\n"
     ]
    }
   ],
   "source": [
    "task_dir = '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_'\n",
    "\n",
    "### RACE: Unfiltered Workers\n",
    "# prompt_type, task_id = 'question', '1553982706'  # Q-only\n",
    "# prompt_type, task_id = 'context_question', 1553790696  # TFIDF\n",
    "# prompt_type, task_id = 'context_question', 1553901953  # FastText\n",
    "### RACE: Filtered Workers\n",
    "# prompt_type, task_id = 'question', '1554052233'  # Q-only\n",
    "# prompt_type, task_id = 'quote and question', 1554006689  # TFIDF-QA\n",
    "# prompt_type, task_id = 'quote and question', 1554130485  # TFIDF-A\n",
    "# prompt_type, task_id = 'quote and question', 1554069931  # Cross-Ranker\n",
    "# prompt_type, task_id = 'quote and question', 1554072277  # Predicting Search\n",
    "# prompt_type, task_id = 'quote and question', 1554132868  # Predicting ΔP(A)\n",
    "\n",
    "### RACE Test\n",
    "## Persuading\n",
    "# prompt_type, task_id, name = 'quote and question', 1556671432, 'TFIDF-QA'\n",
    "# prompt_type, task_id, name = 'quote and question', 1556725767, 'TFIDF-A'\n",
    "# prompt_type, task_id, name = 'quote and question', 1556739336, 'BoW-A'\n",
    "# prompt_type, task_id, name = 'quote and question', 1556756789, 'Pred ΔP(A)'  # (race.m=sl-sents.i.best.e)\n",
    "# prompt_type, task_id, name = 'quote and question', 1556809031, 'Pred P(A)'\n",
    "# prompt_type, task_id, name = 'quote and question', 1556832343, 'Pred Search (Almost complete)'\n",
    "# prompt_type, task_id, name = 'quote and question', 1556892630, 'Pred Search'\n",
    "## Acc on Summary\n",
    "# prompt_type, task_id, name = 'passage and question', 1555823963, 'Full Passage'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1555946909, 'BoW-A'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1555952058, 'Cross-Ranker Best Epoch'  # (6-10 sentence incorrectly placed at end)\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556939750, 'Pred ΔP(A) (lower pay)'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556977072, 'Pred P(A)'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556987177, 'Pred Search'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556999857, 'Pred ΔP(A)'\n",
    "# dataset = 'race'\n",
    "\n",
    "### DREAM\n",
    "## Persuading\n",
    "# prompt_type, task_id, name = 'question', 1554582693, 'Q-only'\n",
    "# prompt_type, task_id, name = 'quote and question', 1554596686, 'TFIDF-QA'\n",
    "# prompt_type, task_id, name = 'quote and question', 1554587404, 'TFIDF-A'\n",
    "# prompt_type, task_id, name = 'quote and question', 1554662280, 'BoW-A'\n",
    "# prompt_type, task_id, name = 'quote and question', 1556670413, 'Bi-Ranker'\n",
    "# prompt_type, task_id, name = 'quote and question', 1554675304, 'Cross-Ranker'\n",
    "# prompt_type, task_id, name = 'quote and question', 1554685131, 'Pred Search'\n",
    "# prompt_type, task_id, name = 'quote and question', 1554692472, 'Pred P(A)'\n",
    "# prompt_type, task_id, name = 'quote and question', 1554729998, 'Pred ΔP(A)'\n",
    "prompt_type, task_id, name = 'quote and question', 1555333992, 'Pred Search (ToM)'\n",
    "## Acc on Summary\n",
    "# prompt_type, task_id, name = 'question, answers, and quotes', 1555707929, 'TFIDF-A'  # 64.21%: (Less filter / no feedback)\n",
    "# prompt_type, task_id, name = 'question, answers, and quotes', 1555722489, 'Cross-Ranker'  # 65.38%: (Less filter / no feedback)\n",
    "# prompt_type, task_id, name = 'question and quotes', 1555789302, 'Pred Search'  # 75.17% (4/5 filter)\n",
    "# prompt_type, task_id, name = 'question and quotes', 1555812443, 'Pred Search'  # 79.32% Actually: quotes and question (4/5 filter)\n",
    "# prompt_type, task_id, name = 'passage and question', 1555804551, 'Full Passage'  # 92.97%\n",
    "# prompt_type, task_id, name = 'quotes and question', 1555823257, 'FastText'  # (5/5 filter) (77.33%)\n",
    "# prompt_type, task_id, name = 'quotes and question', 1555946647, 'RACE Cross-Ranker'  # (4 sentences incorrectly placed at end) (80.84%)\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556727396, 'Cross-Ranker'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556740293, 'Bi-Ranker'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556757043, 'TFIDF-A'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556811067, 'TFIDF-QA'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556832115, 'Predicting Search'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556892896, 'Predicting P(A)'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556938429, 'Predicting ΔP(A)'\n",
    "dataset = 'dream'\n",
    "\n",
    "\n",
    "split = None  # 'middle', 'high', None\n",
    "\n",
    "\n",
    "# Set useful variables\n",
    "task_dir += str(task_id)\n",
    "if dataset != 'race':\n",
    "    split = None\n",
    "num_options = 3 if dataset == 'dream' else 4\n",
    "options = ['A', 'B', 'C', 'D'][:num_options]\n",
    "debate_mode_to_option = {'Ⅰ': 'A', 'Ⅱ': 'B', 'Ⅲ': 'C', 'Ⅳ': 'D', 'ⅰ': 'A', 'ⅱ': 'B', 'ⅲ': 'C', 'ⅳ': 'D', None: None}\n",
    "question_type_labels = ['a', 'c', 'l', 'm', 's'] if dataset == 'dream' else ['a', 'b', 'c', 'd', 'e']\n",
    "\n",
    "# if (dataset == 'dream') and (prompt_type == 'quote and question'):\n",
    "#     question_type_labels = []\n",
    "\n",
    "# Read HIT data\n",
    "print('# HIT Files:', len(os.listdir(task_dir)))\n",
    "hit_results = []\n",
    "num_passed_test = 0\n",
    "for hit_dir in os.listdir(task_dir):\n",
    "    if hit_dir.startswith('o_'):\n",
    "        continue\n",
    "    num_passed_test += 1\n",
    "    with open(os.path.join(task_dir, hit_dir, 'custom/data.json'), 'r') as file:\n",
    "        hit_results.append(json.load(file))\n",
    "        file.close()\n",
    "if len(os.listdir(task_dir)) != num_passed_test:\n",
    "    num_total_tested = len(os.listdir(task_dir)) - num_passed_test\n",
    "    print('# Passed Test:', num_passed_test, '/', num_total_tested, '=', round((100. * num_passed_test) / num_total_tested, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Time: 174.2 | Acc: 50 | Max Freq: 50.0 | Rate: 10 | Feedback: Nothing | Quote Rating: 8 | Quote Desc: Interesting\n",
      "| Time: 315.0 | Acc: 35 | Max Freq: 50.0 | Rate: 10 | Feedback: I don't know, I enjoyed it the way it was.  I thought it was easy to understand the directions and fun to do. | Quote Rating: 8 | Quote Desc: Some of them were much more helpful than others,  some didn't help at all.\n",
      "| Time: 358.9 | Acc: 55 | Max Freq: 55.0 | Rate: 10 | Feedback: Make more of the quotes relevant, or perhaps longer interchange/conversation. | Quote Rating: 8 | Quote Desc: Mostly useful, some not helpful at all nor relevant to the question.\n",
      "| Time: 220.9 | Acc: 45 | Max Freq: 55.0 | Rate: 7 | Feedback: Add more details into the passage quotes | Quote Rating: 6 | Quote Desc: Some of them indicated the correct answer, some of them were too vague.\n",
      "| Time: 370.4 | Acc: 70 | Max Freq: 40.0 | Rate: 9 | Feedback: I think it's fine the way it is. | Quote Rating: 8 | Quote Desc: Brief and usually helpful.\n",
      "| Time: 449.0 | Acc: 60 | Max Freq: 40.0 | Rate: 9 | Feedback: Maybe giving us a way to review / resubmit our answers.  I submitted a few and had considered going back to review them but when I saw I couldn't change an answer I just carried on. | Quote Rating: 7 | Quote Desc: Some were helpful but several also seemed unrelated. \n",
      "| Time: 198.8 | Acc: 35 | Max Freq: 40.0 | Rate: 7 | Feedback: I'm not sure; everything seemed fine to me. | Quote Rating: 5 | Quote Desc: Sometimes they all but answered the question for me, other times they provided a strong hint towards the correct answer, but some times they were (out-of-context) so unrelated to the question that I was essentially guessing at random,\n",
      "| Time: 146.3 | Acc: 55 | Max Freq: 55.0 | Rate: 10 | Feedback: Format | Quote Rating: 4 | Quote Desc: Ambiguous \n",
      "| Time: 170.2 | Acc: 35 | Max Freq: 45.0 | Rate: 6 | Feedback: no ideas. | Quote Rating: 6 | Quote Desc: random\n",
      "| Time: 173.7 | Acc: 55 | Max Freq: 40.0 | Rate: 10 | Feedback: No improvements to suggest. | Quote Rating: 9 | Quote Desc: I think that they were clear and helped me to answer the questions with limited passages.\n",
      "| Time: 204.1 | Acc: 50 | Max Freq: 40.0 | Rate: 9 | Feedback: It was interesting as is. | Quote Rating: 5 | Quote Desc: Some are very vague and cryptic.\n",
      "| Time: 318.6 | Acc: 45 | Max Freq: 40.0 | Rate: 10 | Feedback: no improvements needed | Quote Rating: 8 | Quote Desc: Short, mostly helpful, sometimes too vague.\n",
      "| Time: 313.1 | Acc: 55 | Max Freq: 55.0 | Rate: 10 | Feedback: I can't say how I think it could be improved. | Quote Rating: 7 | Quote Desc: Mostly the provided passages gave a general idea of the topic and how to answer the questions. A few were vague, and a few had answer options that could have worked multiple ways.\n",
      "| Time: 454.8 | Acc: 35 | Max Freq: 45.0 | Rate: 10 | Feedback: Give some more clues for answers | Quote Rating: 3 | Quote Desc: Very hard to guess the answers and not much meaning\n",
      "| Time: 566.4 | Acc: 25 | Max Freq: 50.0 | Rate: 9 | Feedback: I improve the more book red and developing my knowledge. | Quote Rating: 10 | Quote Desc: There are good for training.\n",
      "| Time: 415.3 | Acc: 60 | Max Freq: 45.0 | Rate: 6 | Feedback: more specific passages | Quote Rating: 5 | Quote Desc: vague\n",
      "| Time: 190.8 | Acc: 40 | Max Freq: 45.0 | Rate: 10 | Feedback: Maybe provide a bit more information in the quotes. | Quote Rating: 5 | Quote Desc: They were short and sometimes did not provide enough information to answer the question.\n",
      "| Time: 230.8 | Acc: 55 | Max Freq: 50.0 | Rate: 9 | Feedback: Good, thanks! | Quote Rating: 3 | Quote Desc: Very brief\n",
      "| Time: 496.9 | Acc: 70 | Max Freq: 70.0 | Rate: 9 | Feedback: I think it's good. I'd like to know what I got wrong, however. | Quote Rating: 9 | Quote Desc: Vague to some extent but coupled with the question they seemed to line up in my mind, mostly.\n",
      "| Time: 323.8 | Acc: 75 | Max Freq: 35.0 | Rate: 10 | Feedback: I think it's fine just the way it is. | Quote Rating: 10 | Quote Desc: Logically fairly easy to put into context\n",
      "| Time: 363.8 | Acc: 45 | Max Freq: 35.0 | Rate: 10 | Feedback: This task is perfect. Thank you for having it. | Quote Rating: 7 | Quote Desc: Adequate\n",
      "A2L9G4YBBC7Z99 3HOSI13XH03PZAO0AKS6GWUVU33DD8 | reject_reasons: ['median_duration = 2316'] | block_reasons: [] | bonus_reasons: []\n",
      "| Time: 45.8 | Acc: 35 | Max Freq: 40.0 | Rate: 9 | Feedback: analysis | Quote Rating: 8 | Quote Desc: nice\n",
      "| Time: 301.3 | Acc: 60 | Max Freq: 45.0 | Rate: 8 | Feedback: no | Quote Rating: 10 | Quote Desc: conversations\n",
      "| Time: 343.1 | Acc: 55 | Max Freq: 40.0 | Rate: 10 | Feedback: Perhaps, a chance to get a clue on some of the harder questions. | Quote Rating: 8 | Quote Desc: Some very helpful, some not so much.\n",
      "| Time: 179.8 | Acc: 50 | Max Freq: 50.0 | Rate: 5 | Feedback: nothing I can think of. | Quote Rating: 8 | Quote Desc: good\n",
      "| Time: 433.1 | Acc: 60 | Max Freq: 35.0 | Rate: 10 | Feedback: I don't know.  | Quote Rating: 4 | Quote Desc: Some of them made sense,  some seemed like trick questions and some just made no sense. \n",
      "| Time: 251.8 | Acc: 50 | Max Freq: 45.0 | Rate: 5 | Feedback: have better quotes with the questions | Quote Rating: 4 | Quote Desc: difficult to decipher\n",
      "| Time: 206.6 | Acc: 70 | Max Freq: 35.0 | Rate: 10 | Feedback: You can't, it's fine as is. | Quote Rating: 6 | Quote Desc: Strange, vague, sometimes helpful.\n",
      "| Time: 359.8 | Acc: 45 | Max Freq: 45.0 | Rate: 6 | Feedback: I don't know how you can improve. | Quote Rating: 8 | Quote Desc: They were vague.\n",
      "| Time: 138.4 | Acc: 50 | Max Freq: 40.0 | Rate: 9 | Feedback: Longer passages | Quote Rating: 8 | Quote Desc: Brief and non specific\n",
      "| Time: 294.4 | Acc: 55 | Max Freq: 55.0 | Rate: 8 | Feedback: give more clues in the quote | Quote Rating: 7 | Quote Desc: Mostly useful\n",
      "| Time: 268.1 | Acc: 35 | Max Freq: 40.0 | Rate: 6 | Feedback: provide more information | Quote Rating: 6 | Quote Desc: not enough information to make a informed decision more than half the time\n",
      "| Time: 191.1 | Acc: 45 | Max Freq: 45.0 | Rate: 8 | Feedback: Not sure | Quote Rating: 8 | Quote Desc: At times very direct and other times felt like a quick riddle that we had to solve\n",
      "| Time: 302.5 | Acc: 45 | Max Freq: 40.0 | Rate: 9 | Feedback: I do not know | Quote Rating: 8 | Quote Desc: Curious\n",
      "| Time: 185.8 | Acc: 65 | Max Freq: 40.0 | Rate: 9 | Feedback: make it a little shorter | Quote Rating: 7 | Quote Desc: a good starting point\n",
      "| Time: 419.3 | Acc: 60 | Max Freq: 45.0 | Rate: 7 | Feedback: I can not say. I am not sure if the task is functioning as designed | Quote Rating: 5 | Quote Desc: The passage quotes did not makes sense at times\n",
      "| Time: 344.9 | Acc: 55 | Max Freq: 60.0 | Rate: 10 | Feedback: it's fine. | Quote Rating: 5 | Quote Desc: obtuse\n",
      "| Time: 494.4 | Acc: 65 | Max Freq: 40.0 | Rate: 8 | Feedback: I think it's at a good spot. | Quote Rating: 7 | Quote Desc: It was fine as is.\n",
      "| Time: 1012.2 | Acc: 35 | Max Freq: 45.0 | Rate: 10 | Feedback: well knowledgeable | Quote Rating: 10 | Quote Desc: knowledgeable\n",
      "| Time: 165.3 | Acc: 50 | Max Freq: 60.0 | Rate: 10 | Feedback: No recommendations | Quote Rating: 8 | Quote Desc: Brief, sometimes confusing, but mostly fairly easy to understand. Definitely some ambiguous questions.\n",
      "| Time: 303.1 | Acc: 50 | Max Freq: 55.0 | Rate: 10 | Feedback: It's perfect how it is. | Quote Rating: 10 | Quote Desc: They gave good hints as to the context of what was being talked about.\n",
      "| Time: 240.0 | Acc: 55 | Max Freq: 45.0 | Rate: 10 | Feedback: I can't think of anything. I was fine. I guess I don't know if this whole chat system is necessary. It could probably work fine as just a normal multiple choice survey. | Quote Rating: 7 | Quote Desc: Some of them were very useful and you could basically get the exact answer from it, word for word. Some were much more vague and I would have to make some sort of an assumption based on common knowledge.\n",
      "| Time: 115.2 | Acc: 45 | Max Freq: 40.0 | Rate: 8 | Feedback: Not sure, if the purpose is to be hard to guess, then it's good, if you want better results you should have more detail. | Quote Rating: 5 | Quote Desc: A little vague in a lot of places, not a lot of information in at least half of them.\n",
      "| Time: 461.0 | Acc: 45 | Max Freq: 40.0 | Rate: 8 | Feedback: I foudn the task fun, clear and concise. | Quote Rating: 7 | Quote Desc: They were helpful for coming up with the most accurate response, they were descriptive.\n",
      "| Time: 261.7 | Acc: 65 | Max Freq: 50.0 | Rate: 8 | Feedback: less passages | Quote Rating: 8 | Quote Desc: some were hard to understand\n",
      "| Time: 305.2 | Acc: 55 | Max Freq: 45.0 | Rate: 8 | Feedback: Nothing. It's fair  | Quote Rating: 6 | Quote Desc: They were interesting \n",
      "| Time: 841.8 | Acc: 70 | Max Freq: 50.0 | Rate: 10 | Feedback: It is fine as is | Quote Rating: 6 | Quote Desc: They are good despite there not being enough information provided.\n",
      "| Time: 244.6 | Acc: 55 | Max Freq: 45.0 | Rate: 8 | Feedback: I'm not sure | Quote Rating: 6 | Quote Desc: Very brief and vague, they lacked context often\n",
      "| Time: 302.7 | Acc: 50 | Max Freq: 50.0 | Rate: 10 | Feedback: It was already good, thanks. | Quote Rating: 6 | Quote Desc: Some of them had grammar mistakes, or were difficult to judge the context of.\n",
      "| Time: 172.4 | Acc: 60 | Max Freq: 40.0 | Rate: 10 | Feedback: No idea. | Quote Rating: 6 | Quote Desc: Mostly vague, sometimes very obvious.\n",
      "| Time: 265.6 | Acc: 65 | Max Freq: 40.0 | Rate: 6 | Feedback: More details | Quote Rating: 5 | Quote Desc: Lacking information for the most part\n",
      "| Time: 417.4 | Acc: 40 | Max Freq: 45.0 | Rate: 7 | Feedback: Make sure they're grammatical | Quote Rating: 4 | Quote Desc: Some of them didn't make much sense \n",
      "| Time: 260.3 | Acc: 40 | Max Freq: 40.0 | Rate: 5 | Feedback: Since the point is seeing what we can figure out from very little information, I would change nothing. | Quote Rating: 2 | Quote Desc: Very general and non specific.\n",
      "| Time: 168.2 | Acc: 70 | Max Freq: 50.0 | Rate: 7 | Feedback: Track correct answers as you go | Quote Rating: 7 | Quote Desc: Some were not useful in figuring out context by not providing enough detail\n",
      "| Time: 334.5 | Acc: 50 | Max Freq: 45.0 | Rate: 10 | Feedback: Better pay. | Quote Rating: 3 | Quote Desc: Really open to interpretation. \n",
      "| Time: 380.2 | Acc: 65 | Max Freq: 50.0 | Rate: 10 | Feedback: Not sure how it can be improved. I found it very smooth and easy to follow. | Quote Rating: 8 | Quote Desc: I would describe them as somewhat descriptive.\n",
      "| Time: 260.8 | Acc: 50 | Max Freq: 35.0 | Rate: 9 | Feedback: Let the passage contain more information | Quote Rating: 4 | Quote Desc: Complex\n",
      "| Time: 276.0 | Acc: 50 | Max Freq: 50.0 | Rate: 7 | Feedback: I think it did it's purpose a lot of the questions where open ended but I feel it was supposed to be that way | Quote Rating: 9 | Quote Desc: It was interesting and helped for the majority of the questions\n",
      "| Time: 320.7 | Acc: 45 | Max Freq: 40.0 | Rate: 10 | Feedback: Sometimes the drop down menu is a little tough to get the right one selected. It like slips and you put in the wrong one. But otherwise it was fun and interesting. | Quote Rating: 7 | Quote Desc: Everyday conversations mostly.\n",
      "| Time: 559.2 | Acc: 55 | Max Freq: 45.0 | Rate: 9 | Feedback: by giving a more detailed passage | Quote Rating: 6 | Quote Desc: not detailed\n",
      "| Time: 347.6 | Acc: 50 | Max Freq: 40.0 | Rate: 10 | Feedback: The task is just fine. | Quote Rating: 7 | Quote Desc: Interesting\n",
      "| Time: 424.5 | Acc: 65 | Max Freq: 40.0 | Rate: 5 | Feedback: i am not sure | Quote Rating: 8 | Quote Desc: some of them didn't have much of a connection to the questions\n",
      "| Time: 611.1 | Acc: 50 | Max Freq: 50.0 | Rate: 10 | Feedback: I didn't do as well as I thought I would. Perhaps getting feedback after each question would be helpful. | Quote Rating: 10 | Quote Desc: Helpful\n",
      "| Time: 298.7 | Acc: 60 | Max Freq: 50.0 | Rate: 10 | Feedback: It was fine the way it is. | Quote Rating: 8 | Quote Desc: Gave minimal information but often helpful.\n",
      "| Time: 244.8 | Acc: 30 | Max Freq: 45.0 | Rate: 10 | Feedback: It is perfect as it is. | Quote Rating: 7 | Quote Desc: Excerpt\n",
      "| Time: 854.9 | Acc: 50 | Max Freq: 50.0 | Rate: 9 | Feedback: Increase the payment | Quote Rating: 7 | Quote Desc: Random and incomplete\n",
      "| Time: 347.1 | Acc: 70 | Max Freq: 40.0 | Rate: 10 | Feedback: nothing to add | Quote Rating: 8 | Quote Desc: interesting\n",
      "| Time: 242.9 | Acc: 60 | Max Freq: 50.0 | Rate: 10 | Feedback: none | Quote Rating: 10 | Quote Desc: They took my mind to a situation where it could happen.\n",
      "| Time: 325.1 | Acc: 50 | Max Freq: 45.0 | Rate: 10 | Feedback: its good | Quote Rating: 6 | Quote Desc: complicated\n",
      "| Time: 164.0 | Acc: 65 | Max Freq: 45.0 | Rate: 7 | Feedback: Have radio buttons instead of drop down boxes | Quote Rating: 6 | Quote Desc: Like they were missing context\n",
      "| Time: 196.2 | Acc: 70 | Max Freq: 40.0 | Rate: 9 | Feedback: Nothing really comes to mind. It's really fun! | Quote Rating: 6 | Quote Desc: Sometimes they seemed relevant and other times they were so minimal or broad that they could have applied to almost any conversation.\n",
      "| Time: 321.8 | Acc: 55 | Max Freq: 40.0 | Rate: 6 | Feedback: I think the task if fine for what is meant for. I am guessing some of the questions were impossible to answer on purpose. | Quote Rating: 4 | Quote Desc: Most of them were too vague and a significant amount of them would allow for two potential answers that could be correct.\n",
      "| Time: 503.2 | Acc: 65 | Max Freq: 35.0 | Rate: 9 | Feedback: No idea | Quote Rating: 8 | Quote Desc: Too abstract\n",
      "| Time: 240.6 | Acc: 50 | Max Freq: 35.0 | Rate: 7 | Feedback: Better pay | Quote Rating: 6 | Quote Desc: Often lacking in enough context to make a reasonable guess.\n",
      "| Time: 225.5 | Acc: 40 | Max Freq: 55.0 | Rate: 7 | Feedback: It's pretty good, I like it | Quote Rating: 4 | Quote Desc: Brief and occasionally incomplete\n",
      "| Time: 271.2 | Acc: 50 | Max Freq: 45.0 | Rate: 10 | Feedback: It is fine. no problems | Quote Rating: 8 | Quote Desc: Some of them gave the answer exactly, whereas some didn't at all and some you needed to infer. \n",
      "| Time: 416.1 | Acc: 45 | Max Freq: 40.0 | Rate: 10 | Feedback: I like it the way it is | Quote Rating: 6 | Quote Desc: out of context\n",
      "| Time: 374.8 | Acc: 65 | Max Freq: 35.0 | Rate: 6 | Feedback: no idea | Quote Rating: 5 | Quote Desc: good\n",
      "| Time: 202.2 | Acc: 65 | Max Freq: 45.0 | Rate: 10 | Feedback: Higher pay | Quote Rating: 8 | Quote Desc: Vague and incomplete.\n",
      "| Time: 292.8 | Acc: 55 | Max Freq: 45.0 | Rate: 6 | Feedback: Make the passages more clear. | Quote Rating: 6 | Quote Desc: Sometimes random, sometimes helpful. Generally unclear.\n",
      "| Time: 168.5 | Acc: 55 | Max Freq: 55.0 | Rate: 8 | Feedback: Don't know of a way | Quote Rating: 7 | Quote Desc: Helpful most of the time\n",
      "REJECTED: 1\n",
      "INCOMPLETE: 1\n",
      "VALID: 81\n",
      "Median Question Duration: 11.4535\n",
      "Mean Question Duration: 12.748876543209878\n",
      "Min/Median/Mean/Max Worker Duration: 0.76 / 5.02 / 5.34 / 16.87\n",
      "Min/Median/Mean/Max Good Worker Durations: 2.73 / 5.59 / 5.73 / 14.03\n",
      "Median Worker Accuracy: 0.55\n",
      "Median Max Response Freq: 0.45\n",
      "Quote Rating: | Mean: 6.7 | Median: 7.0 | Std: 1.85\n"
     ]
    }
   ],
   "source": [
    "num_valid_hits, num_rejected_hits, num_incomplete_hits = 0, 0, 0\n",
    "metrics = {}\n",
    "task_ratings = {i: 0 for i in range(11)}\n",
    "quote_ratings = []\n",
    "durations = []\n",
    "worker_durations = []\n",
    "accuracy_by_worker = {}\n",
    "max_response_freqs = []\n",
    "worker_ids = []\n",
    "hits_by_qid = {}\n",
    "\n",
    "for hit_result in hit_results:\n",
    "    if ((len(hit_result['reject_reasons']) > 0) or\n",
    "        (len(hit_result['block_reasons']) > 0)):\n",
    "        num_rejected_hits += 1\n",
    "        print(hit_result['worker_id'], hit_result['assignment_id'],\n",
    "              '| reject_reasons:', hit_result['reject_reasons'],\n",
    "              '| block_reasons:', hit_result['block_reasons'],\n",
    "              '| bonus_reasons: ' + str(hit_result['bonus_reasons']) if 'bonus_reasons' in hit_result else '')\n",
    "    elif hit_result['feedback'] is None:\n",
    "        num_incomplete_hits += 1\n",
    "        continue\n",
    "    \n",
    "    worker_ids.append(hit_result['worker_id'])\n",
    "    num_valid_hits += 1\n",
    "    if (hit_result['task_rating'] is not None) and (hit_result['task_rating'].isdigit()):\n",
    "        task_ratings[int(hit_result['task_rating'])] += 1\n",
    "    if (hit_result.get('quote_rating') is not None) and (hit_result['quote_rating'].isdigit()):\n",
    "        quote_ratings.append(int(hit_result['quote_rating']))\n",
    "    for qtype, qtype_accuracy in hit_result['accuracy'].items():\n",
    "        accuracy_by_worker[qtype] = accuracy_by_worker.get(qtype, []) + [qtype_accuracy]\n",
    "    \n",
    "    hit_durations = []\n",
    "    response_option_counts = {option: 0 for option in options}\n",
    "    responses = []\n",
    "    for prompt in hit_result['data']:\n",
    "        qid = prompt['sample']['qid']\n",
    "        if (split is not None) and (split not in qid):\n",
    "            continue\n",
    "        hits_by_qid[qid] = hits_by_qid.get(qid, [])\n",
    "        hits_by_qid[qid].append(prompt)\n",
    "        model_stance = debate_mode_to_option[prompt['sample']['debate_mode']]\n",
    "        answer = prompt['sample']['eval_labels'][0]\n",
    "        human_correct = (prompt['response'] == answer)\n",
    "        assert answer in options, 'Answer must be in options.'\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if qid not in metrics:\n",
    "            metrics[qid] = {\n",
    "                option: {\n",
    "                    'num': 0,\n",
    "                    'num_correct': 0,\n",
    "                    'num_correct_debate_mode': 0,\n",
    "                    'num_incorrect_debate_mode': 0,\n",
    "                    'num_correct_with_correct_debate_mode': 0,\n",
    "                    'num_correct_with_incorrect_debate_mode': 0,\n",
    "                    'num_debate_mode_responses': 0,\n",
    "                    'is_debate_mode_response': []\n",
    "                }\n",
    "                for option in ([None] if model_stance is None else options)\n",
    "            }\n",
    "            for qtype in question_type_labels:\n",
    "                metrics[qid][qtype] = {\n",
    "                    'num': 0,\n",
    "                    'num_correct': 0,\n",
    "                }\n",
    "            metrics[qid]['answer'] = answer\n",
    "        for qtype in set(''.join(prompt['sample'].get('question_type_labels', []))):\n",
    "            qtype = qtype.lower()\n",
    "            metrics[qid][qtype]['num'] += 1\n",
    "            metrics[qid][qtype]['num_correct'] += human_correct\n",
    "        prompt_metrics = metrics[qid][model_stance]\n",
    "        prompt_metrics['num'] += 1\n",
    "        prompt_metrics['num_correct'] += human_correct\n",
    "        if model_stance == answer:\n",
    "            prompt_metrics['num_correct_with_correct_debate_mode'] += human_correct\n",
    "            prompt_metrics['num_correct_debate_mode'] += 1\n",
    "        else:\n",
    "            prompt_metrics['num_correct_with_incorrect_debate_mode'] += human_correct\n",
    "            prompt_metrics['num_incorrect_debate_mode'] += 1\n",
    "        prompt_metrics['num_debate_mode_responses'] += (prompt['response'] == model_stance)\n",
    "        prompt_metrics['is_debate_mode_response'].append(prompt['response'] == model_stance)\n",
    "        \n",
    "        hit_durations.append(prompt['duration'] / 1000.)\n",
    "        response_option_counts[prompt['response']] += 1\n",
    "        responses.append(prompt['response'])\n",
    "    duration = np.sum(np.array(hit_durations))\n",
    "    worker_durations.append(duration)\n",
    "    durations += hit_durations\n",
    "    response_options_array = np.array(list(response_option_counts.values()))\n",
    "    response_options_array = response_options_array / response_options_array.sum()\n",
    "    max_response_freq = response_options_array.max()\n",
    "    max_response_freqs.append(max_response_freq)\n",
    "    acc = round(100 * hit_result['accuracy'][prompt_type])\n",
    "    print('| Time:', round(duration, 1),\n",
    "          '| Acc:', acc,\n",
    "          '| Max Freq:', round(100 * max_response_freq, 1),\n",
    "          '| Rate:', hit_result['task_rating'],\n",
    "          '| Feedback:', hit_result['feedback'],\n",
    "          '| Quote Rating:', None if 'quote_rating' not in hit_result else hit_result['quote_rating'], \n",
    "          '| Quote Desc:', None if 'quote_description' not in hit_result else hit_result['quote_description'])\n",
    "\n",
    "good_worker_durations = []\n",
    "assert len(worker_durations) == len(accuracy_by_worker[prompt_type])\n",
    "for worker_duration, worker_accuracy in zip(worker_durations, accuracy_by_worker[prompt_type]):\n",
    "    if worker_accuracy > np.median(np.array(accuracy_by_worker[prompt_type])):\n",
    "        good_worker_durations.append(worker_duration)\n",
    "\n",
    "quote_ratings = np.array(quote_ratings)\n",
    "durations = np.array(durations)\n",
    "worker_durations = np.array(worker_durations)\n",
    "good_worker_durations = np.array(good_worker_durations)\n",
    "max_response_freqs = np.array(max_response_freqs)\n",
    "\n",
    "quote_ratings.sort()\n",
    "durations.sort()\n",
    "worker_durations.sort()\n",
    "good_worker_durations.sort()\n",
    "max_response_freqs.sort()\n",
    "\n",
    "for qtype in accuracy_by_worker:\n",
    "    accuracy_by_worker[qtype] = np.array(accuracy_by_worker[qtype])\n",
    "    accuracy_by_worker[qtype].sort()\n",
    "print('REJECTED:', num_rejected_hits)\n",
    "print('INCOMPLETE:', num_incomplete_hits)\n",
    "print('VALID:', num_valid_hits)\n",
    "print('Median Question Duration:', np.median(durations))\n",
    "print('Mean Question Duration:', np.mean(durations[int(durations.shape[0] / 10.):int(9. * durations.shape[0] / 10.)]))\n",
    "print('Min/Median/Mean/Max Worker Duration:',\n",
    "      round(np.min(worker_durations / 60.), 2), '/',\n",
    "      round(np.median(worker_durations / 60.), 2), '/',\n",
    "      round(np.mean(worker_durations / 60.), 2), '/',\n",
    "      round(np.max(worker_durations / 60.), 2))\n",
    "print('Min/Median/Mean/Max Good Worker Durations:',\n",
    "      round(np.min(good_worker_durations / 60.), 2), '/',\n",
    "      round(np.median(good_worker_durations / 60.), 2),'/',\n",
    "      round(np.mean(good_worker_durations / 60.), 2), '/',\n",
    "      round(np.max(good_worker_durations / 60.), 2))\n",
    "print('Median Worker Accuracy:', np.median(accuracy_by_worker[prompt_type]))\n",
    "print('Median Max Response Freq:', np.median(max_response_freqs))\n",
    "print('Quote Rating:',\n",
    "      '| Mean:', round(quote_ratings.mean(), 2),\n",
    "      '| Median:', round(np.median(quote_ratings), 2),\n",
    "      '| Std:', round(np.std(quote_ratings), 2))\n",
    "# pprint(hit_results[0]['data'][0])\n",
    "# pprint(hit_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evals per sample: 5.4\n",
      "Fraction insuffient evals: 0.0\n",
      "Convinced: 48.46 %\n",
      "- Correct debater: 75.39 %\n",
      "- Incorrect debater: 35.0 %\n",
      "Accuracy: 52.89 %\n",
      "- Correct debater: 75.39 %\n",
      "- Incorrect debater: 41.64 %\n",
      "Extra Evals: 7.41 %\n",
      "Evals per sample distribution: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7]\n",
      "Accuracy/Num-Samples by Q Type:\n",
      "{'a': (0.2803921568627451, 2),\n",
      " 'c': (0.5391246498599439, 35),\n",
      " 'l': (0.5303839869281045, 70),\n",
      " 'm': (0.45699891067538134, 12),\n",
      " 's': (0.5563061683006536, 16)}\n"
     ]
    }
   ],
   "source": [
    "accuracy_by_qtype = {qtype: [] for qtype in question_type_labels}\n",
    "accuracy_by_sample = []\n",
    "accuracy_by_sample_correct_debate_mode = []\n",
    "accuracy_by_sample_incorrect_debate_mode = []\n",
    "convinced_freqs = []\n",
    "convinced_freqs_with_correct_debate_mode = []\n",
    "convinced_freqs_with_incorrect_debate_mode = []\n",
    "num_evals_by_sample = []\n",
    "convinced_by_sample = []\n",
    "for qid, qid_metrics in metrics.items():\n",
    "    answer = metrics[qid]['answer']\n",
    "    for qid_metric_key, prompt in qid_metrics.items():\n",
    "        if qid_metric_key in question_type_labels:\n",
    "            qtype = qid_metric_key\n",
    "            if qid_metrics[qtype]['num'] > 0:\n",
    "                accuracy_by_qtype[qtype].append(qid_metrics[qtype]['num_correct'] / qid_metrics[qtype]['num'])\n",
    "            continue\n",
    "        if not (qid_metric_key in [None] + options):\n",
    "            continue\n",
    "        model_stance = qid_metric_key\n",
    "\n",
    "        # Q-only stats\n",
    "        prompt_metrics = metrics[qid][model_stance]\n",
    "        num_evals_by_sample.append(prompt_metrics['num'])\n",
    "        convinced_by_sample.append(prompt_metrics['is_debate_mode_response'])\n",
    "        accuracy_by_sample.append(prompt_metrics['num_correct'] / prompt_metrics['num'])\n",
    "        if model_stance is None:\n",
    "            continue\n",
    "        \n",
    "        # Debater stats\n",
    "#         if 'num_debate_mode_responses' not in prompt_metrics:\n",
    "#             print(qid_metric_key, prompt_metrics)\n",
    "        convinced_freq = prompt_metrics['num_debate_mode_responses'] / prompt_metrics['num']\n",
    "        if model_stance == answer:\n",
    "            convinced_freqs_with_correct_debate_mode.append(convinced_freq)\n",
    "            accuracy_by_sample_correct_debate_mode.append(\n",
    "                prompt_metrics['num_correct_with_correct_debate_mode'] /\n",
    "                prompt_metrics['num_correct_debate_mode'])\n",
    "        else:\n",
    "            convinced_freqs_with_incorrect_debate_mode.append(convinced_freq)\n",
    "            accuracy_by_sample_incorrect_debate_mode.append(\n",
    "                prompt_metrics['num_correct_with_incorrect_debate_mode'] /\n",
    "                prompt_metrics['num_incorrect_debate_mode'])\n",
    "        convinced_freqs.append(convinced_freq)\n",
    "\n",
    "accuracy_by_qtype = {qtype: (np.array(accuracy_by_qtype[qtype]).mean(), len(accuracy_by_qtype[qtype])) for qtype in question_type_labels}\n",
    "worker_ids = set(worker_ids)\n",
    "        \n",
    "num_evals_by_sample = np.array(num_evals_by_sample)\n",
    "print('Evals per sample:', num_evals_by_sample.mean())\n",
    "print('Fraction insuffient evals:', (num_evals_by_sample < 5).mean())\n",
    "\n",
    "convinced_freqs = np.array(convinced_freqs)\n",
    "print('Convinced:', round(100 * convinced_freqs.mean(), 2), '%')\n",
    "convinced_freqs_with_correct_debate_mode = np.array(convinced_freqs_with_correct_debate_mode)\n",
    "print('- Correct debater:', round(100 * convinced_freqs_with_correct_debate_mode.mean(), 2), '%')\n",
    "convinced_freqs_with_incorrect_debate_mode = np.array(convinced_freqs_with_incorrect_debate_mode)\n",
    "print('- Incorrect debater:', round(100 * convinced_freqs_with_incorrect_debate_mode.mean(), 2), '%')\n",
    "\n",
    "accuracy_by_sample = np.array(accuracy_by_sample)\n",
    "print('Accuracy:', round(100 * accuracy_by_sample.mean(), 2), '%')\n",
    "accuracy_by_sample_correct_debate_mode = np.array(accuracy_by_sample_correct_debate_mode)\n",
    "print('- Correct debater:', round(100 * accuracy_by_sample_correct_debate_mode.mean(), 2), '%')\n",
    "accuracy_by_sample_incorrect_debate_mode = np.array(accuracy_by_sample_incorrect_debate_mode)\n",
    "print('- Incorrect debater:', round(100 * accuracy_by_sample_incorrect_debate_mode.mean(), 2), '%')\n",
    "\n",
    "num_target_evals = 5\n",
    "print('Extra Evals:', round(((100. * (num_evals_by_sample - num_target_evals).sum()) / num_evals_by_sample.sum()), 2), '%')\n",
    "num_evals_by_sample.sort()\n",
    "print('Evals per sample distribution:', num_evals_by_sample)\n",
    "\n",
    "print('Accuracy/Num-Samples by Q Type:')\n",
    "pprint(accuracy_by_qtype)\n",
    "# 1.5*3.1*60/(917.5684545454544*26/(20*60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPS, Mean: (46.91, 8.59)\n"
     ]
    }
   ],
   "source": [
    "def nps(task_ratings):\n",
    "    num_ratings = sum(list(task_ratings.values()))\n",
    "    if num_ratings == 0:\n",
    "        return None\n",
    "\n",
    "    nps_sum_ratings = 0\n",
    "    sum_ratings = 0\n",
    "    for score, num_raters in task_ratings.items():\n",
    "        sum_ratings += num_raters * score\n",
    "        if score >= 9:\n",
    "            nps_sum_ratings += num_raters\n",
    "        elif score <= 6:\n",
    "            nps_sum_ratings -= num_raters\n",
    "    return round(100 * (nps_sum_ratings / float(num_ratings)), 2), round((sum_ratings / float(num_ratings)), 2)\n",
    "\n",
    "print('NPS, Mean:', nps(task_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bi-Ranker': array([46.33333333, 42.66666667, 44.        , 46.33333333, 42.33333333]),\n",
      " 'BoW-A': array([41.33333333, 41.        , 43.        , 40.        , 40.66666667]),\n",
      " 'Cross-Ranker': array([50.33333333, 50.33333333, 50.66666667, 52.33333333, 47.66666667]),\n",
      " 'Pred P(A)': array([51.        , 49.33333333, 50.        , 50.66666667, 49.        ]),\n",
      " 'Pred Search': array([45.        , 50.        , 48.66666667, 51.        , 50.33333333]),\n",
      " 'Pred Search (ToM)': array([49.66666667, 46.        , 50.        , 50.        , 49.        ]),\n",
      " 'Pred ΔP(A)': array([47.66666667, 47.66666667, 49.33333333, 50.33333333, 46.66666667]),\n",
      " 'TFIDF-A': array([43.33333333, 41.        , 45.66666667, 42.33333333, 45.33333333]),\n",
      " 'TFIDF-QA': array([40.33333333, 41.33333333, 44.33333333, 41.33333333, 42.66666667])}\n"
     ]
    }
   ],
   "source": [
    "evals[name] = []\n",
    "for eval_no in range(num_evals):\n",
    "    evals[name].append([convinced_array[eval_no] for convinced_array in convinced_by_sample])\n",
    "\n",
    "evals[name] = 100. * np.array(evals[name]).mean(axis=1)\n",
    "pprint(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** TFIDF-QA *****\n",
      "MEAN: 42.0\n",
      "STD: 1.38\n",
      "STDERR: 0.62\n",
      "\n",
      "***** TFIDF-A *****\n",
      "MEAN: 43.53\n",
      "STD: 1.77\n",
      "STDERR: 0.79\n",
      "\n",
      "***** BoW-A *****\n",
      "MEAN: 41.2\n",
      "STD: 1.0\n",
      "STDERR: 0.45\n",
      "\n",
      "***** Bi-Ranker *****\n",
      "MEAN: 44.33\n",
      "STD: 1.73\n",
      "STDERR: 0.77\n",
      "\n",
      "***** Cross-Ranker *****\n",
      "MEAN: 50.27\n",
      "STD: 1.5\n",
      "STDERR: 0.67\n",
      "\n",
      "***** Pred Search *****\n",
      "MEAN: 49.0\n",
      "STD: 2.14\n",
      "STDERR: 0.96\n",
      "\n",
      "***** Pred P(A) *****\n",
      "MEAN: 50.0\n",
      "STD: 0.76\n",
      "STDERR: 0.34\n",
      "\n",
      "***** Pred ΔP(A) *****\n",
      "MEAN: 48.33\n",
      "STD: 1.32\n",
      "STDERR: 0.59\n",
      "\n",
      "***** Pred Search (ToM) *****\n",
      "MEAN: 48.93\n",
      "STD: 1.51\n",
      "STDERR: 0.68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n, eval_values in evals.items():\n",
    "    print('*****', n, '*****')\n",
    "    print('MEAN:', round(eval_values.mean(), 2))\n",
    "    print('STD:', round(eval_values.std(), 2))\n",
    "    print('STDERR:', round(eval_values.std() / np.sqrt(full_evals.shape[0]), 2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF-QA / TFIDF-QA : 1.0\n",
      "TFIDF-QA / TFIDF-A : 0.2116\n",
      "TFIDF-QA / BoW-A : 0.3787\n",
      "TFIDF-QA / Bi-Ranker : 0.0694\n",
      "TFIDF-QA / Cross-Ranker : 0.0\n",
      "TFIDF-QA / Pred Search : 0.001\n",
      "TFIDF-QA / Pred P(A) : 0.0\n",
      "TFIDF-QA / Pred ΔP(A) : 0.0002\n",
      "TFIDF-QA / Pred Search (ToM) : 0.0001\n",
      "TFIDF-A / TFIDF-QA : 0.2116\n",
      "TFIDF-A / TFIDF-A : 1.0\n",
      "TFIDF-A / BoW-A : 0.0595\n",
      "TFIDF-A / Bi-Ranker : 0.5358\n",
      "TFIDF-A / Cross-Ranker : 0.0004\n",
      "TFIDF-A / Pred Search : 0.0046\n",
      "TFIDF-A / Pred P(A) : 0.0008\n",
      "TFIDF-A / Pred ΔP(A) : 0.003\n",
      "TFIDF-A / Pred Search (ToM) : 0.0018\n",
      "BoW-A / TFIDF-QA : 0.3787\n",
      "BoW-A / TFIDF-A : 0.0595\n",
      "BoW-A / BoW-A : 1.0\n",
      "BoW-A / Bi-Ranker : 0.0183\n",
      "BoW-A / Cross-Ranker : 0.0\n",
      "BoW-A / Pred Search : 0.0007\n",
      "BoW-A / Pred P(A) : 0.0\n",
      "BoW-A / Pred ΔP(A) : 0.0\n",
      "BoW-A / Pred Search (ToM) : 0.0001\n",
      "Bi-Ranker / TFIDF-QA : 0.0694\n",
      "Bi-Ranker / TFIDF-A : 0.5358\n",
      "Bi-Ranker / BoW-A : 0.0183\n",
      "Bi-Ranker / Bi-Ranker : 1.0\n",
      "Bi-Ranker / Cross-Ranker : 0.0009\n",
      "Bi-Ranker / Pred Search : 0.0101\n",
      "Bi-Ranker / Pred P(A) : 0.0013\n",
      "Bi-Ranker / Pred ΔP(A) : 0.0069\n",
      "Bi-Ranker / Pred Search (ToM) : 0.004\n",
      "Cross-Ranker / TFIDF-QA : 0.0\n",
      "Cross-Ranker / TFIDF-A : 0.0004\n",
      "Cross-Ranker / BoW-A : 0.0\n",
      "Cross-Ranker / Bi-Ranker : 0.0009\n",
      "Cross-Ranker / Cross-Ranker : 1.0\n",
      "Cross-Ranker / Pred Search : 0.3636\n",
      "Cross-Ranker / Pred P(A) : 0.7616\n",
      "Cross-Ranker / Pred ΔP(A) : 0.089\n",
      "Cross-Ranker / Pred Search (ToM) : 0.2454\n",
      "Pred Search / TFIDF-QA : 0.001\n",
      "Pred Search / TFIDF-A : 0.0046\n",
      "Pred Search / BoW-A : 0.0007\n",
      "Pred Search / Bi-Ranker : 0.0101\n",
      "Pred Search / Cross-Ranker : 0.3636\n",
      "Pred Search / Pred Search : 1.0\n",
      "Pred Search / Pred P(A) : 0.4188\n",
      "Pred Search / Pred ΔP(A) : 0.6129\n",
      "Pred Search / Pred Search (ToM) : 0.9608\n",
      "Pred P(A) / TFIDF-QA : 0.0\n",
      "Pred P(A) / TFIDF-A : 0.0008\n",
      "Pred P(A) / BoW-A : 0.0\n",
      "Pred P(A) / Bi-Ranker : 0.0013\n",
      "Pred P(A) / Cross-Ranker : 0.7616\n",
      "Pred P(A) / Pred Search : 0.4188\n",
      "Pred P(A) / Pred P(A) : 1.0\n",
      "Pred P(A) / Pred ΔP(A) : 0.068\n",
      "Pred P(A) / Pred Search (ToM) : 0.2549\n",
      "Pred ΔP(A) / TFIDF-QA : 0.0002\n",
      "Pred ΔP(A) / TFIDF-A : 0.003\n",
      "Pred ΔP(A) / BoW-A : 0.0\n",
      "Pred ΔP(A) / Bi-Ranker : 0.0069\n",
      "Pred ΔP(A) / Cross-Ranker : 0.089\n",
      "Pred ΔP(A) / Pred Search : 0.6129\n",
      "Pred ΔP(A) / Pred P(A) : 0.068\n",
      "Pred ΔP(A) / Pred ΔP(A) : 1.0\n",
      "Pred ΔP(A) / Pred Search (ToM) : 0.5663\n",
      "Pred Search (ToM) / TFIDF-QA : 0.0001\n",
      "Pred Search (ToM) / TFIDF-A : 0.0018\n",
      "Pred Search (ToM) / BoW-A : 0.0001\n",
      "Pred Search (ToM) / Bi-Ranker : 0.004\n",
      "Pred Search (ToM) / Cross-Ranker : 0.2454\n",
      "Pred Search (ToM) / Pred Search : 0.9608\n",
      "Pred Search (ToM) / Pred P(A) : 0.2549\n",
      "Pred Search (ToM) / Pred ΔP(A) : 0.5663\n",
      "Pred Search (ToM) / Pred Search (ToM) : 1.0\n"
     ]
    }
   ],
   "source": [
    "for n1, eval_values1 in evals.items():\n",
    "    for n2, eval_values2 in evals.items():\n",
    "        print(n1, '/', n2, ':', round(ttest_ind(eval_values1, eval_values2, equal_var=False)[1], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

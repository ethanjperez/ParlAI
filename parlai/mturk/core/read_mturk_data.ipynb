{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from pprint import pprint\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "num_evals = 5\n",
    "evals = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualified: 41.94 %\n"
     ]
    }
   ],
   "source": [
    "task_dir = '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_'\n",
    "\n",
    "task_setup = [\n",
    "# ## Persuading Humans (Dev)\n",
    "# ('race', 'question', 1554052233, 'No Passage'),\n",
    "# ('race', 'quote and question', 1554006689, 'TFIDF(S,[Q;A])'),\n",
    "# ('race', 'quote and question', 1554130485, 'TFIDF(S,A)'),\n",
    "# ('race', 'quote and question', 1554069931, 'BERT Base'),\n",
    "# ('race', 'quote and question', 1554072277, 'Pred search'),\n",
    "# ('race', 'quote and question', 1554132868, 'Pred Δp(A)'),\n",
    "# ## Persuading Humans\n",
    "# ('race', 'quote and question', 1556832343, 'Pred search (Almost complete)'),\n",
    "# ('race', 'quote and question', 1557155351, 'Bi-Ranker'),\n",
    "# ## Persuading Humans: FINAL\n",
    "# ('race', 'question', 1557351318, 'No Passage'),\n",
    "# ('race', 'quote and question', 1556671432, 'TFIDF(S,[Q;A])'),\n",
    "# ('race', 'quote and question', 1556725767, 'TFIDF(S,A)'),\n",
    "# ('race', 'quote and question', 1556739336, 'FastText(S,A)'),\n",
    "# ('race', 'quote and question', 1557144204, 'BERT Base'),\n",
    "# ('race', 'quote and question', 1558102264, 'BERT Large'),\n",
    "# ('race', 'quote and question', 1556892630, 'Pred search'),\n",
    "# ('race', 'quote and question', 1556809031, 'Pred p(A)'),\n",
    "# ('race', 'quote and question', 1556756789, 'Pred Δp(A)'),  # (race.m=sl-sents.i.best.e)\n",
    "# ('race', 'quote and question', 1557420471, 'Human 1'),\n",
    "# ('race', 'quote and question', 1558016111, 'Human 2'),\n",
    "# ('race', 'quote and question', 1558028902, 'Human 3'),\n",
    "# ## Human QA on Summary\n",
    "# ('race', 'quotes and question', 1555946909, 'FastText(S,A) (lower pay)'),\n",
    "# ('race', 'quotes and question', 1555952058, 'BERT Base Best Epoch'),  # (6-10 sentence incorrectly placed at end)\n",
    "# ('race', 'quotes and question', 1556939750, 'Pred Δp(A) (lower pay)'),\n",
    "# ('race', 'quotes and question', 1557093902, 'Bi-Ranker'),\n",
    "# ## Human QA on Summary: FINAL\n",
    "# ('race', 'passage and question', 1555823963, 'Full Passage'),\n",
    "# ('race', 'quotes and question', ?, 'First N'),\n",
    "# ('race', 'quotes and question', ?, 'TFIDF(S,Q)'),\n",
    "# ('race', 'quotes and question', ?, 'FastText(S,Q)'),  # Running\n",
    "# ('race', 'quotes and question', 1557189780, 'TFIDF(S,[Q;A])'),\n",
    "# ('race', 'quotes and question', 1557164593, 'TFIDF(S,A)'),\n",
    "# ('race', 'quotes and question', 1557234076, 'FastText(S,A)'),\n",
    "# ('race', 'quotes and question', 1557085110, 'BERT Base'),  # Last Epoch\n",
    "# ('race', 'quotes and question', 1558119911, 'BERT Large'),\n",
    "# ('race', 'quotes and question', 1556987177, 'Pred search'),\n",
    "# ('race', 'quotes and question', 1556977072, 'Pred p(A)'),\n",
    "# ('race', 'quotes and question', 1556999857, 'Pred Δp(A)'),\n",
    "# ('race', 'quotes and question', 1557432288, 'Human 1'),\n",
    "# ('race', 'quotes and question', 1558039471, 'Human 2'),\n",
    "# ('race', 'quotes and question', 1558054770, 'Human 3'),\n",
    "# ## Persuading Humans\n",
    "# ('dream', 'quote and question', 1556670413, 'Bi-Ranker'),\n",
    "# ('dream', 'quote and question', 1555333992, 'Pred search (ToM)'),\n",
    "# ## Persuading Humans: FINAL\n",
    "# ('dream', 'question', 1554582693, 'No Passage'),\n",
    "# ('dream', 'quote and question', 1554596686, 'TFIDF(S,[Q;A])'),\n",
    "# ('dream', 'quote and question', 1554587404, 'TFIDF(S,A)'),\n",
    "# ('dream', 'quote and question', 1554662280, 'FastText(S,A)'),\n",
    "# ('dream', 'quote and question', 1554675304, 'BERT Base'),\n",
    "# ('dream', 'quote and question', 1558108101, 'BERT Large'),\n",
    "# ('dream', 'quote and question', 1554685131, 'Pred search'),\n",
    "# ('dream', 'quote and question', 1554692472, 'Pred p(A)'),\n",
    "# ('dream', 'quote and question', 1554729998, 'Pred Δp(A)'),\n",
    "# ('dream', 'quote and question', 1558028987, 'Human 1'),\n",
    "# ('dream', 'quotes and question', ?, 'Human 2'),\n",
    "# ('dream', 'quotes and question', ?, 'Human 3'),\n",
    "# ## Human QA on Summary\n",
    "# ('dream', 'question, answers, and quotes', 1555707929, 'TFIDF(S,A)'),  # 64.21%: (Less filter / no feedback)\n",
    "# ('dream', 'question, answers, and quotes', 1555722489, 'BERT Base'),  # 65.38%: (Less filter / no feedback)\n",
    "# ('dream', 'question and quotes', 1555789302, 'Pred search'),  # 75.17% (4/5 filter)\n",
    "# ('dream', 'question and quotes', 1555812443, 'Pred search'),  # 79.32% Actually: quotes and question (4/5 filter)\n",
    "# ('dream', 'quotes and question', 1555946647, 'BERT Base (RACE -> DREAM)'),  # (4 sentences incorrectly placed at end) (80.84%)\n",
    "# ('dream', 'quotes and question', 1556740293, 'Bi-Ranker'),\n",
    "# ## Human QA on Summary: FINAL\n",
    "# ('dream', 'passage and question', 1555804551, 'Full Passage'),\n",
    "# ('dream', 'quotes and question', ?, 'First N'),  # Running\n",
    "# ('dream', 'quotes and question', 1558120652, 'TFIDF(S,Q)'),  # TODO: See results\n",
    "# ('dream', 'quotes and question', 1558059069, 'FastText(S,Q)'),\n",
    "# ('dream', 'quotes and question', 1556811067, 'TFIDF(S,[Q;A])'),\n",
    "# ('dream', 'quotes and question', 1556757043, 'TFIDF(S,A)'),\n",
    "# ('dream', 'quotes and question', 1555823257, 'FastText(S,A)'),\n",
    "# ('dream', 'quotes and question', 1556727396, 'BERT Base'),\n",
    "# ('dream', 'quotes and question', 1558101763, 'BERT Large'),\n",
    "# ('dream', 'quotes and question', 1556832115, 'Pred search'),\n",
    "# ('dream', 'quotes and question', 1556892896, 'Pred p(A)'),\n",
    "# ('dream', 'quotes and question', 1556938429, 'Pred Δp(A)'),\n",
    "# ('dream', 'quotes and question', 1558016251, 'Human 1'),\n",
    "# ('dream', 'quotes and question', ?, 'Human 2'),\n",
    "# ('dream', 'quotes and question', ?, 'Human 3'),\n",
    "]\n",
    "\n",
    "dataset, prompt_type, task_id, name = task_setup[-1]\n",
    "split = None  # 'middle', 'high', None\n",
    "\n",
    "\n",
    "# Set useful variables\n",
    "task_dir += str(task_id)\n",
    "if dataset != 'race':\n",
    "    split = None\n",
    "num_options = 3 if dataset == 'dream' else 4\n",
    "options = ['A', 'B', 'C', 'D'][:num_options]\n",
    "debate_mode_to_option = {'Ⅰ': 'A', 'Ⅱ': 'B', 'Ⅲ': 'C', 'Ⅳ': 'D', 'ⅰ': 'A', 'ⅱ': 'B', 'ⅲ': 'C', 'ⅳ': 'D', None: None}\n",
    "question_type_labels = ['a', 'c', 'l', 'm', 's'] if dataset == 'dream' else ['a', 'b', 'c', 'd', 'e']\n",
    "\n",
    "# if (dataset == 'dream') and (prompt_type == 'quote and question'):\n",
    "#     question_type_labels = []\n",
    "\n",
    "# Read HIT data\n",
    "hit_results = []\n",
    "num_passed_test = 0\n",
    "for hit_dir in os.listdir(task_dir):\n",
    "    if hit_dir.startswith('o_'):\n",
    "        continue\n",
    "    num_passed_test += 1\n",
    "    with open(os.path.join(task_dir, hit_dir, 'custom/data.json'), 'r') as file:\n",
    "        hit_results.append(json.load(file))\n",
    "        file.close()\n",
    "if len(os.listdir(task_dir)) != num_passed_test:\n",
    "    num_total_tested = len(os.listdir(task_dir)) - num_passed_test\n",
    "    print('Qualified:', round((100. * num_passed_test) / num_total_tested, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Time: 343.0 | Acc: 70 | Max Freq: 40.0 | Rate: 8 | Feedback: Not sure | Quote Rating: 2 | Quote Desc: Usually easy to decipher, but sometimes just don't make any sense. \n",
      "| Time: 414.7 | Acc: 80 | Max Freq: 50.0 | Rate: 10 | Feedback: The only way I could see that the task could be improved is make sure each passage as at least a little bit of information that guides you toward the correct answer.  | Quote Rating: 8 | Quote Desc: I think most of the provided passage quotes offered enough information that allowed you to answer the questions but there were a few that did not have enough information to and you had to guess what you thought the answer should be. \n",
      "| Time: 537.4 | Acc: 80 | Max Freq: 40.0 | Rate: 8 | Feedback: Make the questions less vague, but I am sure that will improve.  | Quote Rating: 8 | Quote Desc: Most of them were clear, and most of them made the correct answer obvious. However, quotes #1-#3 and #20 were vague. It was impossible to figure out those answers given those quotes. \n",
      "| Time: 391.1 | Acc: 85 | Max Freq: 50.0 | Rate: 10 | Feedback: Show the average correct for each task so it feels more competitive and how many must be correct for the bonus is known. | Quote Rating: 8 | Quote Desc: They included details that provided answers to unstated details.\n",
      "| Time: 312.3 | Acc: 85 | Max Freq: 55.0 | Rate: 7 | Feedback: make the window not so jittery on chrome. | Quote Rating: 8 | Quote Desc: Most of them made sense, some were not relevant at all. They were mostly about where people were or where they went.\n",
      "| Time: 486.3 | Acc: 90 | Max Freq: 35.0 | Rate: 9 | Feedback: Everything is good. | Quote Rating: 7 | Quote Desc: Some of them didn't help at all but about 3/4 of them were very helpful.\n",
      "| Time: 487.6 | Acc: 85 | Max Freq: 35.0 | Rate: 10 | Feedback: I enjoy doing these! Keep them coming!! It makes my brain work :) | Quote Rating: 8 | Quote Desc: Broken, but useful to determine the intent of the conversations.\n",
      "| Time: 324.6 | Acc: 90 | Max Freq: 50.0 | Rate: 0 | Feedback: I dunno - I just don't have others I recommend these kinds of tasks to. Don't even want people I work with to know I take surveys for cash. | Quote Rating: 9 | Quote Desc: Most of them were snippets directly related to the question\n",
      "| Time: 415.4 | Acc: 85 | Max Freq: 45.0 | Rate: 7 | Feedback: Make all quotes directly related to the questions. | Quote Rating: 8 | Quote Desc: Overall they were more useful than the last similar HIT that I did.\n",
      "| Time: 443.5 | Acc: 85 | Max Freq: 50.0 | Rate: 10 | Feedback: I think it is good | Quote Rating: 10 | Quote Desc: Straight-forward for the most part, conversation format\n",
      "| Time: 785.7 | Acc: 55 | Max Freq: 45.0 | Rate: 10 | Feedback: make it so we can find the answer with just the wording | Quote Rating: 6 | Quote Desc: the wording threw me off a bit, but i really enjoyed \n",
      "| Time: 461.0 | Acc: 75 | Max Freq: 35.0 | Rate: 7 | Feedback: Avoid placing different speakers on the same line. Multi-lines would make it easier to read. | Quote Rating: 6 | Quote Desc: Short. Sometimes an answer could only be determined by the elimination of definitely incorrect answers.\n",
      "| Time: 354.3 | Acc: 65 | Max Freq: 50.0 | Rate: 10 | Feedback: Make some of the information provided a little more clear. | Quote Rating: 7 | Quote Desc: Most were very helpful and made answering easy. There were some that did not give enough context or were not clear enough to answer correctly.\n",
      "| Time: 457.7 | Acc: 85 | Max Freq: 40.0 | Rate: 10 | Feedback: less cuts in between the sentences | Quote Rating: 9 | Quote Desc: very good, a few were misleading though\n",
      "| Time: 456.1 | Acc: 75 | Max Freq: 40.0 | Rate: 9 | Feedback: Some of the passages require just a little more context, and the grammar needs to be improved.  | Quote Rating: 6 | Quote Desc: Of the questions I answered incorrectly, I could only reasonably accept the correct answer for two of them. For example how am I supposed to infer the two speakers in Q20 were strangers when 'friends' was an option?\n",
      "| Time: 659.5 | Acc: 75 | Max Freq: 45.0 | Rate: 8 | Feedback: Not sure if it would make sense, but maybe having an option to flag a question that really doesn't make any sense. Like #7 it talks about a rental but doesn't say anything at all about price and doesn't allude to price in anyway. But asks how much the rental costs. (See also: #8, #16, #18, #19, #20) | Quote Rating: 5 | Quote Desc: Some were painfully obvious, but others were impossible to answer.\n",
      "| Time: 457.1 | Acc: 70 | Max Freq: 35.0 | Rate: 10 | Feedback: i dont have a suggestion.  it worked great for me and it was fun. | Quote Rating: 7 | Quote Desc: Some vague, some were very specific and clear, some required I infer some info which I sometimes did and sometimes didnt do well with\n",
      "| Time: 571.1 | Acc: 85 | Max Freq: 65.0 | Rate: 10 | Feedback: Fewer training questions at the beginning. Three would be enough I think. | Quote Rating: 9 | Quote Desc: For most of them they made it easy to answer the questions. They were helpful.\n",
      "| Time: 780.5 | Acc: 60 | Max Freq: 50.0 | Rate: 8 | Feedback: make it a bit easier | Quote Rating: 8 | Quote Desc: very difficult\n",
      "| Time: 339.8 | Acc: 80 | Max Freq: 50.0 | Rate: 10 | Feedback: There isn't anything to improve | Quote Rating: 10 | Quote Desc: They were informative and useful\n",
      "| Time: 605.9 | Acc: 75 | Max Freq: 40.0 | Rate: 10 | Feedback: Maybe review the quotes showed because two of them provided absolutely no helpful info at all. | Quote Rating: 8 | Quote Desc: Some provide a good deal of info, while others absolutely none at all. Some were clear, while others confusing.\n",
      "| Time: 323.8 | Acc: 85 | Max Freq: 50.0 | Rate: 10 | Feedback: Make there be just a bit more context to some of the quotes.  | Quote Rating: 6 | Quote Desc: Some of them were very hard to tell, they didn't all have enough information, like how were we supposed to tell how many people were in the guys family?\n",
      "| Time: 385.1 | Acc: 80 | Max Freq: 60.0 | Rate: 9 | Feedback: By providing better quotes as sometimes it is difficult to find out who is speaking a sentence | Quote Rating: 7 | Quote Desc: Some of them helped while the others were confusing \n",
      "| Time: 408.3 | Acc: 85 | Max Freq: 45.0 | Rate: 8 | Feedback: clarify some of the quotes | Quote Rating: 7 | Quote Desc: some were too vague\n",
      "| Time: 461.9 | Acc: 90 | Max Freq: 55.0 | Rate: 10 | Feedback: I feels fine to me. | Quote Rating: 9 | Quote Desc: some were pretty devoid of any helpful hint.\n",
      "| Time: 547.4 | Acc: 75 | Max Freq: 50.0 | Rate: 7 | Feedback: Make sure the answers are at least possible.  Some questions were impossible to answer based on the provided information. | Quote Rating: 7 | Quote Desc: A little bit cryptic and some were clearly missing the information that the question asked. \n",
      "REJECTED: 0\n",
      "INCOMPLETE: 0\n",
      "VALID: 26\n",
      "Median Question Duration: 18.7395\n",
      "Mean Question Duration: 21.217925480769228\n",
      "Min/Median/Mean/Max Worker Duration: 5.21 / 7.61 / 7.83 / 13.09\n",
      "Min/Median/Mean/Max Good Worker Durations: 5.21 / 7.16 / 7.06 / 9.52\n",
      "Median Worker Accuracy: 0.8\n",
      "Median Max Response Freq: 0.475\n",
      "Quote Rating: | Mean: 7.42 | Median: 8.0 | Std: 1.64\n",
      "debate_mode_counts: {'Ⅰ': 0, 'Ⅱ': 0, 'Ⅲ': 0, 'Ⅳ': 0, 'ⅰ': 0, 'ⅱ': 0, 'ⅲ': 0, 'ⅳ': 0, None: 520}\n"
     ]
    }
   ],
   "source": [
    "num_valid_hits, num_rejected_hits, num_incomplete_hits = 0, 0, 0\n",
    "metrics = {}\n",
    "task_ratings = {i: 0 for i in range(11)}\n",
    "quote_ratings = []\n",
    "durations = []\n",
    "worker_durations = []\n",
    "accuracy_by_worker = {}\n",
    "max_response_freqs = []\n",
    "worker_ids = []\n",
    "hits_by_qid = {}\n",
    "debate_mode_counts = {debate_mode: 0 for debate_mode in debate_mode_to_option.keys()}\n",
    "\n",
    "for hit_result in hit_results:\n",
    "    if ((len(hit_result['reject_reasons']) > 0) or\n",
    "        (len(hit_result['block_reasons']) > 0)):\n",
    "        num_rejected_hits += 1\n",
    "        print(hit_result['worker_id'], hit_result['assignment_id'],\n",
    "              '| reject_reasons:', hit_result['reject_reasons'],\n",
    "              '| block_reasons:', hit_result['block_reasons'],\n",
    "              '| bonus_reasons: ' + str(hit_result['bonus_reasons']) if 'bonus_reasons' in hit_result else '')\n",
    "    elif hit_result['feedback'] is None:\n",
    "        num_incomplete_hits += 1\n",
    "        continue\n",
    "    \n",
    "    worker_ids.append(hit_result['worker_id'])\n",
    "    num_valid_hits += 1\n",
    "    if (hit_result['task_rating'] is not None) and (hit_result['task_rating'].isdigit()):\n",
    "        task_ratings[int(hit_result['task_rating'])] += 1\n",
    "    if (hit_result.get('quote_rating') is not None) and (hit_result['quote_rating'].isdigit()):\n",
    "        quote_ratings.append(int(hit_result['quote_rating']))\n",
    "    for qtype, qtype_accuracy in hit_result['accuracy'].items():\n",
    "        accuracy_by_worker[qtype] = accuracy_by_worker.get(qtype, []) + [qtype_accuracy]\n",
    "    \n",
    "    hit_durations = []\n",
    "    response_option_counts = {option: 0 for option in options}\n",
    "    responses = []\n",
    "    for prompt in hit_result['data']:\n",
    "        qid = prompt['sample']['qid']\n",
    "        if (split is not None) and (split not in qid):\n",
    "            continue\n",
    "        hits_by_qid[qid] = hits_by_qid.get(qid, [])\n",
    "        hits_by_qid[qid].append(prompt)\n",
    "        debate_mode_counts[prompt['sample']['debate_mode']] += 1\n",
    "        stance = debate_mode_to_option[prompt['sample']['debate_mode']]\n",
    "        answer = prompt['sample']['eval_labels'][0]\n",
    "        human_correct = (prompt['response'] == answer)\n",
    "        assert answer in options, 'Answer must be in options.'\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if qid not in metrics:\n",
    "            metrics[qid] = {\n",
    "                option: {\n",
    "                    'num': 0,\n",
    "                    'num_correct': 0,\n",
    "                    'num_correct_debate_mode': 0,\n",
    "                    'num_incorrect_debate_mode': 0,\n",
    "                    'num_correct_with_correct_debate_mode': 0,\n",
    "                    'num_correct_with_incorrect_debate_mode': 0,\n",
    "                    'num_debate_mode_responses': 0,\n",
    "                    'is_debate_mode_response': []\n",
    "                }\n",
    "                for option in ([None] if stance is None else options)\n",
    "            }\n",
    "#             for qtype in question_type_labels:\n",
    "#                 metrics[qid][qtype] = {\n",
    "#                     'num': 0,\n",
    "#                     'num_correct': 0,\n",
    "#                 }\n",
    "            metrics[qid]['answer'] = answer\n",
    "        metrics[qid]['qtype'] = metrics[qid].get('qtype', set([]))\n",
    "        for qtype in set(''.join(prompt['sample'].get('question_type_labels', []))):\n",
    "            qtype = qtype.lower()\n",
    "            metrics[qid]['qtype'].add(qtype)\n",
    "#             if qtype not in metrics[qid]:\n",
    "#                 print('Did you set `dataset` appropriately?')\n",
    "#             metrics[qid][qtype]['num'] += 1\n",
    "#             metrics[qid][qtype]['num_correct'] += human_correct\n",
    "        prompt_metrics = metrics[qid][stance]\n",
    "        prompt_metrics['num'] += 1\n",
    "        prompt_metrics['num_correct'] += human_correct\n",
    "        if stance == answer:\n",
    "            prompt_metrics['num_correct_with_correct_debate_mode'] += human_correct\n",
    "            prompt_metrics['num_correct_debate_mode'] += 1\n",
    "        else:\n",
    "            prompt_metrics['num_correct_with_incorrect_debate_mode'] += human_correct\n",
    "            prompt_metrics['num_incorrect_debate_mode'] += 1\n",
    "        prompt_metrics['num_debate_mode_responses'] += (prompt['response'] == stance)\n",
    "        prompt_metrics['is_debate_mode_response'].append(prompt['response'] == stance)\n",
    "        \n",
    "        hit_durations.append(prompt['duration'] / 1000.)\n",
    "        response_option_counts[prompt['response']] += 1\n",
    "        responses.append(prompt['response'])\n",
    "    duration = np.sum(np.array(hit_durations))\n",
    "    worker_durations.append(duration)\n",
    "    durations += hit_durations\n",
    "    response_options_array = np.array(list(response_option_counts.values()))\n",
    "    response_options_array = response_options_array / response_options_array.sum()\n",
    "    max_response_freq = response_options_array.max()\n",
    "    max_response_freqs.append(max_response_freq)\n",
    "    acc = round(100 * hit_result['accuracy'][prompt_type])\n",
    "    print('| Time:', round(duration, 1),\n",
    "          '| Acc:', acc,\n",
    "          '| Max Freq:', round(100 * max_response_freq, 1),\n",
    "          '| Rate:', hit_result['task_rating'],\n",
    "          '| Feedback:', hit_result['feedback'],\n",
    "          '| Quote Rating:', None if 'quote_rating' not in hit_result else hit_result['quote_rating'], \n",
    "          '| Quote Desc:', None if 'quote_description' not in hit_result else hit_result['quote_description'])\n",
    "\n",
    "debate_modes_used = list(filter(lambda x: debate_mode_counts[x] > 0, debate_mode_counts.keys()))\n",
    "\n",
    "good_worker_durations = []\n",
    "assert len(worker_durations) == len(accuracy_by_worker[prompt_type])\n",
    "for worker_duration, worker_accuracy in zip(worker_durations, accuracy_by_worker[prompt_type]):\n",
    "    if worker_accuracy > np.median(np.array(accuracy_by_worker[prompt_type])):\n",
    "        good_worker_durations.append(worker_duration)\n",
    "\n",
    "quote_ratings = np.array(quote_ratings)\n",
    "durations = np.array(durations)\n",
    "worker_durations = np.array(worker_durations)\n",
    "good_worker_durations = np.array(good_worker_durations)\n",
    "max_response_freqs = np.array(max_response_freqs)\n",
    "\n",
    "quote_ratings.sort()\n",
    "durations.sort()\n",
    "worker_durations.sort()\n",
    "good_worker_durations.sort()\n",
    "max_response_freqs.sort()\n",
    "\n",
    "for qtype in accuracy_by_worker:\n",
    "    accuracy_by_worker[qtype] = np.array(accuracy_by_worker[qtype])\n",
    "    accuracy_by_worker[qtype].sort()\n",
    "print('REJECTED:', num_rejected_hits)\n",
    "print('INCOMPLETE:', num_incomplete_hits)\n",
    "print('VALID:', num_valid_hits)\n",
    "print('Median Question Duration:', np.median(durations))\n",
    "print('Mean Question Duration:', np.mean(durations[int(durations.shape[0] / 10.):int(9. * durations.shape[0] / 10.)]))\n",
    "print('Min/Median/Mean/Max Worker Duration:',\n",
    "      round(np.min(worker_durations / 60.), 2), '/',\n",
    "      round(np.median(worker_durations / 60.), 2), '/',\n",
    "      round(np.mean(worker_durations / 60.), 2), '/',\n",
    "      round(np.max(worker_durations / 60.), 2))\n",
    "print('Min/Median/Mean/Max Good Worker Durations:',\n",
    "      round(np.min(good_worker_durations / 60.), 2), '/',\n",
    "      round(np.median(good_worker_durations / 60.), 2),'/',\n",
    "      round(np.mean(good_worker_durations / 60.), 2), '/',\n",
    "      round(np.max(good_worker_durations / 60.), 2))\n",
    "print('Median Worker Accuracy:', np.median(accuracy_by_worker[prompt_type]))\n",
    "print('Median Max Response Freq:', np.median(max_response_freqs))\n",
    "print('Quote Rating:',\n",
    "      '| Mean:', round(quote_ratings.mean(), 2),\n",
    "      '| Median:', round(np.median(quote_ratings), 2),\n",
    "      '| Std:', round(np.std(quote_ratings), 2))\n",
    "# pprint(hit_results[0]['data'][0])\n",
    "# pprint(hit_results[0])\n",
    "print('debate_mode_counts:', debate_mode_counts)\n",
    "\n",
    "qids = list(metrics.keys())\n",
    "qids.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPS, Mean: (57.69, 8.65)\n"
     ]
    }
   ],
   "source": [
    "def nps(task_ratings):\n",
    "    num_ratings = sum(list(task_ratings.values()))\n",
    "    if num_ratings == 0:\n",
    "        return None\n",
    "\n",
    "    nps_sum_ratings = 0\n",
    "    sum_ratings = 0\n",
    "    for score, num_raters in task_ratings.items():\n",
    "        sum_ratings += num_raters * score\n",
    "        if score >= 9:\n",
    "            nps_sum_ratings += num_raters\n",
    "        elif score <= 6:\n",
    "            nps_sum_ratings -= num_raters\n",
    "    return round(100 * (nps_sum_ratings / float(num_ratings)), 2), round((sum_ratings / float(num_ratings)), 2)\n",
    "\n",
    "print('NPS, Mean:', nps(task_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': (0.30000000000000004, 2),\n",
      " 'c': (0.8038095238095238, 35),\n",
      " 'l': (0.7638095238095238, 70),\n",
      " 'm': (0.8638888888888889, 12),\n",
      " 's': (0.8416666666666666, 16)}\n",
      "Evals per sample: 5.2\n",
      "Fraction insuffient evals: 0.0\n",
      "Convinced: nan % ( nan )\n",
      "- Agent is right: nan % ( nan )\n",
      "- Agent is wrong: nan % ( nan )\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Accuracy: 79.13 %\n",
      "Accuracy: 79.13333333333333 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/main/lib/python3.6/site-packages/ipykernel_launcher.py:80: RuntimeWarning: Mean of empty slice.\n",
      "/anaconda3/envs/main/lib/python3.6/site-packages/ipykernel_launcher.py:82: RuntimeWarning: Mean of empty slice.\n",
      "/anaconda3/envs/main/lib/python3.6/site-packages/ipykernel_launcher.py:84: RuntimeWarning: Mean of empty slice.\n",
      "/anaconda3/envs/main/lib/python3.6/site-packages/ipykernel_launcher.py:88: RuntimeWarning: Mean of empty slice.\n",
      "/anaconda3/envs/main/lib/python3.6/site-packages/ipykernel_launcher.py:90: RuntimeWarning: Mean of empty slice.\n",
      "/anaconda3/envs/main/lib/python3.6/site-packages/ipykernel_launcher.py:92: RuntimeWarning: Mean of empty slice.\n"
     ]
    }
   ],
   "source": [
    "accuracy_by_qtype = {qtype: [] for qtype in question_type_labels}\n",
    "accuracy_by_sample = []\n",
    "accuracy_by_sample_correct_debate_mode = []\n",
    "accuracy_by_sample_incorrect_debate_mode = []\n",
    "convinced_by_qtype = {qtype: [] for qtype in question_type_labels}\n",
    "convinced_freqs = []\n",
    "convinced_freqs_with_correct_debate_mode = []\n",
    "convinced_freqs_with_incorrect_debate_mode = []\n",
    "convinced_freqs_by_qtype = {qtype: [] for qtype in question_type_labels}\n",
    "convinced_freqs_with_correct_debate_mode_by_qtype = {qtype: [] for qtype in question_type_labels}\n",
    "convinced_freqs_with_incorrect_debate_mode_by_qtype = {qtype: [] for qtype in question_type_labels}\n",
    "num_evals_by_sample = []\n",
    "convinced_by_sample = []\n",
    "# qtypes = []\n",
    "# qtypes_with_correct_debate_mode = []\n",
    "# qtypes_with_incorrect_debate_mode = []\n",
    "\n",
    "for qid in qids:\n",
    "    qid_metrics = metrics[qid]\n",
    "    answer = qid_metrics['answer']\n",
    "    for qid_metric_key, prompt in qid_metrics.items():\n",
    "        if qid_metric_key in question_type_labels:\n",
    "#             qtype = qid_metric_key\n",
    "#             if qid_metrics[qtype]['num'] > 0:\n",
    "#                 accuracy_by_qtype[qtype].append(qid_metrics[qtype]['num_correct'] / qid_metrics[qtype]['num'])\n",
    "#                 convinced_by_qtype[qtype].append(qid_metrics[qtype][])\n",
    "            continue\n",
    "        if not (qid_metric_key in [None] + options):\n",
    "            continue\n",
    "        stance = qid_metric_key\n",
    "\n",
    "        # Q-only stats\n",
    "        prompt_metrics = qid_metrics[stance]\n",
    "        num_evals_by_sample.append(prompt_metrics['num'])\n",
    "        convinced_by_sample.append(prompt_metrics['is_debate_mode_response'])\n",
    "        accuracy_by_sample.append(prompt_metrics['num_correct'] / prompt_metrics['num'])\n",
    "        for qtype in qid_metrics['qtype']:\n",
    "            accuracy_by_qtype[qtype].append(prompt_metrics['num_correct'] / prompt_metrics['num'])\n",
    "        if stance is None:\n",
    "            continue\n",
    "        \n",
    "        # Debater stats\n",
    "#         if 'num_debate_mode_responses' not in prompt_metrics:\n",
    "#             print(qid_metric_key, prompt_metrics)\n",
    "        convinced_freq = prompt_metrics['num_debate_mode_responses'] / prompt_metrics['num']\n",
    "        if stance == answer:\n",
    "            convinced_freqs_with_correct_debate_mode.append(convinced_freq)\n",
    "            for qtype in qid_metrics['qtype']:\n",
    "                convinced_freqs_with_correct_debate_mode_by_qtype[qtype].append(convinced_freq)\n",
    "#             qtypes_with_correct_debate_mode.append(qid_metrics['qtype'])\n",
    "            accuracy_by_sample_correct_debate_mode.append(\n",
    "                prompt_metrics['num_correct_with_correct_debate_mode'] /\n",
    "                prompt_metrics['num_correct_debate_mode'])\n",
    "        else:\n",
    "            convinced_freqs_with_incorrect_debate_mode.append(convinced_freq)\n",
    "            for qtype in qid_metrics['qtype']:\n",
    "                convinced_freqs_with_incorrect_debate_mode_by_qtype[qtype].append(convinced_freq)\n",
    "#             qtypes_with_incorrect_debate_mode.append(qid_metrics['qtype'])\n",
    "            accuracy_by_sample_incorrect_debate_mode.append(\n",
    "                prompt_metrics['num_correct_with_incorrect_debate_mode'] /\n",
    "                prompt_metrics['num_incorrect_debate_mode'])\n",
    "        convinced_freqs.append(convinced_freq)\n",
    "        for qtype in qid_metrics['qtype']:\n",
    "            convinced_freqs_by_qtype[qtype].append(convinced_freq)\n",
    "#         qtypes.append(qid_metrics['qtype'])\n",
    "\n",
    "# qtypes = np.array(qtypes)\n",
    "# qtypes_with_correct_debate_mode = np.array(qtypes_with_correct_debate_mode)\n",
    "# qtypes_with_incorrect_debate_mode = np.array(qtypes_with_incorrect_debate_mode)\n",
    "\n",
    "# print(accuracy_by_qtype)\n",
    "accuracy_by_qtype = {qtype: (np.array(accuracy_by_qtype[qtype]).mean(), len(accuracy_by_qtype[qtype])) for qtype in question_type_labels}\n",
    "pprint(accuracy_by_qtype)\n",
    "\n",
    "num_evals_by_sample = np.array(num_evals_by_sample)\n",
    "print('Evals per sample:', num_evals_by_sample.mean())\n",
    "print('Fraction insuffient evals:', (num_evals_by_sample < 5).mean())\n",
    "\n",
    "convinced_freqs = np.array(convinced_freqs)\n",
    "print('Convinced:', round(100 * convinced_freqs.mean(), 2), '% (', 100 * convinced_freqs.mean(), ')')\n",
    "convinced_freqs_with_correct_debate_mode = np.array(convinced_freqs_with_correct_debate_mode)\n",
    "print('- Agent is right:', round(100 * convinced_freqs_with_correct_debate_mode.mean(), 2), '% (', 100 * convinced_freqs_with_correct_debate_mode.mean(), ')')\n",
    "convinced_freqs_with_incorrect_debate_mode = np.array(convinced_freqs_with_incorrect_debate_mode)\n",
    "print('- Agent is wrong:', round(100 * convinced_freqs_with_incorrect_debate_mode.mean(), 2), '% (', 100 * convinced_freqs_with_incorrect_debate_mode.mean(), ')')\n",
    "\n",
    "for qtype in question_type_labels:\n",
    "#     print(len(convinced_freqs_by_qtype[qtype]))\n",
    "    convinced_freqs_by_qtype[qtype] = np.array(convinced_freqs_by_qtype[qtype]).mean()\n",
    "    print(len(convinced_freqs_with_correct_debate_mode_by_qtype[qtype]))\n",
    "    convinced_freqs_with_correct_debate_mode_by_qtype[qtype] = np.array(convinced_freqs_with_correct_debate_mode_by_qtype[qtype]).mean()\n",
    "#     print(len(convinced_freqs_with_incorrect_debate_mode_by_qtype[qtype]))\n",
    "    convinced_freqs_with_incorrect_debate_mode_by_qtype[qtype] = np.array(convinced_freqs_with_incorrect_debate_mode_by_qtype[qtype]).mean()\n",
    "\n",
    "accuracy_by_sample = np.array(accuracy_by_sample)\n",
    "print('Accuracy:', round(100 * accuracy_by_sample.mean(), 2), '%')\n",
    "print('Accuracy:', 100 * accuracy_by_sample.mean(), '%')\n",
    "accuracy_by_sample_correct_debate_mode = np.array(accuracy_by_sample_correct_debate_mode)\n",
    "\n",
    "num_target_evals = 5\n",
    "# print('Extra Evals:', round(((100. * (num_evals_by_sample - num_target_evals).sum()) / num_evals_by_sample.sum()), 2), '%')\n",
    "# num_evals_by_sample.sort()\n",
    "# print('Evals per sample distribution:', num_evals_by_sample)\n",
    "# 1.5*3.1*60/(917.5684545454544*26/(20*60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BERT Large': [[False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False],\n",
      "                [False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False],\n",
      "                [False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False],\n",
      "                [False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False,\n",
      "                 False]],\n",
      " 'FastText(S,Q)': array([0., 0., 0., 0., 0.])}\n",
      "***** BERT Large *****\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-952-1105e6805e64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_values\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*****'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*****'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MEAN:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'STD:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'STDERR:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "evals[name] = []\n",
    "for eval_no in range(num_evals):\n",
    "    evals[name].append([convinced_array[eval_no] for convinced_array in convinced_by_sample])\n",
    "\n",
    "evals[name] = 100. * np.array(evals[name]).mean(axis=1)\n",
    "pprint(evals)\n",
    "\n",
    "for n, eval_values in evals.items():\n",
    "    print('*****', n, '*****')\n",
    "    print('MEAN:', round(eval_values.mean(), 1))\n",
    "    print('STD:', round(eval_values.std(), 2))\n",
    "    print('STDERR:', round(eval_values.std() / np.sqrt(eval_values.shape[0]), 2))\n",
    "    print()\n",
    "\n",
    "for n1, eval_values1 in evals.items():\n",
    "    for n2, eval_values2 in evals.items():\n",
    "        print(n1, '/', n2, ':', round(ttest_ind(eval_values1, eval_values2, equal_var=False)[1], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n",
      "80.38\n",
      "76.38\n",
      "86.39\n",
      "84.17\n"
     ]
    }
   ],
   "source": [
    "# print('Accuracy/Num-Samples by Q Type:')\n",
    "if len(accuracy_by_qtype) > 0:\n",
    "    for qtype in question_type_labels:\n",
    "        print(round(100. * accuracy_by_qtype[qtype][0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(100. * convinced_freqs.mean())\n",
    "# print(100. * convinced_freqs_with_correct_debate_mode.mean())\n",
    "# print(100. * convinced_freqs_with_incorrect_debate_mode.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for qtype in question_type_labels:\n",
    "#     print(100. * convinced_freqs[qtypes == qtype].mean(), convinced_freqs[qtypes == qtype].sum())\n",
    "    \n",
    "# for qtype in question_type_labels:\n",
    "#     print(100. * convinced_freqs_with_correct_debate_mode[qtypes_with_correct_debate_mode == qtype].mean(), convinced_freqs_with_correct_debate_mode[qtypes_with_correct_debate_mode == qtype].sum())\n",
    "    \n",
    "# for qtype in question_type_labels:\n",
    "#     print(100. * convinced_freqs_with_incorrect_debate_mode[qtypes_with_incorrect_debate_mode == qtype].mean(), convinced_freqs_with_incorrect_debate_mode[qtypes_with_incorrect_debate_mode == qtype].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.29960317460317\n",
      "38.798363095238095\n",
      "39.854497354497354\n",
      "41.98562443845463\n",
      "39.0029761904762\n",
      "77.77777777777779\n",
      "68.52678571428571\n",
      "73.64197530864197\n",
      "72.51572327044025\n",
      "64.79166666666667\n",
      "29.14021164021164\n",
      "28.888888888888893\n",
      "28.592004703115816\n",
      "31.80892482779275\n",
      "30.406746031746028\n"
     ]
    }
   ],
   "source": [
    "for qtype in question_type_labels:\n",
    "    print(100. * convinced_freqs_by_qtype[qtype])\n",
    "for qtype in question_type_labels:\n",
    "    print(100. * convinced_freqs_with_correct_debate_mode_by_qtype[qtype])\n",
    "for qtype in question_type_labels:\n",
    "    print(100. * convinced_freqs_with_incorrect_debate_mode_by_qtype[qtype])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.87291666666667\n",
      "50.94618055555556\n",
      "53.27473958333333\n",
      "54.11651234567901\n",
      "49.23349056603774\n",
      "41.875\n"
     ]
    }
   ],
   "source": [
    "print(100. * accuracy_by_sample.mean())\n",
    "for qtype in question_type_labels:\n",
    "    print(100. * accuracy_by_qtype[qtype][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

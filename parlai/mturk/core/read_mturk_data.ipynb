{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HIT Files: 277\n",
      "# Passed Test: 105 / 172 = 61.05 %\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "# prompt_type, task_dir = 'context_question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1553733240'  # TFIDF (1)\n",
    "# prompt_type, task_dir = 'context_question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1553790696'  # TFIDF\n",
    "# prompt_type, task_dir = 'context_question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1553901953'  # FastText\n",
    "# prompt_type, task_dir = 'question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1553982706'  # Q-only\n",
    "### Filtered Workers\n",
    "# prompt_type, task_dir = 'quote and question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1554006689'  # TFIDF(Q+O)\n",
    "# prompt_type, task_dir = 'question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1554052233'  # Q-only\n",
    "# prompt_type, task_dir = 'quote and question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1554069931'  # Oracle\n",
    "prompt_type, task_dir = 'quote and question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1554072277'  # SL\n",
    "\n",
    "\n",
    "# Set useful variables\n",
    "num_options = 4\n",
    "options = ['A', 'B', 'C', 'D'][:num_options]\n",
    "debate_mode_to_option = {'Ⅰ': 'A', 'Ⅱ': 'B', 'Ⅲ': 'C', 'Ⅳ': 'D', 'ⅰ': 'A', 'ⅱ': 'B', 'ⅲ': 'C', 'ⅳ': 'D', None: None}\n",
    "\n",
    "# Read HIT data\n",
    "print('# HIT Files:', len(os.listdir(task_dir)))\n",
    "hit_results = []\n",
    "num_passed_test = 0\n",
    "for hit_dir in os.listdir(task_dir):\n",
    "    if hit_dir.startswith('o_'):\n",
    "        continue\n",
    "    num_passed_test += 1\n",
    "    with open(os.path.join(task_dir, hit_dir, 'custom/data.json'), 'r') as file:\n",
    "        hit_results.append(json.load(file))\n",
    "        file.close()\n",
    "if len(os.listdir(task_dir)) != num_passed_test:\n",
    "    num_total_tested = len(os.listdir(task_dir)) - num_passed_test\n",
    "    print('# Passed Test:', num_passed_test, '/', num_total_tested, '=', round((100. * num_passed_test) / num_total_tested, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Time: 655.0 | Acc: 53 | Max Freq: 26.3 | Rate: 8 | Feedback: No need for improvements. Thanks!\n",
      "| Time: 255.7 | Acc: 53 | Max Freq: 31.6 | Rate: 3 | Feedback: Too many questions that made no sense \n",
      "| Time: 238.9 | Acc: 37 | Max Freq: 36.8 | Rate: 4 | Feedback: All good\n",
      "| Time: 745.1 | Acc: 42 | Max Freq: 36.8 | Rate: 2 | Feedback: Provide more context in the passages.\n",
      "| Time: 555.9 | Acc: 58 | Max Freq: 42.1 | Rate: 10 | Feedback: I think everything worked great!\n",
      "| Time: 865.4 | Acc: 58 | Max Freq: 42.1 | Rate: 10 | Feedback: It's interesting overall. Some questions did not make sense, but I am not sure if that's done on purpose\n",
      "| Time: 347.6 | Acc: 68 | Max Freq: 31.6 | Rate: 10 | Feedback: N/A\n",
      "| Time: 479.7 | Acc: 47 | Max Freq: 31.6 | Rate: 10 | Feedback: Nothing to improve.\n",
      "| Time: 524.6 | Acc: 63 | Max Freq: 36.8 | Rate: 10 | Feedback: some of the questions were impossible to answer.  But I knew that in the beginning.\n",
      "| Time: 356.5 | Acc: 63 | Max Freq: 31.6 | Rate: 7 | Feedback: I don't know I liked the task and it was an efficient interface..\n",
      "| Time: 565.0 | Acc: 11 | Max Freq: 26.3 | Rate: 2 | Feedback: questions are hard to guess\n",
      "| Time: 879.7 | Acc: 47 | Max Freq: 31.6 | Rate: 10 | Feedback: I like it how it is.  I don't understand it, but it seemed fun taking it.\n",
      "| Time: 1012.8 | Acc: 65 | Max Freq: 25.0 | Rate: 6 | Feedback: Assure that the provided sentence information relies less on context.\n",
      "| Time: 598.6 | Acc: 50 | Max Freq: 40.0 | Rate: 8 | Feedback: give us a little more to hint at the answer.  a little more to read \n",
      "| Time: 556.6 | Acc: 63 | Max Freq: 31.6 | Rate: 6 | Feedback: you should do one with jokes instead, to give us a laugh,\n",
      "| Time: 593.0 | Acc: 37 | Max Freq: 36.8 | Rate: 2 | Feedback: Make questions coherant\n",
      "| Time: 439.9 | Acc: 68 | Max Freq: 26.3 | Rate: 10 | Feedback: Can't think of anything.\n",
      "| Time: 383.5 | Acc: 70 | Max Freq: 40.0 | Rate: 10 | Feedback: not much i liked the questions fun hit \n",
      "| Time: 437.1 | Acc: 37 | Max Freq: 36.8 | Rate: 8 | Feedback: more context\n",
      "| Time: 546.8 | Acc: 47 | Max Freq: 31.6 | Rate: 10 | Feedback: In the sample questions, give the reason why a certain answer is correct. \n",
      "| Time: 340.0 | Acc: 55 | Max Freq: 35.0 | Rate: 10 | Feedback: not sure\n",
      "| Time: 523.4 | Acc: 63 | Max Freq: 36.8 | Rate: 4 | Feedback: Having the instructions on the side versus on an introductory page is a bit off-putting but I don't know why that is so.\n",
      "| Time: 777.5 | Acc: 53 | Max Freq: 36.8 | Rate: 9 | Feedback: perhaps after we answer, show us the correct answer if we got it wrong\n",
      "| Time: 582.5 | Acc: 42 | Max Freq: 42.1 | Rate: 10 | Feedback: It is good as it already is.\n",
      "| Time: 363.3 | Acc: 50 | Max Freq: 35.0 | Rate: 9 | Feedback: I cannot think of a way to improve it.\n",
      "| Time: 416.6 | Acc: 58 | Max Freq: 31.6 | Rate: 8 | Feedback: n/a\n",
      "| Time: 405.5 | Acc: 55 | Max Freq: 40.0 | Rate: 10 | Feedback: Perhaps give instant feedback if the question is answered correctly or incorrectly.\n",
      "| Time: 351.2 | Acc: 58 | Max Freq: 36.8 | Rate: 10 | Feedback: none\n",
      "| Time: 494.2 | Acc: 58 | Max Freq: 31.6 | Rate: 10 | Feedback: it was very interesting!\n",
      "| Time: 438.8 | Acc: 60 | Max Freq: 35.0 | Rate: 5 | Feedback: Maybe a short note about how abstract some of the quotes are compared to the question, but maybe that's the point. All was fine.\n",
      "| Time: 756.5 | Acc: 58 | Max Freq: 47.4 | Rate: 5 | Feedback: n/a\n",
      "| Time: 593.1 | Acc: 58 | Max Freq: 42.1 | Rate: 5 | Feedback: Not much, it's fine.\n",
      "| Time: 562.9 | Acc: 79 | Max Freq: 36.8 | Rate: 5 | Feedback: There were some typos, but otherwise it was a fun task. \n",
      "| Time: 787.2 | Acc: 47 | Max Freq: 42.1 | Rate: 5 | Feedback: I don't know\n",
      "| Time: 541.5 | Acc: 58 | Max Freq: 36.8 | Rate: 10 | Feedback: Remove nonsense questions\n",
      "| Time: 329.6 | Acc: 53 | Max Freq: 31.6 | Rate: 10 | Feedback: some of the quotes are a big vague for the choices given.\n",
      "| Time: 582.0 | Acc: 63 | Max Freq: 31.6 | Rate: 5 | Feedback: There are probably a few too many questions.\n",
      "| Time: 374.2 | Acc: 47 | Max Freq: 47.4 | Rate: 10 | Feedback: Make it possible to just click on the right answer instead of selecting from a dropdown.\n",
      "| Time: 433.4 | Acc: 58 | Max Freq: 42.1 | Rate: 7 | Feedback: I don't have any suggestions\n",
      "| Time: 254.4 | Acc: 53 | Max Freq: 31.6 | Rate: 10 | Feedback: n/a\n",
      "| Time: 315.5 | Acc: 63 | Max Freq: 47.4 | Rate: 10 | Feedback: This was fun. I have nothing to add. \n",
      "| Time: 1053.9 | Acc: 50 | Max Freq: 40.0 | Rate: 9 | Feedback: You could maybe make some of the questions less ambiguous.\n",
      "| Time: 467.3 | Acc: 58 | Max Freq: 42.1 | Rate: 8 | Feedback: I don't  know\n",
      "| Time: 312.4 | Acc: 55 | Max Freq: 40.0 | Rate: 8 | Feedback: Explain what is actually going on better!\n",
      "| Time: 477.9 | Acc: 53 | Max Freq: 47.4 | Rate: 8 | Feedback: Provide more logical answers.   Some seemed nonsensical.\n",
      "| Time: 536.1 | Acc: 42 | Max Freq: 36.8 | Rate: 6 | Feedback: Clearer prompts.\n",
      "| Time: 338.4 | Acc: 21 | Max Freq: 36.8 | Rate: 4 | Feedback: no\n",
      "| Time: 1180.5 | Acc: 53 | Max Freq: 31.6 | Rate: 9 | Feedback: Give more clues\n",
      "| Time: 393.4 | Acc: 42 | Max Freq: 36.8 | Rate: 10 | Feedback: it's good how it is\n",
      "| Time: 545.0 | Acc: 68 | Max Freq: 52.6 | Rate: 9 | Feedback: You've got some strange spacing going on prior to the appearance of an apostrophe in your text. Not sure how easy it is to fix the regex formatting, but things like \"can't\" are appearing as \"ca n't\" and it's a bit jarring to read.\n",
      "| Time: 255.2 | Acc: 47 | Max Freq: 31.6 | Rate: 9 | Feedback: More practice\n",
      "| Time: 580.7 | Acc: 42 | Max Freq: 31.6 | Rate: 8 | Feedback: Nothing comes to mind, the instructions were very clear and the layout of the task was easy to read.\n",
      "| Time: 414.0 | Acc: 74 | Max Freq: 36.8 | Rate: 10 | Feedback: Maybe make the questions a bit clearer at points \n",
      "| Time: 529.1 | Acc: 47 | Max Freq: 42.1 | Rate: 6 | Feedback: Make it mobile compatible\n",
      "| Time: 593.6 | Acc: 21 | Max Freq: 36.8 | Rate: 10 | Feedback: Is really interesting like it is!\n",
      "| Time: 788.6 | Acc: 60 | Max Freq: 45.0 | Rate: 7 | Feedback: I don't know.\n",
      "| Time: 402.3 | Acc: 35 | Max Freq: 30.0 | Rate: 7 | Feedback: No comment\n",
      "| Time: 388.8 | Acc: 40 | Max Freq: 45.0 | Rate: 10 | Feedback: Not needed\n",
      "| Time: 384.7 | Acc: 58 | Max Freq: 31.6 | Rate: 9 | Feedback: I think it was pretty great.\n",
      "| Time: 755.5 | Acc: 32 | Max Freq: 31.6 | Rate: 10 | Feedback: GIVE SO E CLUES\n",
      "| Time: 734.4 | Acc: 37 | Max Freq: 36.8 | Rate: 3 | Feedback: remove the ambiguity\n",
      "| Time: 506.4 | Acc: 32 | Max Freq: 31.6 | Rate: 10 | Feedback: so much fun, dont touch it\n",
      "| Time: 815.7 | Acc: 58 | Max Freq: 31.6 | Rate: 10 | Feedback: I'm not sure I keep thinking I was correct every  question because I saw the word correct. Would I change the way you have things probably not.. \n",
      "| Time: 327.0 | Acc: 58 | Max Freq: 47.4 | Rate: 10 | Feedback: I think if the User interface was more dynamic (in terms of color and presentation) it would be good.\n",
      "| Time: 385.4 | Acc: 79 | Max Freq: 36.8 | Rate: 10 | Feedback: I thought it was really fun. It would be great if it was a batch. An improvement would be to say if the answer was right or wrong after each question, and if wrong, show the correct answer. \n",
      "| Time: 616.8 | Acc: 50 | Max Freq: 35.0 | Rate: 6 | Feedback: I'd like to see all questions that are possible to answer.\n",
      "| Time: 575.0 | Acc: 37 | Max Freq: 42.1 | Rate: 7 | Feedback: Remove ambiguity or live with less accuracy\n",
      "| Time: 464.5 | Acc: 55 | Max Freq: 45.0 | Rate: 8 | Feedback: Can't think of anything\n",
      "| Time: 680.3 | Acc: 74 | Max Freq: 42.1 | Rate: 10 | Feedback: more questions\n",
      "| Time: 656.4 | Acc: 47 | Max Freq: 31.6 | Rate: 8 | Feedback: No suggestions\n",
      "| Time: 916.4 | Acc: 42 | Max Freq: 36.8 | Rate: 10 | Feedback: Make the bonus easier to get. \n",
      "| Time: 451.3 | Acc: 37 | Max Freq: 36.8 | Rate: 6 | Feedback: Making better sense of the questions.\n",
      "| Time: 299.2 | Acc: 65 | Max Freq: 30.0 | Rate: 9 | Feedback: Not sure, very neat\n",
      "| Time: 448.6 | Acc: 63 | Max Freq: 26.3 | Rate: 10 | Feedback: I liked it as is.  It pays well for the time put in.\n",
      "| Time: 317.2 | Acc: 84 | Max Freq: 31.6 | Rate: 9 | Feedback: I think it is good the way it is.\n",
      "| Time: 643.5 | Acc: 63 | Max Freq: 31.6 | Rate: 10 | Feedback: I don't think you can   unless you let me do another one\n",
      "| Time: 354.8 | Acc: 47 | Max Freq: 36.8 | Rate: 10 | Feedback: It was great as is.\n",
      "| Time: 706.2 | Acc: 37 | Max Freq: 31.6 | Rate: 10 | Feedback: n/a\n",
      "| Time: 413.1 | Acc: 53 | Max Freq: 31.6 | Rate: 8 | Feedback: No suggestions\n",
      "| Time: 270.5 | Acc: 53 | Max Freq: 31.6 | Rate: 6 | Feedback: I enjoyed it. I can't think of anything you could do - it was fine like it was.\n",
      "| Time: 560.4 | Acc: 32 | Max Freq: 31.6 | Rate: 10 | Feedback: make it shorter\n",
      "| Time: 508.4 | Acc: 16 | Max Freq: 36.8 | Rate: 5 | Feedback: not sure\n",
      "| Time: 822.6 | Acc: 45 | Max Freq: 35.0 | Rate: 6 | Feedback: Make the questions a little more coherent \n",
      "| Time: 402.3 | Acc: 75 | Max Freq: 30.0 | Rate: 10 | Feedback: Some of the passages were very unclear\n",
      "| Time: 615.9 | Acc: 55 | Max Freq: 50.0 | Rate: 7 | Feedback: make it 15 questions\n",
      "| Time: 356.1 | Acc: 63 | Max Freq: 42.1 | Rate: 10 | Feedback: There is nothing I see that can be done to improve it.\n",
      "| Time: 483.6 | Acc: 47 | Max Freq: 36.8 | Rate: 9 | Feedback: I cannot think of anything really. Maybe a bit more of an explanation and a few more practice runs? \n",
      "| Time: 308.8 | Acc: 63 | Max Freq: 47.4 | Rate: 7 | Feedback: There were some spelling and grammar errors that were a little annoying. Also, some sentences were very hard to infer from, but I think that's part of the study. I had fun!\n",
      "| Time: 321.2 | Acc: 63 | Max Freq: 36.8 | Rate: 10 | Feedback: Add more examples. \n",
      "| Time: 647.8 | Acc: 79 | Max Freq: 31.6 | Rate: 10 | Feedback: at the end, show me the ones that I missed and what the correct answer was.\n",
      "| Time: 528.1 | Acc: 53 | Max Freq: 47.4 | Rate: 10 | Feedback: nothing\n",
      "| Time: 508.0 | Acc: 63 | Max Freq: 36.8 | Rate: 8 | Feedback: No suggestions, everything was smooth and clear.\n",
      "| Time: 434.4 | Acc: 42 | Max Freq: 42.1 | Rate: 1 | Feedback: Have better answers\n",
      "| Time: 655.6 | Acc: 42 | Max Freq: 36.8 | Rate: 10 | Feedback: increase pay\n",
      "| Time: 386.4 | Acc: 42 | Max Freq: 31.6 | Rate: 6 | Feedback: Explain that some of the questions are impossible to answer!\n",
      "| Time: 583.8 | Acc: 21 | Max Freq: 42.1 | Rate: 10 | Feedback: It's Great and fun.\n",
      "| Time: 485.9 | Acc: 68 | Max Freq: 31.6 | Rate: 9 | Feedback: It was interesting as is.\n",
      "| Time: 561.8 | Acc: 32 | Max Freq: 36.8 | Rate: 10 | Feedback: I don't think that there is anything that you could do to improve it. I did not do very well but that is not something that you could change and even though my score was terrible, it was still a lot of fun and different than most tasks I work on\n",
      "| Time: 833.0 | Acc: 60 | Max Freq: 50.0 | Rate: 9 | Feedback: I'm not sure. It was interesting.\n",
      "| Time: 488.4 | Acc: 58 | Max Freq: 36.8 | Rate: 10 | Feedback: for me, question 2 and question 1 were identical at first, and I only saw the actual question 2 after I thought I had answered it, so be sure that questions are displaying correctly.\n",
      "| Time: 482.0 | Acc: 65 | Max Freq: 45.0 | Rate: 10 | Feedback: I can't think of anything. It was easy to understand and fun to complete.\n",
      "REJECTED: 0\n",
      "INCOMPLETE: 4\n",
      "VALID: 101\n",
      "Median Question Duration: 22.367\n",
      "Median Worker Duration: 506.41200000000003\n",
      "Median Worker Accuracy: 0.5263157894736842\n",
      "Median Max Response Freq: 0.3684210526315789\n"
     ]
    }
   ],
   "source": [
    "num_valid_hits, num_rejected_hits, num_incomplete_hits = 0, 0, 0\n",
    "metrics = {}\n",
    "task_ratings = {i: 0 for i in range(11)}\n",
    "durations = []\n",
    "durations_by_worker = []\n",
    "accuracy_by_worker = {}\n",
    "max_response_freqs = []\n",
    "\n",
    "for hit_result in hit_results:\n",
    "    if ((len(hit_result['reject_reasons']) > 0) or\n",
    "        (len(hit_result['block_reasons']) > 0)):\n",
    "        num_rejected_hits += 1\n",
    "        print('| reject_reasons:', hit_result['reject_reasons'], '| block_reasons:', hit_result['block_reasons'])\n",
    "        continue\n",
    "    elif hit_result['feedback'] is None:\n",
    "        num_incomplete_hits += 1\n",
    "        continue\n",
    "    \n",
    "    num_valid_hits += 1\n",
    "    if (hit_result['task_rating'] is not None) and (hit_result['task_rating'].isdigit()):\n",
    "        task_ratings[int(hit_result['task_rating'])] += 1\n",
    "    for qtype, qtype_accuracy in hit_result['accuracy'].items():\n",
    "        accuracy_by_worker[qtype] = accuracy_by_worker.get(qtype, []) + [qtype_accuracy]\n",
    "    \n",
    "    hit_durations = []\n",
    "    response_option_counts = {option: 0 for option in options}\n",
    "    responses = []\n",
    "    for prompt in hit_result['data']:\n",
    "        qid = prompt['sample']['qid']\n",
    "        model_stance = debate_mode_to_option[prompt['sample']['debate_mode']]\n",
    "        answer = prompt['sample']['eval_labels'][0]\n",
    "        human_correct = (prompt['response'] == answer)\n",
    "        assert answer in options, 'Answer must be in options.'\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if qid not in metrics:\n",
    "            metrics[qid] = {\n",
    "                option: {\n",
    "                    'num': 0,\n",
    "                    'num_correct': 0,\n",
    "                    'num_correct_debate_mode': 0,\n",
    "                    'num_incorrect_debate_mode': 0,\n",
    "                    'num_correct_with_correct_debate_mode': 0,\n",
    "                    'num_correct_with_incorrect_debate_mode': 0,\n",
    "                    'num_debate_mode_responses': 0,\n",
    "                }\n",
    "                for option in ([None] if model_stance is None else options)\n",
    "            }\n",
    "            metrics[qid]['answer'] = answer\n",
    "        prompt_metrics = metrics[qid][model_stance]\n",
    "        prompt_metrics['num'] += 1\n",
    "        prompt_metrics['num_correct'] += human_correct\n",
    "        if model_stance == answer:\n",
    "            prompt_metrics['num_correct_with_correct_debate_mode'] += human_correct\n",
    "            prompt_metrics['num_correct_debate_mode'] += 1\n",
    "        else:\n",
    "            prompt_metrics['num_correct_with_incorrect_debate_mode'] += human_correct\n",
    "            prompt_metrics['num_incorrect_debate_mode'] += 1\n",
    "        prompt_metrics['num_debate_mode_responses'] += (prompt['response'] == model_stance)\n",
    "        \n",
    "        hit_durations.append(prompt['duration'] / 1000.)\n",
    "        response_option_counts[prompt['response']] += 1\n",
    "        responses.append(prompt['response'])\n",
    "    duration = np.sum(np.array(hit_durations))\n",
    "    durations_by_worker.append(duration)\n",
    "    durations += hit_durations\n",
    "    response_options_array = np.array(list(response_option_counts.values()))\n",
    "    response_options_array = response_options_array / response_options_array.sum()\n",
    "    max_response_freq = response_options_array.max()\n",
    "    max_response_freqs.append(max_response_freq)\n",
    "    print('| Time:', round(duration, 1),\n",
    "          '| Acc:', round(100 * hit_result['accuracy'][prompt_type]),\n",
    "          '| Max Freq:', round(100 * max_response_freq, 1),\n",
    "          '| Rate:', hit_result['task_rating'],\n",
    "          '| Feedback:', hit_result['feedback'])\n",
    "\n",
    "durations = np.array(durations)\n",
    "durations_by_worker = np.array(durations_by_worker)\n",
    "max_response_freqs = np.array(max_response_freqs)\n",
    "durations.sort()\n",
    "durations_by_worker.sort()\n",
    "max_response_freqs.sort()\n",
    "for qtype in accuracy_by_worker:\n",
    "    accuracy_by_worker[qtype] = np.array(accuracy_by_worker[qtype])\n",
    "    accuracy_by_worker[qtype].sort()\n",
    "print('REJECTED:', num_rejected_hits)\n",
    "print('INCOMPLETE:', num_incomplete_hits)\n",
    "print('VALID:', num_valid_hits)\n",
    "print('Median Question Duration:', np.median(durations))\n",
    "print('Median Worker Duration:', np.median(durations_by_worker))\n",
    "print('Median Worker Accuracy:', np.median(accuracy_by_worker[prompt_type]))\n",
    "print('Median Max Response Freq:', np.median(max_response_freqs))\n",
    "# pprint(hit_results[0]['data'][0])\n",
    "# pprint(hit_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evals per sample: 5.049479166666667\n",
      "Fraction insuffient evals: 0.0\n",
      "Convinced: 42.46 %\n",
      "- Correct debater: 75.73 %\n",
      "- Incorrect debater: 31.37 %\n",
      "Accuracy: 52.21 %\n",
      "- Correct debater: 75.73 %\n",
      "- Incorrect debater: 44.38 %\n",
      "Extra Evals: 0.98 %\n",
      "Evals per sample distribution: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n"
     ]
    }
   ],
   "source": [
    "accuracy_by_sample = []\n",
    "accuracy_by_sample_correct_debate_mode = []\n",
    "accuracy_by_sample_incorrect_debate_mode = []\n",
    "convinced_freqs = []\n",
    "convinced_freqs_with_correct_debate_mode = []\n",
    "convinced_freqs_with_incorrect_debate_mode = []\n",
    "num_evals_by_sample = []\n",
    "for qid, qid_metrics in metrics.items():\n",
    "    answer = metrics[qid]['answer']\n",
    "    for model_stance, prompt in qid_metrics.items():\n",
    "        if not (model_stance in [None] + options):\n",
    "            continue\n",
    "\n",
    "        # Q-only stats\n",
    "        prompt_metrics = metrics[qid][model_stance]\n",
    "        num_evals_by_sample.append(prompt_metrics['num'])\n",
    "        accuracy_by_sample.append(prompt_metrics['num_correct'] / prompt_metrics['num'])\n",
    "        if model_stance is None:\n",
    "            continue\n",
    "        \n",
    "        # Debater stats\n",
    "        convinced_freq = prompt_metrics['num_debate_mode_responses'] / prompt_metrics['num']\n",
    "        if model_stance == answer:\n",
    "            convinced_freqs_with_correct_debate_mode.append(convinced_freq)\n",
    "            accuracy_by_sample_correct_debate_mode.append(\n",
    "                prompt_metrics['num_correct_with_correct_debate_mode'] /\n",
    "                prompt_metrics['num_correct_debate_mode'])\n",
    "        else:\n",
    "            convinced_freqs_with_incorrect_debate_mode.append(convinced_freq)\n",
    "            accuracy_by_sample_incorrect_debate_mode.append(\n",
    "                prompt_metrics['num_correct_with_incorrect_debate_mode'] /\n",
    "                prompt_metrics['num_incorrect_debate_mode'])\n",
    "        convinced_freqs.append(convinced_freq)\n",
    "\n",
    "num_evals_by_sample = np.array(num_evals_by_sample)\n",
    "print('Evals per sample:', num_evals_by_sample.mean())\n",
    "print('Fraction insuffient evals:', (num_evals_by_sample < 5).mean())\n",
    "\n",
    "convinced_freqs = np.array(convinced_freqs)\n",
    "print('Convinced:', round(100 * convinced_freqs.mean(), 2), '%')\n",
    "convinced_freqs_with_correct_debate_mode = np.array(convinced_freqs_with_correct_debate_mode)\n",
    "print('- Correct debater:', round(100 * convinced_freqs_with_correct_debate_mode.mean(), 2), '%')\n",
    "convinced_freqs_with_incorrect_debate_mode = np.array(convinced_freqs_with_incorrect_debate_mode)\n",
    "print('- Incorrect debater:', round(100 * convinced_freqs_with_incorrect_debate_mode.mean(), 2), '%')\n",
    "\n",
    "accuracy_by_sample = np.array(accuracy_by_sample)\n",
    "print('Accuracy:', round(100 * accuracy_by_sample.mean(), 2), '%')\n",
    "accuracy_by_sample_correct_debate_mode = np.array(accuracy_by_sample_correct_debate_mode)\n",
    "print('- Correct debater:', round(100 * accuracy_by_sample_correct_debate_mode.mean(), 2), '%')\n",
    "accuracy_by_sample_incorrect_debate_mode = np.array(accuracy_by_sample_incorrect_debate_mode)\n",
    "print('- Incorrect debater:', round(100 * accuracy_by_sample_incorrect_debate_mode.mean(), 2), '%')\n",
    "\n",
    "num_target_evals = 5\n",
    "print('Extra Evals:', round(((100. * (num_evals_by_sample - num_target_evals).sum()) / num_evals_by_sample.sum()), 2), '%')\n",
    "num_evals_by_sample.sort()\n",
    "print('Evals per sample distribution:', num_evals_by_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPS: 31.68\n"
     ]
    }
   ],
   "source": [
    "def nps(task_ratings):\n",
    "    num_ratings = sum(list(task_ratings.values()))\n",
    "    if num_ratings == 0:\n",
    "        return None\n",
    "\n",
    "    sum_ratings = 0\n",
    "    for score, num_raters in task_ratings.items():\n",
    "        if score >= 9:\n",
    "            sum_ratings += num_raters\n",
    "        elif score <= 6:\n",
    "            sum_ratings -= num_raters\n",
    "    return round(100 * (sum_ratings / float(num_ratings)), 2)\n",
    "\n",
    "print('NPS:', nps(task_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5263157894736842"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(accuracy_by_worker['quote and question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

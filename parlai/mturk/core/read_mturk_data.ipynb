{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HIT Files: 132\n",
      "# Passed Test: 34 / 98 = 34.69 %\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "task_dir = '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_'\n",
    "\n",
    "### RACE: Unfiltered Workers\n",
    "# prompt_type, task_id = 'question', '1553982706'  # Q-only\n",
    "# prompt_type, task_id = 'context_question', 1553790696  # TFIDF\n",
    "# prompt_type, task_id = 'context_question', 1553901953  # FastText\n",
    "### RACE: Filtered Workers\n",
    "# prompt_type, task_id = 'question', '1554052233'  # Q-only\n",
    "# prompt_type, task_id = 'quote and question', 1554006689  # TFIDF(Q+O)\n",
    "# prompt_type, task_id = 'quote and question', 1554130485  # TFIDF(O)\n",
    "# prompt_type, task_id = 'quote and question', 1554069931  # Search\n",
    "# prompt_type, task_id = 'quote and question', 1554072277  # SL\n",
    "# prompt_type, task_id = 'quote and question', 1554132868  # SL-Influence\n",
    "# dataset = 'race'\n",
    "\n",
    "### DREAM\n",
    "dataset = 'dream'\n",
    "# prompt_type, task_id = 'question', 1554582693  # Q-only\n",
    "# prompt_type, task_id = 'quote and question', 1554596686  # TFIDF(Q+O)\n",
    "# prompt_type, task_id = 'quote and question', 1554587404  # TFIDF(O)\n",
    "# prompt_type, task_id = 'quote and question', 1554662280  # FastText(O)\n",
    "# prompt_type, task_id = 'quote and question', 1554675304  # Search\n",
    "# prompt_type, task_id = 'quote and question', 1554685131  # SL\n",
    "# prompt_type, task_id = 'quote and question', 1554692472  # SL-Sents\n",
    "# prompt_type, task_id = 'quote and question', 1554729998  # SL-Sents-Influence\n",
    "# prompt_type, task_id = 'quote and question', 1555333992  # SL-Theory-of-Mind\n",
    "## All answers at once\n",
    "# prompt_type, task_id = 'question, answers, and quotes', 1555707929  # TFIDF(O)\n",
    "# prompt_type, task_id = 'question, answers, and quotes', 1555722489  # Search\n",
    "prompt_type, task_id = 'question and quotes', 1555789302  # SL\n",
    "\n",
    "# split = 'middle'\n",
    "split = None\n",
    "\n",
    "# Set useful variables\n",
    "task_dir += str(task_id)\n",
    "num_options = 3 if dataset == 'dream' else 4\n",
    "options = ['A', 'B', 'C', 'D'][:num_options]\n",
    "debate_mode_to_option = {'Ⅰ': 'A', 'Ⅱ': 'B', 'Ⅲ': 'C', 'Ⅳ': 'D', 'ⅰ': 'A', 'ⅱ': 'B', 'ⅲ': 'C', 'ⅳ': 'D', None: None}\n",
    "\n",
    "# Read HIT data\n",
    "print('# HIT Files:', len(os.listdir(task_dir)))\n",
    "hit_results = []\n",
    "num_passed_test = 0\n",
    "for hit_dir in os.listdir(task_dir):\n",
    "    if hit_dir.startswith('o_'):\n",
    "        continue\n",
    "    num_passed_test += 1\n",
    "    with open(os.path.join(task_dir, hit_dir, 'custom/data.json'), 'r') as file:\n",
    "        hit_results.append(json.load(file))\n",
    "        file.close()\n",
    "if len(os.listdir(task_dir)) != num_passed_test:\n",
    "    num_total_tested = len(os.listdir(task_dir)) - num_passed_test\n",
    "    print('# Passed Test:', num_passed_test, '/', num_total_tested, '=', round((100. * num_passed_test) / num_total_tested, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.709  7.208 29.393 20.374 15.629  8.965 12.496 28.015 14.957 12.516\n",
      "  8.2   19.473 15.736 16.859 10.372 19.74  10.425  8.739 10.94  29.596]\n",
      "| Time: 13.8 | Acc: 85 | Max Freq: 35.0 | Rate: 8 | Feedback: A couple of them were pretty impossible | Quote Rating: 9 | Quote Desc: Interesting\n",
      "[77.276 51.117 33.66  24.222 93.05  35.05  13.801 33.338 30.877 29.096\n",
      " 30.975 52.833 13.62  42.506 67.475 26.976 27.185 26.089 33.053 42.753]\n",
      "| Time: 33.2 | Acc: 80 | Max Freq: 50.0 | Rate: 10 | Feedback: I honestly think the set up is really good the way it is and does not need improved. The practice questions helped a lot in understanding the task. | Quote Rating: 8 | Quote Desc: They were helpful overall in figuring out which answer was best. The passage quotes were concise and informative.\n",
      "[20.652 12.837  9.077 12.312 12.004  9.241  7.124  7.497  8.581 10.245\n",
      " 12.425 10.398  7.317  4.607  8.445  6.366  6.163  4.728  7.822  3.345]\n",
      "| Time: 8.5 | Acc: 50 | Max Freq: 55.0 | Rate: 2 | Feedback: make the questions more understandable | Quote Rating: 1 | Quote Desc: made no sense\n",
      "[11.    11.266 11.257  9.736 10.753 21.968 11.694 11.716  9.118  9.561\n",
      " 18.229 11.41   7.281 22.863 28.972 15.33  13.275  7.366 25.462 31.669]\n",
      "| Time: 11.6 | Acc: 90 | Max Freq: 40.0 | Rate: 6 | Feedback: No ideas | Quote Rating: 8 | Quote Desc: Not always well written in terms of grammar. Occasionally they lacked enough information. \n",
      "[60.967 52.763 13.339 36.325 14.479 20.573 16.806 38.619 26.94  38.571\n",
      " 12.296 18.641 25.462 29.936 14.334 32.381 15.163 13.092 36.279 22.512]\n",
      "| Time: 24.0 | Acc: 75 | Max Freq: 55.0 | Rate: 7 | Feedback: maybe one or two difficult practice ones | Quote Rating: 7 | Quote Desc: Some were the same with different answers.\n",
      "[118.616   8.169   9.856   8.484  33.308  10.28   10.81    7.879  22.834\n",
      "  10.958  11.851  18.029  11.807  18.423  11.485   6.487  13.48    6.222\n",
      "  14.464   8.108]\n",
      "| Time: 11.2 | Acc: 75 | Max Freq: 55.0 | Rate: 10 | Feedback: Weed out the instances were the correct answer is simply a guess at most. | Quote Rating: 7 | Quote Desc: I thought most of them were rather discernable but a few were practically impossible.\n",
      "[29.095 42.209 15.322 26.195 20.138 23.612 35.456 28.035 47.654 14.251\n",
      " 19.353 27.895 24.131 15.65  28.647 13.949 25.489 19.93  13.592 28.011]\n",
      "| Time: 24.8 | Acc: 90 | Max Freq: 35.0 | Rate: 10 | Feedback: Maybe a little more information on the really vague ones. I don't really like to guess without having more information. But maybe that was the point. | Quote Rating: 10 | Quote Desc: Pretty good in fact, there were only a few that were so vague that I had to guess.\n",
      "[166.5    13.373  25.825  44.069  48.511  20.559  14.336  41.328  19.532\n",
      "  14.273  19.342  15.984  39.65   37.531  31.011  34.526  17.195   8.904\n",
      "  10.8    16.728]\n",
      "| Time: 20.0 | Acc: 70 | Max Freq: 50.0 | Rate: 7 | Feedback: Some of the questions need to be rewritten. | Quote Rating: 8 | Quote Desc: Most of them were easy to follow but a few left me confused on how to answer.\n",
      "[22.205 13.741 27.753 15.513 21.58  27.534  5.551 25.635 16.087 16.103\n",
      " 10.574 20.75  23.269 16.221 17.226 51.593 10.742  6.711 10.522 18.099]\n",
      "| Time: 16.7 | Acc: 75 | Max Freq: 35.0 | Rate: 7 | Feedback: Make the situation more clear with less ambiguous quotes. | Quote Rating: 5 | Quote Desc: Some of them were ambiguous as best. \n",
      "[28.999 17.865 31.876 30.194 21.843 18.811 16.308 26.705 20.345 13.568\n",
      " 22.64  14.96  15.724 25.831 29.913 17.021 24.664 14.684 18.554 21.432]\n",
      "| Time: 20.9 | Acc: 80 | Max Freq: 35.0 | Rate: 10 | Feedback: I think its good as is | Quote Rating: 8 | Quote Desc: It was like a little puzzle\n",
      "[52.573 41.67  44.432 21.471 44.418 35.807 18.369 23.381 31.043 26.404\n",
      " 14.122 57.557 18.607 36.364 51.41  15.528 38.547 11.332 26.945 34.675]\n",
      "| Time: 32.9 | Acc: 70 | Max Freq: 40.0 | Rate: 9 | Feedback: nothing, it was fun | Quote Rating: 8 | Quote Desc: Tricky but have to key in on certain words that identify.\n",
      "[30.387 29.702 11.244 29.747 14.19  26.032 13.003 25.606 33.069 21.289\n",
      " 25.339 29.435 20.626 23.144 26.397  9.315 35.715 19.363 14.088 16.148]\n",
      "| Time: 24.2 | Acc: 65 | Max Freq: 40.0 | Rate: 8 | Feedback: Make the directions a little more clear. The task was very confusing at first. | Quote Rating: 7 | Quote Desc: Most of the provided passages left a lot to be inferred. In a majority of cases though the information provided was helpful in making  an educated guess.\n",
      "[16.393 30.94  34.792 20.102 15.787 23.301 18.044 28.544 34.42  18.089\n",
      " 13.483 18.763 17.667 10.254 12.721 18.333 11.514 10.658 12.821 27.888]\n",
      "| Time: 18.1 | Acc: 90 | Max Freq: 70.0 | Rate: 10 | Feedback: Nothing...it was actually fun | Quote Rating: 9 | Quote Desc: If you read them carefully, they could direct you to the answer\n",
      "[53.432 19.561 27.872 25.383 24.384 21.537 30.273 11.541 32.873 50.295\n",
      " 37.672 43.881 13.426 27.025 53.    54.65  22.294 11.382 15.453 18.774]\n",
      "| Time: 26.2 | Acc: 90 | Max Freq: 55.0 | Rate: 10 | Feedback: I really didn't understand the instructions until I played.  I am not sure how to make the instructions more clear though.  I had to actually do it to understand. | Quote Rating: 9 | Quote Desc: They were tricky and most were like a puzzle.  Some seemed obvious but not many. \n",
      "[76.159 24.639 32.95  42.116 58.93  21.911 35.077 13.922 60.796 25.66\n",
      " 26.421 16.008 23.761 43.19  22.143 25.247 20.575 15.274 21.089 32.976]\n",
      "| Time: 25.5 | Acc: 75 | Max Freq: 50.0 | Rate: 3 | Feedback: A little more clarity on what is going on.  Why are you asking me questions you know the answer to, but have made difficult to answer. | Quote Rating: 5 | Quote Desc: Some provide clues, some do not.\n",
      "[10.482 20.299 14.538 16.043 10.761 10.159 16.921 12.063 16.563 12.572\n",
      " 12.689  8.02   7.986  7.64   6.7    7.442 13.44   6.103  4.781 13.247]\n",
      "| Time: 11.4 | Acc: 85 | Max Freq: 50.0 | Rate: 10 | Feedback: It is pretty neat as it is.  | Quote Rating: 9 | Quote Desc: MOst of them made sense and it wasn't too hard to guess once I got the hang of it. \n",
      "[20.598 25.138 82.012 26.975 23.341 28.155 44.039 19.748 63.333 33.246\n",
      " 43.031 50.719 33.765  9.039 24.684 14.747 21.682 26.8   25.279 19.48 ]\n",
      "| Time: 26.0 | Acc: 70 | Max Freq: 45.0 | Rate: 5 | Feedback: Less questions for the time | Quote Rating: 8 | Quote Desc: They were helpful\n",
      "[38.715 38.919 21.549 21.036 23.1   26.804 15.419 21.675 14.5   16.681\n",
      " 37.299 24.303  9.876 24.251 39.799 15.435 20.243  8.049 10.788 18.277]\n",
      "| Time: 21.3 | Acc: 80 | Max Freq: 45.0 | Rate: 5 | Feedback: It is definitely not 11 minutes long as stated.  Much longer :( | Quote Rating: 6 | Quote Desc: Some were relevant, others left no clue as to the answer.\n",
      "A3DQ5VQMUOSZ35 3QY5DC2MXSZ8EWDINLDLEW14TJ1FUP | reject_reasons: ['median_duration = 6869'] | block_reasons: [] | bonus_reasons: []\n",
      "[35.456 20.624 18.619 22.855 14.698 32.45  32.905  9.858  9.359  3.099\n",
      "  1.798  6.869  3.235  3.881  3.69   2.537  3.933  2.393  3.457  2.057]\n",
      "| Time: 5.4 | Acc: 40 | Max Freq: 40.0 | Rate: 7 | Feedback: less ambiguity | Quote Rating: 6 | Quote Desc: ambiguous\n",
      "[55.065 14.94  13.457  9.215 12.783 15.626 36.32   7.394 47.658 15.645\n",
      " 21.33  19.787 25.336 35.991 20.766  6.455 44.879 11.549 31.448 13.041]\n",
      "| Time: 17.7 | Acc: 85 | Max Freq: 55.0 | Rate: 10 | Feedback: There were two questions, which I felt was impossible to answer, and my only option was to guess blindly. | Quote Rating: 8 | Quote Desc: Most of them were pretty simple and I was able to derive enough information to answer the questions\n",
      "[30.62  17.258 13.638 24.038 27.068 27.09  37.809 12.942 68.761 16.992\n",
      " 20.96  16.539 32.394 41.639 29.437  8.713 21.048 12.759 24.974 15.251]\n",
      "| Time: 22.5 | Acc: 70 | Max Freq: 45.0 | Rate: 8 | Feedback: more examples | Quote Rating: 7 | Quote Desc: challenging\n",
      "[21.529  7.791 14.641 10.079 10.558  7.983  8.676  9.563 15.059 19.652\n",
      "  6.814  8.026 19.097 17.231 16.343 17.229 13.104  8.608 13.749 21.875]\n",
      "| Time: 13.4 | Acc: 75 | Max Freq: 45.0 | Rate: 7 | Feedback: Make sure you provide a way to reconnect if you get disconnected.  | Quote Rating: 7 | Quote Desc: A little confusing at times, but once I figured it out, it wasn't too difficult. There were a few that really made me raise an eyebrow, such as the one about the hotel making the top ten list. \n",
      "[25.468  9.93  13.558 13.737 11.83  11.61   7.049 30.071 10.588 14.093\n",
      "  6.982  8.847 29.309 14.359 14.094 14.107 14.584 14.931  6.509 11.252]\n",
      "| Time: 13.6 | Acc: 80 | Max Freq: 40.0 | Rate: 7 | Feedback: No idea, there was one question where I had to guess because there was no answer that could be given by what you provided | Quote Rating: 7 | Quote Desc: Some of them were difficult to decipher \n",
      "[25.148 16.357 13.039 25.361 26.01  11.455 13.149 10.812 11.153  7.899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10.305 29.596 12.264 41.943 21.053  9.591 11.772  7.471  7.774  9.578]\n",
      "| Time: 12.0 | Acc: 70 | Max Freq: 50.0 | Rate: 10 | Feedback: I found this to be enjoyable just the way it is. Thank you! | Quote Rating: 7 | Quote Desc: They were helpful about 75% of the time.  For a couple questions there was no help and it was a complete guess.  For one example(14), the quotes alone indicated two correct answers, of which I picked one that must have been invalidated elsewhere in the paragraph.\n",
      "[15.359 18.591  9.476 19.093  8.182 10.688 11.084 14.588 18.361 12.346\n",
      " 10.44  20.772 16.208  8.871 12.64   9.447 21.405 11.564  9.785 15.687]\n",
      "| Time: 12.5 | Acc: 75 | Max Freq: 40.0 | Rate: 0 | Feedback: The interface was a bit glitchy at times and slow to load | Quote Rating: 5 | Quote Desc: Short, without much relevant information to the question\n",
      "[ 22.336 122.982  45.753  72.634  46.478  35.19   77.269  34.388  39.978\n",
      " 136.835  21.359  36.638  32.543  28.013  79.506  13.765  28.899  27.43\n",
      "  28.477  21.144]\n",
      "| Time: 34.8 | Acc: 70 | Max Freq: 55.0 | Rate: 10 | Feedback: n/a | Quote Rating: 10 | Quote Desc: pretty fun\n",
      "[ 12.493  13.403  15.716  18.925  15.402 101.535  10.274  14.877  12.641\n",
      "   8.356  23.826  79.998  24.071  17.038  18.69   10.055   7.763   9.559\n",
      "   8.01   17.531]\n",
      "| Time: 15.1 | Acc: 75 | Max Freq: 60.0 | Rate: 5 | Feedback: Spell check the answers and possibly lighten the ambiguity of the choices? | Quote Rating: 6 | Quote Desc: Like they were put through a computer, some of the quotes had typos and didn't make sense grammatically.\n",
      "[39.128 37.765 25.81  32.12  19.924 41.595 70.078 33.724 24.769 23.962\n",
      " 18.612 32.043 20.216  9.975 31.595 17.326 50.25   8.301 16.971 24.96 ]\n",
      "| Time: 25.4 | Acc: 65 | Max Freq: 40.0 | Rate: 7 | Feedback: Maybe make some problems that are more easier to solve or require less cognitive ability. | Quote Rating: 6 | Quote Desc: Some of them are straight foward but others are harder to deceifer. \n",
      "[23.663 29.271 12.349 32.069 14.99  19.879 27.586 36.744 59.089 18.124\n",
      " 17.536 25.733 32.7   19.06  19.306  9.798 21.244 18.288 15.08  19.508]\n",
      "| Time: 19.7 | Acc: 65 | Max Freq: 40.0 | Rate: 6 | Feedback: You could narrow the questions down to those that can actually be answered properly from the text | Quote Rating: 7 | Quote Desc: Most of them could indicate the problem, but a few of them were too vague. Those were the ones I got wrong.\n",
      "REJECTED: 1\n",
      "INCOMPLETE: 5\n",
      "VALID: 29\n",
      "Median Question Duration: 18.63\n",
      "Median Worker Duration: 19.6935\n",
      "Median Worker Accuracy: 0.75\n",
      "Median Max Response Freq: 0.45\n",
      "Quote Rating: | Mean: 7.17 | Median: 7.0 | Std: 1.78\n"
     ]
    }
   ],
   "source": [
    "num_valid_hits, num_rejected_hits, num_incomplete_hits = 0, 0, 0\n",
    "metrics = {}\n",
    "task_ratings = {i: 0 for i in range(11)}\n",
    "quote_ratings = []\n",
    "durations = []\n",
    "durations_by_worker = []\n",
    "accuracy_by_worker = {}\n",
    "max_response_freqs = []\n",
    "worker_ids = []\n",
    "\n",
    "for hit_result in hit_results:\n",
    "    if ((len(hit_result['reject_reasons']) > 0) or\n",
    "        (len(hit_result['block_reasons']) > 0)):\n",
    "        num_rejected_hits += 1\n",
    "        print(hit_result['worker_id'], hit_result['assignment_id'],\n",
    "              '| reject_reasons:', hit_result['reject_reasons'],\n",
    "              '| block_reasons:', hit_result['block_reasons'],\n",
    "              '| bonus_reasons: ' + str(hit_result['bonus_reasons']) if 'bonus_reasons' in hit_result else '')\n",
    "    elif hit_result['feedback'] is None:\n",
    "        num_incomplete_hits += 1\n",
    "        continue\n",
    "    \n",
    "    worker_ids.append(hit_result['worker_id'])\n",
    "#     if hit_result['worker_id'] == 'A1PUHCEBSOWETV':\n",
    "#         print('*** A1PUHCEBSOWETV ***', hit_result['assignment_id'])\n",
    "    num_valid_hits += 1\n",
    "    if (hit_result['task_rating'] is not None) and (hit_result['task_rating'].isdigit()):\n",
    "        task_ratings[int(hit_result['task_rating'])] += 1\n",
    "    if (hit_result['quote_rating'] is not None) and (hit_result['quote_rating'].isdigit()):\n",
    "        quote_ratings.append(int(hit_result['quote_rating']))\n",
    "    for qtype, qtype_accuracy in hit_result['accuracy'].items():\n",
    "        accuracy_by_worker[qtype] = accuracy_by_worker.get(qtype, []) + [qtype_accuracy]\n",
    "    \n",
    "    hit_durations = []\n",
    "    response_option_counts = {option: 0 for option in options}\n",
    "    responses = []\n",
    "    for prompt in hit_result['data']:\n",
    "        qid = prompt['sample']['qid']\n",
    "        if (split is not None) and (split not in qid):\n",
    "            continue\n",
    "        model_stance = debate_mode_to_option[prompt['sample']['debate_mode']]\n",
    "        answer = prompt['sample']['eval_labels'][0]\n",
    "        human_correct = (prompt['response'] == answer)\n",
    "        assert answer in options, 'Answer must be in options.'\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if qid not in metrics:\n",
    "            metrics[qid] = {\n",
    "                option: {\n",
    "                    'num': 0,\n",
    "                    'num_correct': 0,\n",
    "                    'num_correct_debate_mode': 0,\n",
    "                    'num_incorrect_debate_mode': 0,\n",
    "                    'num_correct_with_correct_debate_mode': 0,\n",
    "                    'num_correct_with_incorrect_debate_mode': 0,\n",
    "                    'num_debate_mode_responses': 0,\n",
    "                }\n",
    "                for option in ([None] if model_stance is None else options)\n",
    "            }\n",
    "            metrics[qid]['answer'] = answer\n",
    "        prompt_metrics = metrics[qid][model_stance]\n",
    "        prompt_metrics['num'] += 1\n",
    "        prompt_metrics['num_correct'] += human_correct\n",
    "        if model_stance == answer:\n",
    "            prompt_metrics['num_correct_with_correct_debate_mode'] += human_correct\n",
    "            prompt_metrics['num_correct_debate_mode'] += 1\n",
    "        else:\n",
    "            prompt_metrics['num_correct_with_incorrect_debate_mode'] += human_correct\n",
    "            prompt_metrics['num_incorrect_debate_mode'] += 1\n",
    "        prompt_metrics['num_debate_mode_responses'] += (prompt['response'] == model_stance)\n",
    "        \n",
    "        hit_durations.append(prompt['duration'] / 1000.)\n",
    "        response_option_counts[prompt['response']] += 1\n",
    "        responses.append(prompt['response'])\n",
    "    print(np.array(hit_durations))\n",
    "    duration = np.median(np.array(hit_durations))\n",
    "    durations_by_worker.append(duration)\n",
    "    durations += hit_durations\n",
    "    response_options_array = np.array(list(response_option_counts.values()))\n",
    "    response_options_array = response_options_array / response_options_array.sum()\n",
    "    max_response_freq = response_options_array.max()\n",
    "    max_response_freqs.append(max_response_freq)\n",
    "    print('| Time:', round(duration, 1),\n",
    "          '| Acc:', round(100 * hit_result['accuracy'][prompt_type]),\n",
    "          '| Max Freq:', round(100 * max_response_freq, 1),\n",
    "          '| Rate:', hit_result['task_rating'],\n",
    "          '| Feedback:', hit_result['feedback'],\n",
    "          '| Quote Rating:', None if 'quote_rating' not in hit_result else hit_result['quote_rating'], \n",
    "          '| Quote Desc:', None if 'quote_description' not in hit_result else hit_result['quote_description'])\n",
    "\n",
    "quote_ratings = np.array(quote_ratings)\n",
    "durations = np.array(durations)\n",
    "durations_by_worker = np.array(durations_by_worker)\n",
    "max_response_freqs = np.array(max_response_freqs)\n",
    "durations.sort()\n",
    "durations_by_worker.sort()\n",
    "max_response_freqs.sort()\n",
    "for qtype in accuracy_by_worker:\n",
    "    accuracy_by_worker[qtype] = np.array(accuracy_by_worker[qtype])\n",
    "    accuracy_by_worker[qtype].sort()\n",
    "print('REJECTED:', num_rejected_hits)\n",
    "print('INCOMPLETE:', num_incomplete_hits)\n",
    "print('VALID:', num_valid_hits)\n",
    "print('Median Question Duration:', np.median(durations))\n",
    "print('Median Worker Duration:', np.median(durations_by_worker))\n",
    "print('Median Worker Accuracy:', np.median(accuracy_by_worker[prompt_type]))\n",
    "print('Median Max Response Freq:', np.median(max_response_freqs))\n",
    "print('Quote Rating:',\n",
    "      '| Mean:', round(quote_ratings.mean(), 2),\n",
    "      '| Median:', round(np.median(quote_ratings), 2),\n",
    "      '| Std:', round(np.std(quote_ratings), 2))\n",
    "# pprint(hit_results[0]['data'][0])\n",
    "# pprint(hit_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evals per sample: 5.8\n",
      "Fraction insuffient evals: 0.2\n",
      "Convinced: nan %\n",
      "- Correct debater: nan %\n",
      "- Incorrect debater: nan %\n",
      "Accuracy: 75.17 %\n",
      "- Correct debater: nan %\n",
      "- Incorrect debater: nan %\n",
      "Extra Evals: 13.79 %\n",
      "Evals per sample distribution: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:42: RuntimeWarning: Mean of empty slice.\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: RuntimeWarning: Mean of empty slice.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:46: RuntimeWarning: Mean of empty slice.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: RuntimeWarning: Mean of empty slice.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: RuntimeWarning: Mean of empty slice.\n"
     ]
    }
   ],
   "source": [
    "accuracy_by_sample = []\n",
    "accuracy_by_sample_correct_debate_mode = []\n",
    "accuracy_by_sample_incorrect_debate_mode = []\n",
    "convinced_freqs = []\n",
    "convinced_freqs_with_correct_debate_mode = []\n",
    "convinced_freqs_with_incorrect_debate_mode = []\n",
    "num_evals_by_sample = []\n",
    "for qid, qid_metrics in metrics.items():\n",
    "    answer = metrics[qid]['answer']\n",
    "    for model_stance, prompt in qid_metrics.items():\n",
    "        if not (model_stance in [None] + options):\n",
    "            continue\n",
    "\n",
    "        # Q-only stats\n",
    "        prompt_metrics = metrics[qid][model_stance]\n",
    "        num_evals_by_sample.append(prompt_metrics['num'])\n",
    "        accuracy_by_sample.append(prompt_metrics['num_correct'] / prompt_metrics['num'])\n",
    "        if model_stance is None:\n",
    "            continue\n",
    "        \n",
    "        # Debater stats\n",
    "        convinced_freq = prompt_metrics['num_debate_mode_responses'] / prompt_metrics['num']\n",
    "        if model_stance == answer:\n",
    "            convinced_freqs_with_correct_debate_mode.append(convinced_freq)\n",
    "            accuracy_by_sample_correct_debate_mode.append(\n",
    "                prompt_metrics['num_correct_with_correct_debate_mode'] /\n",
    "                prompt_metrics['num_correct_debate_mode'])\n",
    "        else:\n",
    "            convinced_freqs_with_incorrect_debate_mode.append(convinced_freq)\n",
    "            accuracy_by_sample_incorrect_debate_mode.append(\n",
    "                prompt_metrics['num_correct_with_incorrect_debate_mode'] /\n",
    "                prompt_metrics['num_incorrect_debate_mode'])\n",
    "        convinced_freqs.append(convinced_freq)\n",
    "\n",
    "worker_ids = set(worker_ids)\n",
    "        \n",
    "num_evals_by_sample = np.array(num_evals_by_sample)\n",
    "print('Evals per sample:', num_evals_by_sample.mean())\n",
    "print('Fraction insuffient evals:', (num_evals_by_sample < 5).mean())\n",
    "\n",
    "convinced_freqs = np.array(convinced_freqs)\n",
    "print('Convinced:', round(100 * convinced_freqs.mean(), 2), '%')\n",
    "convinced_freqs_with_correct_debate_mode = np.array(convinced_freqs_with_correct_debate_mode)\n",
    "print('- Correct debater:', round(100 * convinced_freqs_with_correct_debate_mode.mean(), 2), '%')\n",
    "convinced_freqs_with_incorrect_debate_mode = np.array(convinced_freqs_with_incorrect_debate_mode)\n",
    "print('- Incorrect debater:', round(100 * convinced_freqs_with_incorrect_debate_mode.mean(), 2), '%')\n",
    "\n",
    "accuracy_by_sample = np.array(accuracy_by_sample)\n",
    "print('Accuracy:', round(100 * accuracy_by_sample.mean(), 2), '%')\n",
    "accuracy_by_sample_correct_debate_mode = np.array(accuracy_by_sample_correct_debate_mode)\n",
    "print('- Correct debater:', round(100 * accuracy_by_sample_correct_debate_mode.mean(), 2), '%')\n",
    "accuracy_by_sample_incorrect_debate_mode = np.array(accuracy_by_sample_incorrect_debate_mode)\n",
    "print('- Incorrect debater:', round(100 * accuracy_by_sample_incorrect_debate_mode.mean(), 2), '%')\n",
    "\n",
    "num_target_evals = 5\n",
    "print('Extra Evals:', round(((100. * (num_evals_by_sample - num_target_evals).sum()) / num_evals_by_sample.sum()), 2), '%')\n",
    "num_evals_by_sample.sort()\n",
    "print('Evals per sample distribution:', num_evals_by_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPS, Mean: (10.34, 7.38)\n"
     ]
    }
   ],
   "source": [
    "def nps(task_ratings):\n",
    "    num_ratings = sum(list(task_ratings.values()))\n",
    "    if num_ratings == 0:\n",
    "        return None\n",
    "\n",
    "    nps_sum_ratings = 0\n",
    "    sum_ratings = 0\n",
    "    for score, num_raters in task_ratings.items():\n",
    "        sum_ratings += num_raters * score\n",
    "        if score >= 9:\n",
    "            nps_sum_ratings += num_raters\n",
    "        elif score <= 6:\n",
    "            nps_sum_ratings -= num_raters\n",
    "    return round(100 * (nps_sum_ratings / float(num_ratings)), 2), round((sum_ratings / float(num_ratings)), 2)\n",
    "\n",
    "print('NPS, Mean:', nps(task_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.401 ,  8.513 , 11.2215, 11.412 , 11.552 , 12.018 , 12.493 ,\n",
       "       13.4265, 13.6475, 13.833 , 15.1395, 16.7235, 17.716 , 18.0665,\n",
       "       19.6935, 20.0455, 20.8885, 21.2925, 22.543 , 23.987 , 24.2415,\n",
       "       24.81  , 25.385 , 25.4535, 26.0395, 26.204 , 32.859 , 33.1955,\n",
       "       34.789 ])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations_by_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.746551724137931"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracy_by_worker[prompt_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1, 1: 0, 2: 1, 3: 1, 4: 0, 5: 3, 6: 2, 7: 7, 8: 3, 9: 1, 10: 10}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HIT Files: 326\n",
      "# Passed Test: 114 / 212 = 53.77 %\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "# prompt_type, task_dir = 'question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1553982706'  # Q-only\n",
    "# prompt_type, task_dir = 'context_question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1553790696'  # TFIDF\n",
    "# prompt_type, task_dir = 'context_question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1553901953'  # FastText\n",
    "### Filtered Workers\n",
    "# prompt_type, task_dir = 'question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1554052233'  # Q-only\n",
    "# prompt_type, task_dir = 'quote and question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1554006689'  # TFIDF(Q+O)\n",
    "# prompt_type, task_dir = 'quote and question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1554130485'  # TFIDF(O)\n",
    "# prompt_type, task_dir = 'quote and question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1554069931'  # Oracle\n",
    "# prompt_type, task_dir = 'quote and question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1554072277'  # SL\n",
    "prompt_type, task_dir = 'quote and question', '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_1554132868'  # SL-Influence\n",
    "\n",
    "split = 'middle'\n",
    "# split = None\n",
    "\n",
    "# Set useful variables\n",
    "num_options = 4\n",
    "options = ['A', 'B', 'C', 'D'][:num_options]\n",
    "debate_mode_to_option = {'Ⅰ': 'A', 'Ⅱ': 'B', 'Ⅲ': 'C', 'Ⅳ': 'D', 'ⅰ': 'A', 'ⅱ': 'B', 'ⅲ': 'C', 'ⅳ': 'D', None: None}\n",
    "\n",
    "# Read HIT data\n",
    "print('# HIT Files:', len(os.listdir(task_dir)))\n",
    "hit_results = []\n",
    "num_passed_test = 0\n",
    "for hit_dir in os.listdir(task_dir):\n",
    "    if hit_dir.startswith('o_'):\n",
    "        continue\n",
    "    num_passed_test += 1\n",
    "    with open(os.path.join(task_dir, hit_dir, 'custom/data.json'), 'r') as file:\n",
    "        hit_results.append(json.load(file))\n",
    "        file.close()\n",
    "if len(os.listdir(task_dir)) != num_passed_test:\n",
    "    num_total_tested = len(os.listdir(task_dir)) - num_passed_test\n",
    "    print('# Passed Test:', num_passed_test, '/', num_total_tested, '=', round((100. * num_passed_test) / num_total_tested, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Time: 16.7 | Acc: 53 | Max Freq: 30.0 | Rate: 1 | Feedback: lower the rate required for the bonus. I used to be in Mensa and if I only got 53% I bet very few people got the bonus.\n",
      "| Time: 13.6 | Acc: 47 | Max Freq: 30.0 | Rate: 10 | Feedback: Not sure anything can be done to improve it, although some of the questions didn't really make sense.\n",
      "| Time: 33.0 | Acc: 53 | Max Freq: 40.0 | Rate: 8 | Feedback: Nothing, that was fun!\n",
      "| Time: 21.3 | Acc: 58 | Max Freq: 40.0 | Rate: 10 | Feedback: n/a\n",
      "| Time: 11.9 | Acc: 37 | Max Freq: 40.0 | Rate: 10 | Feedback: it's fine as it is\n",
      "| Time: 17.2 | Acc: 58 | Max Freq: 40.0 | Rate: 8 | Feedback: was actually a fun task. and good pay too\n",
      "| Time: 16.8 | Acc: 53 | Max Freq: 40.0 | Rate: 10 | Feedback: Can't think of anything\n",
      "| Time: 17.7 | Acc: 53 | Max Freq: 30.0 | Rate: 8 | Feedback: I think it is meant to be difficult, so I would not make a change.\n",
      "| Time: 21.9 | Acc: 35 | Max Freq: 45.5 | Rate: 10 | Feedback: Explain the sentences in more simple terms.\n",
      "| Time: 13.2 | Acc: 74 | Max Freq: 40.0 | Rate: 8 | Feedback: have a button for questions that dont have a right answer\n",
      "| Time: 18.2 | Acc: 35 | Max Freq: 45.5 | Rate: 7 | Feedback: nothing\n",
      "| Time: 16.6 | Acc: 47 | Max Freq: 60.0 | Rate: 6 | Feedback: it seems pretty straight forward\n",
      "| reject_reasons: ['median_duration = 3569'] | block_reasons: []\n",
      "| Time: 3.7 | Acc: 20 | Max Freq: 45.5 | Rate: 9 | Feedback: nice\n",
      "| Time: 14.3 | Acc: 55 | Max Freq: 45.5 | Rate: 8 | Feedback: I see no improvements that are needed.\n",
      "| Time: 11.1 | Acc: 53 | Max Freq: 50.0 | Rate: 6 | Feedback: SOME OF THEM WERE VERY HARD TO FIGURE OUT \n",
      "| Time: 21.8 | Acc: 42 | Max Freq: 40.0 | Rate: 6 | Feedback: Replace the dropdown with radio buttons for our answers.\n",
      "| Time: 21.5 | Acc: 74 | Max Freq: 30.0 | Rate: 10 | Feedback: Make it a little longer. Great practice in comprehension.\n",
      "| Time: 17.6 | Acc: 53 | Max Freq: 60.0 | Rate: 7 | Feedback: Give a little more info in the passage. But I know that's the whole point is to not  give much info.\n",
      "| Time: 13.0 | Acc: 45 | Max Freq: 36.4 | Rate: 10 | Feedback: Not sure!  It was fun though!  Thank you :-)\n",
      "| Time: 16.4 | Acc: 47 | Max Freq: 40.0 | Rate: 9 | Feedback: It's tough to determine the right answers\n",
      "| Time: 13.0 | Acc: 37 | Max Freq: 40.0 | Rate: 7 | Feedback: dont know\n",
      "| Time: 10.5 | Acc: 53 | Max Freq: 40.0 | Rate: 10 | Feedback: Give more information about the passage to make a better guess.\n",
      "| Time: 14.9 | Acc: 63 | Max Freq: 50.0 | Rate: 7 | Feedback: Nothing, this is a great task.\n",
      "| Time: 15.2 | Acc: 63 | Max Freq: 60.0 | Rate: 8 | Feedback: progress bar\n",
      "| Time: 15.8 | Acc: 47 | Max Freq: 30.0 | Rate: 7 | Feedback: there were some questions that were very difficult because there was very little context.\n",
      "| Time: 22.1 | Acc: 55 | Max Freq: 45.5 | Rate: 10 | Feedback: I think it's good as is.\n",
      "| Time: 26.0 | Acc: 65 | Max Freq: 45.5 | Rate: 10 | Feedback: I can't think of a way to improve it.  It was tough with the limited information on some of the quotes, but I know that's part of the experiment.  Thank you. \n",
      "| reject_reasons: ['median_duration = 4523'] | block_reasons: []\n",
      "| Time: 2.7 | Acc: 21 | Max Freq: 40.0 | Rate: 1 | Feedback: i dont know\n",
      "| Time: 10.5 | Acc: 58 | Max Freq: 40.0 | Rate: 8 | Feedback: Not sure. A counter for questions remaining maybe?\n",
      "| Time: 15.3 | Acc: 68 | Max Freq: 50.0 | Rate: 10 | Feedback: unsure, sorry!\n",
      "| Time: 16.0 | Acc: 74 | Max Freq: 40.0 | Rate: 7 | Feedback: adding a little bit of hint\n",
      "| Time: 19.7 | Acc: 60 | Max Freq: 36.4 | Rate: 10 | Feedback: It was fun. No improvement needed.\n",
      "| Time: 12.2 | Acc: 58 | Max Freq: 40.0 | Rate: 7 | Feedback: The pay was fair, the layout was well done I honestly can't think of anything to change.\n",
      "| Time: 23.7 | Acc: 47 | Max Freq: 30.0 | Rate: 0 | Feedback: Don't know\n",
      "| Time: 33.8 | Acc: 42 | Max Freq: 40.0 | Rate: 10 | Feedback: Nothing really, it's just my own perpective I guess which lead me to wrong answers.\n",
      "| Time: 24.9 | Acc: 53 | Max Freq: 30.0 | Rate: 7 | Feedback: I don't see a way. It's already fair.\n",
      "| Time: 14.8 | Acc: 58 | Max Freq: 50.0 | Rate: 9 | Feedback: I don't know.\n",
      "| Time: 14.3 | Acc: 42 | Max Freq: 60.0 | Rate: 9 | Feedback: I think that it is fine as it is.\n",
      "| Time: 26.8 | Acc: 58 | Max Freq: 30.0 | Rate: 10 | Feedback: don't know\n",
      "| Time: 13.4 | Acc: 53 | Max Freq: 30.0 | Rate: 8 | Feedback: N/A\n",
      "| Time: 35.7 | Acc: 42 | Max Freq: 40.0 | Rate: 8 | Feedback: Make it easier LOL\n",
      "| Time: 11.6 | Acc: 42 | Max Freq: 50.0 | Rate: 5 | Feedback: Noting, it works well\n",
      "| Time: 16.3 | Acc: 40 | Max Freq: 36.4 | Rate: 6 | Feedback: Some of the questions and answers are irrelevant to one another, also one question did not have any passage at all, I just had to choose an option. \n",
      "| Time: 18.5 | Acc: 40 | Max Freq: 27.3 | Rate: 10 | Feedback: I don't know.\n",
      "| Time: 14.6 | Acc: 63 | Max Freq: 40.0 | Rate: 1 | Feedback: I don't know, but I felt anxious about getting the wrong answer.\n",
      "| Time: 16.4 | Acc: 47 | Max Freq: 40.0 | Rate: 10 | Feedback: I like it the way it is. \n",
      "| Time: 24.4 | Acc: 60 | Max Freq: 27.3 | Rate: 0 | Feedback: I have no complaints, it was fine as is.\n",
      "| Time: 23.6 | Acc: 68 | Max Freq: 30.0 | Rate: 10 | Feedback: It was random so I don't have an answer...\n",
      "| Time: 16.1 | Acc: 55 | Max Freq: 36.4 | Rate: 5 | Feedback: explain that many tasks require guessing\n",
      "| Time: 11.8 | Acc: 32 | Max Freq: 50.0 | Rate: 9 | Feedback: Nothing to improve. It was easy to understand the directions and easy to answer the questions provided.\n",
      "| Time: 12.8 | Acc: 37 | Max Freq: 30.0 | Rate: 8 | Feedback: i dont know\n",
      "| Time: 6.1 | Acc: 26 | Max Freq: 40.0 | Rate: 10 | Feedback: more context, knowing whether we got it right or wrong so we can revise our method\n",
      "| Time: 18.2 | Acc: 42 | Max Freq: 50.0 | Rate: 10 | Feedback: If you're looking for guesses than I have no suggestions. If you're looking for more logical answers than make the questions more logical.\n",
      "| Time: 15.0 | Acc: 74 | Max Freq: 30.0 | Rate: 8 | Feedback: There seemed to be some grammar mistakes that made things confusing, but other than that it was fun.\n",
      "| Time: 11.8 | Acc: 58 | Max Freq: 30.0 | Rate: 9 | Feedback: Nothing really comes to mind. Some of these were really hard though!\n",
      "| Time: 11.0 | Acc: 42 | Max Freq: 50.0 | Rate: 10 | Feedback: I thought some of the quotes were really hard.\n",
      "| Time: 19.7 | Acc: 58 | Max Freq: 40.0 | Rate: 9 | Feedback: More cowbell.\n",
      "| Time: 19.8 | Acc: 47 | Max Freq: 50.0 | Rate: 7 | Feedback: So many of the answers don't make sense. \n",
      "| Time: 15.8 | Acc: 42 | Max Freq: 50.0 | Rate: 7 | Feedback: More context on the questions\n",
      "| Time: 13.5 | Acc: 32 | Max Freq: 40.0 | Rate: 5 | Feedback: Improve the animation and the colors\n",
      "| Time: 48.6 | Acc: 47 | Max Freq: 30.0 | Rate: 9 | Feedback: Need More like this\n",
      "| Time: 14.2 | Acc: 63 | Max Freq: 40.0 | Rate: 7 | Feedback: Make it easier.\n",
      "| Time: 12.9 | Acc: 42 | Max Freq: 60.0 | Rate: 2 | Feedback: Have more questions that have answers that make sense.  It was really hard to try and guess with nothing to go on.\n",
      "| Time: 11.7 | Acc: 47 | Max Freq: 60.0 | Rate: 8 | Feedback: add more of a timer\n",
      "| Time: 20.3 | Acc: 32 | Max Freq: 40.0 | Rate: 8 | Feedback: by improving the questions type\n",
      "| Time: 15.7 | Acc: 26 | Max Freq: 90.0 | Rate: 9 | Feedback: Better connection. It gets disconnected a lot and the window keeps fluctuating or bouncing (shaking?).\n",
      "| Time: 20.9 | Acc: 63 | Max Freq: 40.0 | Rate: 9 | Feedback: Some questions could have a little more reference material. \n",
      "| Time: 48.1 | Acc: 58 | Max Freq: 70.0 | Rate: 10 | Feedback: I can't see anything that I would change.\n",
      "| Time: 18.9 | Acc: 58 | Max Freq: 40.0 | Rate: 10 | Feedback: give more examples\n",
      "| Time: 12.3 | Acc: 55 | Max Freq: 45.5 | Rate: 5 | Feedback: Have a progress bar\n",
      "| Time: 26.3 | Acc: 53 | Max Freq: 30.0 | Rate: 9 | Feedback: feedback on the task, maybe I would have changed my strategy and got the 2% needed  for the bonus\n",
      "| Time: 21.6 | Acc: 53 | Max Freq: 30.0 | Rate: 8 | Feedback: It is fine just the way it is\n",
      "| Time: 20.6 | Acc: 47 | Max Freq: 60.0 | Rate: 8 | Feedback: N/A\n",
      "| Time: 22.9 | Acc: 63 | Max Freq: 30.0 | Rate: 10 | Feedback: i thought it was perfect!! loved the practice questions that really gave a good idea for how the task would go. \n",
      "| Time: 7.9 | Acc: 53 | Max Freq: 30.0 | Rate: 10 | Feedback: Fix the spelling mistakes. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Time: 17.5 | Acc: 53 | Max Freq: 50.0 | Rate: 8 | Feedback: Some of the statements are pure guesswork, maybe make the samples a bit more challenging.\n",
      "| Time: 22.2 | Acc: 53 | Max Freq: 30.0 | Rate: 10 | Feedback: It would be nice to see the correct answers at some point.\n",
      "| Time: 20.1 | Acc: 63 | Max Freq: 40.0 | Rate: 8 | Feedback: It's fine as it is. It was interesting.\n",
      "| Time: 10.6 | Acc: 63 | Max Freq: 40.0 | Rate: 3 | Feedback: Some of the questions just didn't make sense.\n",
      "| Time: 16.1 | Acc: 45 | Max Freq: 36.4 | Rate: 9 | Feedback: there was one question that had no quote at all\n",
      "| Time: 7.8 | Acc: 74 | Max Freq: 50.0 | Rate: 5 | Feedback: Na\n",
      "| Time: 11.4 | Acc: 32 | Max Freq: 50.0 | Rate: 5 | Feedback: Let participants know whether or not they got the correct answer right away.\n",
      "| Time: 18.0 | Acc: 53 | Max Freq: 40.0 | Rate: 3 | Feedback: Better pay\n",
      "| Time: 24.9 | Acc: 53 | Max Freq: 30.0 | Rate: 8 | Feedback: I am not sure how to improve it.\n",
      "| Time: 19.7 | Acc: 58 | Max Freq: 50.0 | Rate: 7 | Feedback: have a question counter so you know what number you're on\n",
      "| Time: 17.2 | Acc: 53 | Max Freq: 40.0 | Rate: 6 | Feedback: Provide more clear instructions\n",
      "| Time: 21.3 | Acc: 42 | Max Freq: 50.0 | Rate: 5 | Feedback: I think it was straight forward. Everything was clear. \n",
      "| Time: 11.4 | Acc: 58 | Max Freq: 30.0 | Rate: 5 | Feedback: it Is good\n",
      "| reject_reasons: ['median_duration = 1865'] | block_reasons: ['median_duration = 1865']\n",
      "| Time: 2.0 | Acc: 21 | Max Freq: 30.0 | Rate: 7 | Feedback: add some animation colors\n",
      "| Time: 16.1 | Acc: 53 | Max Freq: 50.0 | Rate: 10 | Feedback: less vague\n",
      "| Time: 23.1 | Acc: 21 | Max Freq: 50.0 | Rate: 7 | Feedback: Add more comprehensible stem.\n",
      "| Time: 11.7 | Acc: 60 | Max Freq: 54.5 | Rate: 6 | Feedback: everything seemed fine as is\n",
      "| Time: 25.2 | Acc: 40 | Max Freq: 45.5 | Rate: 8 | Feedback: 7\n",
      "| Time: 14.6 | Acc: 55 | Max Freq: 27.3 | Rate: 7 | Feedback: I can't think of any improvements. It was fine. Maybe some more examples in the instructions.\n",
      "| Time: 12.4 | Acc: 50 | Max Freq: 36.4 | Rate: 10 | Feedback: Nothing it was good to me.\n",
      "| Time: 10.6 | Acc: 63 | Max Freq: 50.0 | Rate: 6 | Feedback: less questions\n",
      "| Time: 21.1 | Acc: 37 | Max Freq: 30.0 | Rate: 10 | Feedback: It's fine\n",
      "| Time: 16.3 | Acc: 32 | Max Freq: 60.0 | Rate: 10 | Feedback: It's perfect already.\n",
      "| Time: 9.9 | Acc: 32 | Max Freq: 70.0 | Rate: 4 | Feedback: The clues shouldn't be so random\n",
      "| Time: 23.4 | Acc: 47 | Max Freq: 30.0 | Rate: 10 | Feedback: As an English major, I know some of these passages do not give enough information to match any of the answers given, to choose from so it's hard to \"get them right.\" That's pretty disheartening, especially for someone like me, who has high reading comprehension. \n",
      "| Time: 39.9 | Acc: 74 | Max Freq: 40.0 | Rate: 9 | Feedback: I think the task is well done.\n",
      "| Time: 16.7 | Acc: 58 | Max Freq: 50.0 | Rate: 5 | Feedback: I don't know\n",
      "| Time: 30.8 | Acc: 53 | Max Freq: 50.0 | Rate: 10 | Feedback: the task is okay.\n",
      "| Time: 12.8 | Acc: 63 | Max Freq: 30.0 | Rate: 10 | Feedback: I don't think you can. It was fun. \n",
      "| Time: 26.8 | Acc: 63 | Max Freq: 30.0 | Rate: 7 | Feedback: No suggestions.\n",
      "| Time: 7.2 | Acc: 53 | Max Freq: 40.0 | Rate: 5 | Feedback: Pick slightly longer passages to get a bit more information on some of the questions.\n",
      "| Time: 11.9 | Acc: 55 | Max Freq: 36.4 | Rate: 10 | Feedback: I don't have any suggestions for improving the task. \n",
      "| reject_reasons: ['median_duration = 2127'] | block_reasons: ['median_duration = 2127']\n",
      "| Time: 2.1 | Acc: 30 | Max Freq: 27.3 | Rate: 10 | Feedback: The task is also improved\n",
      "| Time: 18.4 | Acc: 75 | Max Freq: 45.5 | Rate: 9 | Feedback: hmmm, nothing immediately pops out at me. The task flowed smoothly.\n",
      "| Time: 13.7 | Acc: 65 | Max Freq: 27.3 | Rate: 10 | Feedback: Everything was great.\n",
      "| Time: 11.6 | Acc: 63 | Max Freq: 30.0 | Rate: 7 | Feedback: I'm not sure. Maybe upping the pay a little.\n",
      "REJECTED: 4\n",
      "INCOMPLETE: 3\n",
      "VALID: 111\n",
      "Median Question Duration: 15.9985\n",
      "Median Worker Duration: 16.328\n",
      "Median Worker Accuracy: 0.5263157894736842\n",
      "Median Max Response Freq: 0.4\n",
      "'A3CTXWISODY7D8'\n"
     ]
    }
   ],
   "source": [
    "num_valid_hits, num_rejected_hits, num_incomplete_hits = 0, 0, 0\n",
    "metrics = {}\n",
    "task_ratings = {i: 0 for i in range(11)}\n",
    "durations = []\n",
    "durations_by_worker = []\n",
    "accuracy_by_worker = {}\n",
    "max_response_freqs = []\n",
    "worker_ids = []\n",
    "\n",
    "for hit_result in hit_results:\n",
    "    if ((len(hit_result['reject_reasons']) > 0) or\n",
    "        (len(hit_result['block_reasons']) > 0)):\n",
    "        num_rejected_hits += 1\n",
    "        print('| reject_reasons:', hit_result['reject_reasons'], '| block_reasons:', hit_result['block_reasons'])\n",
    "#         continue\n",
    "    elif hit_result['feedback'] is None:\n",
    "        num_incomplete_hits += 1\n",
    "        continue\n",
    "    \n",
    "    worker_ids.append(hit_result['worker_id'])\n",
    "    num_valid_hits += 1\n",
    "    if (hit_result['task_rating'] is not None) and (hit_result['task_rating'].isdigit()):\n",
    "        task_ratings[int(hit_result['task_rating'])] += 1\n",
    "    for qtype, qtype_accuracy in hit_result['accuracy'].items():\n",
    "        accuracy_by_worker[qtype] = accuracy_by_worker.get(qtype, []) + [qtype_accuracy]\n",
    "    \n",
    "    hit_durations = []\n",
    "    response_option_counts = {option: 0 for option in options}\n",
    "    responses = []\n",
    "    for prompt in hit_result['data']:\n",
    "        qid = prompt['sample']['qid']\n",
    "        if (split is not None) and (split not in qid):\n",
    "            continue\n",
    "        model_stance = debate_mode_to_option[prompt['sample']['debate_mode']]\n",
    "        answer = prompt['sample']['eval_labels'][0]\n",
    "        human_correct = (prompt['response'] == answer)\n",
    "        assert answer in options, 'Answer must be in options.'\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if qid not in metrics:\n",
    "            metrics[qid] = {\n",
    "                option: {\n",
    "                    'num': 0,\n",
    "                    'num_correct': 0,\n",
    "                    'num_correct_debate_mode': 0,\n",
    "                    'num_incorrect_debate_mode': 0,\n",
    "                    'num_correct_with_correct_debate_mode': 0,\n",
    "                    'num_correct_with_incorrect_debate_mode': 0,\n",
    "                    'num_debate_mode_responses': 0,\n",
    "                }\n",
    "                for option in ([None] if model_stance is None else options)\n",
    "            }\n",
    "            metrics[qid]['answer'] = answer\n",
    "        prompt_metrics = metrics[qid][model_stance]\n",
    "        prompt_metrics['num'] += 1\n",
    "        prompt_metrics['num_correct'] += human_correct\n",
    "        if model_stance == answer:\n",
    "            prompt_metrics['num_correct_with_correct_debate_mode'] += human_correct\n",
    "            prompt_metrics['num_correct_debate_mode'] += 1\n",
    "        else:\n",
    "            prompt_metrics['num_correct_with_incorrect_debate_mode'] += human_correct\n",
    "            prompt_metrics['num_incorrect_debate_mode'] += 1\n",
    "        prompt_metrics['num_debate_mode_responses'] += (prompt['response'] == model_stance)\n",
    "        \n",
    "        hit_durations.append(prompt['duration'] / 1000.)\n",
    "        response_option_counts[prompt['response']] += 1\n",
    "        responses.append(prompt['response'])\n",
    "    duration = np.median(np.array(hit_durations))\n",
    "    durations_by_worker.append(duration)\n",
    "    durations += hit_durations\n",
    "    response_options_array = np.array(list(response_option_counts.values()))\n",
    "    response_options_array = response_options_array / response_options_array.sum()\n",
    "    max_response_freq = response_options_array.max()\n",
    "    max_response_freqs.append(max_response_freq)\n",
    "    print('| Time:', round(duration, 1),\n",
    "          '| Acc:', round(100 * hit_result['accuracy'][prompt_type]),\n",
    "          '| Max Freq:', round(100 * max_response_freq, 1),\n",
    "          '| Rate:', hit_result['task_rating'],\n",
    "          '| Feedback:', hit_result['feedback'])\n",
    "\n",
    "durations = np.array(durations)\n",
    "durations_by_worker = np.array(durations_by_worker)\n",
    "max_response_freqs = np.array(max_response_freqs)\n",
    "durations.sort()\n",
    "durations_by_worker.sort()\n",
    "max_response_freqs.sort()\n",
    "for qtype in accuracy_by_worker:\n",
    "    accuracy_by_worker[qtype] = np.array(accuracy_by_worker[qtype])\n",
    "    accuracy_by_worker[qtype].sort()\n",
    "print('REJECTED:', num_rejected_hits)\n",
    "print('INCOMPLETE:', num_incomplete_hits)\n",
    "print('VALID:', num_valid_hits)\n",
    "print('Median Question Duration:', np.median(durations))\n",
    "print('Median Worker Duration:', np.median(durations_by_worker))\n",
    "print('Median Worker Accuracy:', np.median(accuracy_by_worker[prompt_type]))\n",
    "print('Median Max Response Freq:', np.median(max_response_freqs))\n",
    "# pprint(hit_results[0]['data'][0])\n",
    "pprint(hit_results[0]['worker_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evals per sample: 5.549019607843137\n",
      "Fraction insuffient evals: 0.049019607843137254\n",
      "Convinced: 40.65 %\n",
      "- Correct debater: 84.54 %\n",
      "- Incorrect debater: 26.02 %\n",
      "Accuracy: 55.7 %\n",
      "- Correct debater: 84.54 %\n",
      "- Incorrect debater: 46.09 %\n",
      "Extra Evals: 9.89 %\n",
      "Evals per sample distribution: [4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "accuracy_by_sample = []\n",
    "accuracy_by_sample_correct_debate_mode = []\n",
    "accuracy_by_sample_incorrect_debate_mode = []\n",
    "convinced_freqs = []\n",
    "convinced_freqs_with_correct_debate_mode = []\n",
    "convinced_freqs_with_incorrect_debate_mode = []\n",
    "num_evals_by_sample = []\n",
    "for qid, qid_metrics in metrics.items():\n",
    "    answer = metrics[qid]['answer']\n",
    "    for model_stance, prompt in qid_metrics.items():\n",
    "        if not (model_stance in [None] + options):\n",
    "            continue\n",
    "\n",
    "        # Q-only stats\n",
    "        prompt_metrics = metrics[qid][model_stance]\n",
    "        num_evals_by_sample.append(prompt_metrics['num'])\n",
    "        accuracy_by_sample.append(prompt_metrics['num_correct'] / prompt_metrics['num'])\n",
    "        if model_stance is None:\n",
    "            continue\n",
    "        \n",
    "        # Debater stats\n",
    "        convinced_freq = prompt_metrics['num_debate_mode_responses'] / prompt_metrics['num']\n",
    "        if model_stance == answer:\n",
    "            convinced_freqs_with_correct_debate_mode.append(convinced_freq)\n",
    "            accuracy_by_sample_correct_debate_mode.append(\n",
    "                prompt_metrics['num_correct_with_correct_debate_mode'] /\n",
    "                prompt_metrics['num_correct_debate_mode'])\n",
    "        else:\n",
    "            convinced_freqs_with_incorrect_debate_mode.append(convinced_freq)\n",
    "            accuracy_by_sample_incorrect_debate_mode.append(\n",
    "                prompt_metrics['num_correct_with_incorrect_debate_mode'] /\n",
    "                prompt_metrics['num_incorrect_debate_mode'])\n",
    "        convinced_freqs.append(convinced_freq)\n",
    "\n",
    "worker_ids = set(worker_ids)\n",
    "        \n",
    "num_evals_by_sample = np.array(num_evals_by_sample)\n",
    "print('Evals per sample:', num_evals_by_sample.mean())\n",
    "print('Fraction insuffient evals:', (num_evals_by_sample < 5).mean())\n",
    "\n",
    "convinced_freqs = np.array(convinced_freqs)\n",
    "print('Convinced:', round(100 * convinced_freqs.mean(), 2), '%')\n",
    "convinced_freqs_with_correct_debate_mode = np.array(convinced_freqs_with_correct_debate_mode)\n",
    "print('- Correct debater:', round(100 * convinced_freqs_with_correct_debate_mode.mean(), 2), '%')\n",
    "convinced_freqs_with_incorrect_debate_mode = np.array(convinced_freqs_with_incorrect_debate_mode)\n",
    "print('- Incorrect debater:', round(100 * convinced_freqs_with_incorrect_debate_mode.mean(), 2), '%')\n",
    "\n",
    "accuracy_by_sample = np.array(accuracy_by_sample)\n",
    "print('Accuracy:', round(100 * accuracy_by_sample.mean(), 2), '%')\n",
    "accuracy_by_sample_correct_debate_mode = np.array(accuracy_by_sample_correct_debate_mode)\n",
    "print('- Correct debater:', round(100 * accuracy_by_sample_correct_debate_mode.mean(), 2), '%')\n",
    "accuracy_by_sample_incorrect_debate_mode = np.array(accuracy_by_sample_incorrect_debate_mode)\n",
    "print('- Incorrect debater:', round(100 * accuracy_by_sample_incorrect_debate_mode.mean(), 2), '%')\n",
    "\n",
    "num_target_evals = 5\n",
    "print('Extra Evals:', round(((100. * (num_evals_by_sample - num_target_evals).sum()) / num_evals_by_sample.sum()), 2), '%')\n",
    "num_evals_by_sample.sort()\n",
    "print('Evals per sample distribution:', num_evals_by_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "NPS, Mean: (20.72, 7.69)\n"
     ]
    }
   ],
   "source": [
    "def nps(task_ratings):\n",
    "    num_ratings = sum(list(task_ratings.values()))\n",
    "    print(num_ratings)\n",
    "    if num_ratings == 0:\n",
    "        return None\n",
    "\n",
    "    nps_sum_ratings = 0\n",
    "    sum_ratings = 0\n",
    "    for score, num_raters in task_ratings.items():\n",
    "        sum_ratings += num_raters * score\n",
    "        if score >= 9:\n",
    "            nps_sum_ratings += num_raters\n",
    "        elif score <= 6:\n",
    "            nps_sum_ratings -= num_raters\n",
    "    return round(100 * (nps_sum_ratings / float(num_ratings)), 2), round((sum_ratings / float(num_ratings)), 2)\n",
    "\n",
    "print('NPS, Mean:', nps(task_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.312 ,  9.326 , 10.364 , 10.967 , 11.18  , 11.252 , 11.446 ,\n",
       "       11.542 , 11.576 , 12.544 , 12.608 , 12.6555, 12.78  , 13.634 ,\n",
       "       13.708 , 13.727 , 14.3215, 14.509 , 14.537 , 14.538 , 14.65  ,\n",
       "       14.887 , 14.928 , 14.975 , 15.074 , 15.264 , 15.545 , 15.748 ,\n",
       "       15.775 , 15.943 , 15.9795, 15.9865, 16.203 , 16.247 , 16.252 ,\n",
       "       16.331 , 16.424 , 17.016 , 17.283 , 17.348 , 17.623 , 17.699 ,\n",
       "       17.77  , 17.78  , 18.1195, 18.157 , 18.223 , 18.256 , 18.274 ,\n",
       "       18.517 , 18.671 , 18.773 , 19.239 , 19.254 , 19.37  , 19.387 ,\n",
       "       20.1695, 20.221 , 20.561 , 20.63  , 20.75  , 21.057 , 21.226 ,\n",
       "       21.314 , 21.4   , 21.637 , 21.789 , 22.047 , 22.052 , 22.103 ,\n",
       "       22.155 , 22.258 , 22.383 , 22.488 , 22.76  , 22.979 , 22.988 ,\n",
       "       22.99  , 23.05  , 23.219 , 23.242 , 23.29  , 23.5895, 24.1585,\n",
       "       24.243 , 24.281 , 24.422 , 24.7485, 25.315 , 25.702 , 26.223 ,\n",
       "       27.209 , 27.354 , 28.52  , 30.0845, 31.611 , 31.795 , 32.304 ,\n",
       "       35.076 , 36.99  , 40.481 , 50.6245, 64.796 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations_by_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from pprint import pprint\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "num_evals = 5\n",
    "evals = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qualified: 61.54 %\n"
     ]
    }
   ],
   "source": [
    "task_dir = '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_'\n",
    "\n",
    "task_setup = [\n",
    "# ## Persuading Humans (Dev)\n",
    "# ('race', 'question', 1554052233, 'No Passage'),\n",
    "# ('race', 'quote and question', 1554006689, 'TFIDF(S,[Q;A])'),\n",
    "# ('race', 'quote and question', 1554130485, 'TFIDF(S,A)'),\n",
    "# ('race', 'quote and question', 1554069931, 'BERT Base'),\n",
    "# ('race', 'quote and question', 1554072277, 'Pred search'),\n",
    "# ('race', 'quote and question', 1554132868, 'Pred Δp(A)'),\n",
    "# ## Persuading Humans\n",
    "# ('race', 'quote and question', 1556832343, 'Pred search (Almost complete)'),\n",
    "# ('race', 'quote and question', 1557155351, 'Bi-Ranker'),\n",
    "# ## Persuading Humans: FINAL\n",
    "# ('race', 'question', 1557351318, 'No Passage'),\n",
    "# ('race', 'quote and question', 1556671432, 'TFIDF(S,[Q;A])'),\n",
    "# ('race', 'quote and question', 1556725767, 'TFIDF(S,A)'),\n",
    "# ('race', 'quote and question', 1556739336, 'FastText(S,A)'),\n",
    "# ('race', 'quote and question', 1557144204, 'BERT Base'),\n",
    "# ('race', 'quote and question', 1556892630, 'Pred search'),\n",
    "# ('race', 'quote and question', 1556809031, 'Pred p(A)'),\n",
    "# ('race', 'quote and question', 1556756789, 'Pred Δp(A)'),  # (race.m=sl-sents.i.best.e)\n",
    "# ('race', 'quote and question', 1557420471, 'Human 1'),\n",
    "# ('race', 'quote and question', 1558016111, 'Human 2'),\n",
    "('race', 'quote and question', 1558028902, 'Human 3'),\n",
    "# ## Human QA on Summary\n",
    "# ('race', 'quotes and question', 1555946909, 'FastText(S,A) (lower pay)'),\n",
    "# ('race', 'quotes and question', 1555952058, 'BERT Base Best Epoch'),  # (6-10 sentence incorrectly placed at end)\n",
    "# ('race', 'quotes and question', 1556939750, 'Pred Δp(A) (lower pay)'),\n",
    "# ('race', 'quotes and question', 1557093902, 'Bi-Ranker'),\n",
    "# ## Human QA on Summary: FINAL\n",
    "# ('race', 'passage and question', 1555823963, 'Full Passage'),\n",
    "# ('race', 'quotes and question', 1557189780, 'TFIDF(S,[Q;A])'),\n",
    "# ('race', 'quotes and question', 1557164593, 'TFIDF(S,A)'),\n",
    "# ('race', 'quotes and question', 1557234076, 'FastText(S,A)'),\n",
    "# ('race', 'quotes and question', 1557085110, 'BERT Base'),  # Last Epoch\n",
    "# ('race', 'quotes and question', 1556987177, 'Pred search'),\n",
    "# ('race', 'quotes and question', 1556977072, 'Pred p(A)'),\n",
    "# ('race', 'quotes and question', 1556999857, 'Pred Δp(A)'),\n",
    "# ('race', 'quotes and question', 1557432288, 'Human 1'),\n",
    "# ('race', 'quotes and question', 1558039471, 'Human 2'),\n",
    "# ('race', 'quotes and question', 1558054770, 'Human 3'),\n",
    "# ## Persuading Humans\n",
    "# ('dream', 'quote and question', 1556670413, 'Bi-Ranker'),\n",
    "# ('dream', 'quote and question', 1555333992, 'Pred search (ToM)'),\n",
    "# ## Persuading Humans: FINAL\n",
    "# ('dream', 'question', 1554582693, 'No Passage'),\n",
    "# ('dream', 'quote and question', ?, 'FastText(S,Q)'),\n",
    "# ('dream', 'quote and question', 1554596686, 'TFIDF(S,[Q;A])'),\n",
    "# ('dream', 'quote and question', 1554587404, 'TFIDF(S,A)'),\n",
    "# ('dream', 'quote and question', 1554662280, 'FastText(S,A)'),\n",
    "# ('dream', 'quote and question', 1554675304, 'BERT Base'),\n",
    "# ('dream', 'quote and question', 1554685131, 'Pred search'),\n",
    "# ('dream', 'quote and question', 1554692472, 'Pred p(A)'),\n",
    "# ('dream', 'quote and question', 1554729998, 'Pred Δp(A)'),\n",
    "# ('dream', 'quote and question', 1558028987, 'Human 1'),\n",
    "# ('dream', 'quotes and question', ?, 'Human 2'),\n",
    "# ('dream', 'quotes and question', ?, 'Human 3'),\n",
    "# ## Human QA on Summary\n",
    "# ('dream', 'question, answers, and quotes', 1555707929, 'TFIDF(S,A)'),  # 64.21%: (Less filter / no feedback)\n",
    "# ('dream', 'question, answers, and quotes', 1555722489, 'BERT Base'),  # 65.38%: (Less filter / no feedback)\n",
    "# ('dream', 'question and quotes', 1555789302, 'Pred search'),  # 75.17% (4/5 filter)\n",
    "# ('dream', 'question and quotes', 1555812443, 'Pred search'),  # 79.32% Actually: quotes and question (4/5 filter)\n",
    "# ('dream', 'quotes and question', 1555946647, 'BERT Base (RACE -> DREAM)'),  # (4 sentences incorrectly placed at end) (80.84%)\n",
    "# ('dream', 'quotes and question', 1556740293, 'Bi-Ranker'),\n",
    "# ## Human QA on Summary: FINAL\n",
    "# ('dream', 'passage and question', 1555804551, 'Full Passage'),\n",
    "# ('dream', 'quotes and question', 1558059069, 'FastText(S,Q)'),\n",
    "# ('dream', 'quotes and question', 1556811067, 'TFIDF(S,[Q;A])'),\n",
    "# ('dream', 'quotes and question', 1556757043, 'TFIDF(S,A)'),\n",
    "# ('dream', 'quotes and question', 1555823257, 'FastText(S,A)'),\n",
    "# ('dream', 'quotes and question', 1556727396, 'BERT Base'),\n",
    "# ('dream', 'quotes and question', 1556832115, 'Pred search'),\n",
    "# ('dream', 'quotes and question', 1556892896, 'Pred p(A)'),\n",
    "# ('dream', 'quotes and question', 1556938429, 'Pred Δp(A)'),\n",
    "# ('dream', 'quotes and question', 1558016251, 'Human 1'),\n",
    "# ('dream', 'quotes and question', ?, 'Human 2'),\n",
    "# ('dream', 'quotes and question', ?, 'Human 3'),\n",
    "]\n",
    "\n",
    "dataset, prompt_type, task_id, name = task_setup[-1]\n",
    "split = None  # 'middle', 'high', None\n",
    "\n",
    "\n",
    "# Set useful variables\n",
    "task_dir += str(task_id)\n",
    "if dataset != 'race':\n",
    "    split = None\n",
    "num_options = 3 if dataset == 'dream' else 4\n",
    "options = ['A', 'B', 'C', 'D'][:num_options]\n",
    "debate_mode_to_option = {'Ⅰ': 'A', 'Ⅱ': 'B', 'Ⅲ': 'C', 'Ⅳ': 'D', 'ⅰ': 'A', 'ⅱ': 'B', 'ⅲ': 'C', 'ⅳ': 'D', None: None}\n",
    "question_type_labels = ['a', 'c', 'l', 'm', 's'] if dataset == 'dream' else ['a', 'b', 'c', 'd', 'e']\n",
    "\n",
    "# if (dataset == 'dream') and (prompt_type == 'quote and question'):\n",
    "#     question_type_labels = []\n",
    "\n",
    "# Read HIT data\n",
    "hit_results = []\n",
    "num_passed_test = 0\n",
    "for hit_dir in os.listdir(task_dir):\n",
    "    if hit_dir.startswith('o_'):\n",
    "        continue\n",
    "    num_passed_test += 1\n",
    "    with open(os.path.join(task_dir, hit_dir, 'custom/data.json'), 'r') as file:\n",
    "        hit_results.append(json.load(file))\n",
    "        file.close()\n",
    "if len(os.listdir(task_dir)) != num_passed_test:\n",
    "    num_total_tested = len(os.listdir(task_dir)) - num_passed_test\n",
    "    print('Qualified:', round((100. * num_passed_test) / num_total_tested, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Time: 408.4 | Acc: 70 | Max Freq: 35.0 | Rate: 5 | Feedback: Make sure the quotes all relate to the question being asked | Quote Rating: 4 | Quote Desc: Obtuse is the first word that comes to mind\n",
      "| Time: 518.6 | Acc: 40 | Max Freq: 35.0 | Rate: 1 | Feedback: I am not sure, because it would depend on what you were studying in the task. | Quote Rating: 2 | Quote Desc: Some directly correlated to the provided answer choices and some seems completely random and non-sensical. \n",
      "| Time: 1329.9 | Acc: 65 | Max Freq: 45.0 | Rate: 10 | Feedback: Nothing. It is a fun task. | Quote Rating: 9 | Quote Desc: They were useful for the most part\n",
      "| Time: 585.1 | Acc: 25 | Max Freq: 30.0 | Rate: 10 | Feedback: Make the examples as tricky as the real task. | Quote Rating: 6 | Quote Desc: Some of the passages seemed to have nothing to do with the question.  All passages were trickier than the example questions.\n",
      "| Time: 656.6 | Acc: 65 | Max Freq: 35.0 | Rate: 7 | Feedback: Provide what the average worker score is when checking the bonus | Quote Rating: 6 | Quote Desc: Many were difficult to figure out the context, others required a little thought.  It was an interesting exercise\n",
      "| Time: 1990.5 | Acc: 30 | Max Freq: 40.0 | Rate: 7 | Feedback: More | Quote Rating: 6 | Quote Desc: Good\n",
      "| Time: 284.3 | Acc: 60 | Max Freq: 30.0 | Rate: 8 | Feedback: N/A | Quote Rating: 8 | Quote Desc: Some were very vague and some were very good at helping to infer the given information\n",
      "| Time: 662.0 | Acc: 60 | Max Freq: 35.0 | Rate: 10 | Feedback: looks good to me | Quote Rating: 8 | Quote Desc: needed\n",
      "| Time: 541.3 | Acc: 50 | Max Freq: 35.0 | Rate: 3 | Feedback: I don't know | Quote Rating: 3 | Quote Desc: The passage quotes didn't match the answers provided for the most part.\n",
      "| Time: 532.6 | Acc: 45 | Max Freq: 40.0 | Rate: 9 | Feedback: im not sure. maybe be a bit more clear on your passages. more subtle | Quote Rating: 9 | Quote Desc: some were confusing but others were easy to understand\n",
      "| Time: 434.0 | Acc: 50 | Max Freq: 30.0 | Rate: 8 | Feedback: You dont need too. Everything was fine | Quote Rating: 3 | Quote Desc: Vague and a little puzzling\n",
      "| Time: 712.9 | Acc: 60 | Max Freq: 40.0 | Rate: 6 | Feedback: not that I can think of | Quote Rating: 2 | Quote Desc: confusing\n",
      "| Time: 626.7 | Acc: 70 | Max Freq: 40.0 | Rate: 5 | Feedback: higher pay | Quote Rating: 6 | Quote Desc: Sometimes helpful, sometimes not\n",
      "| Time: 498.8 | Acc: 45 | Max Freq: 35.0 | Rate: 10 | Feedback: I don't have any suggestions. | Quote Rating: 10 | Quote Desc: They gave good context clues on what answer the question was looking for.\n",
      "| Time: 672.0 | Acc: 40 | Max Freq: 35.0 | Rate: 8 | Feedback: I'm not sure at the moment, I would have to think about it. | Quote Rating: 6 | Quote Desc: Some made sense, others made no sense. Some answers seemed like an opinion rather than a correct or incorrect answer.\n",
      "| Time: 491.8 | Acc: 50 | Max Freq: 35.0 | Rate: 10 | Feedback: I can't think of anything at the moment. The entire task is exceedingly well-designed and intuitive. | Quote Rating: 8 | Quote Desc: Many of them were self-explanatory and easy to decipher. Some, however, were difficult to judge properly.\n",
      "| Time: 458.3 | Acc: 65 | Max Freq: 35.0 | Rate: 10 | Feedback: Less ambiguous passages. | Quote Rating: 8 | Quote Desc: Most of them made the guess pretty easy, but there were some ambiguous ones.\n",
      "| Time: 597.5 | Acc: 30 | Max Freq: 40.0 | Rate: 10 | Feedback: have more useful quotes to help figure out the questions | Quote Rating: 7 | Quote Desc: some of them made sense with the questions, some did not\n",
      "| Time: 667.7 | Acc: 50 | Max Freq: 40.0 | Rate: 10 | Feedback: use a  different color  than yellow  as a  background  for the  system questions yellow  on white  causes  bad  eye strain  | Quote Rating: 9 | Quote Desc: they helped  give me  some  reference  to  what to choose \n",
      "| Time: 945.3 | Acc: 60 | Max Freq: 40.0 | Rate: 5 | Feedback: Make it more mobile friendly  | Quote Rating: 8 | Quote Desc: Unusual \n",
      "| Time: 490.5 | Acc: 50 | Max Freq: 35.0 | Rate: 8 | Feedback: Nothing that I can think of. The hit seems to run smoothly. | Quote Rating: 8 | Quote Desc: They were okay some seemed a little off topic.\n",
      "| Time: 442.2 | Acc: 60 | Max Freq: 40.0 | Rate: 8 | Feedback: The task was simple and kind of fun, not sure how you could improve it! | Quote Rating: 5 | Quote Desc: Some of them seemed very random.\n",
      "| Time: 929.2 | Acc: 60 | Max Freq: 35.0 | Rate: 9 | Feedback: I think the task is good as it is. I can't think of anything which would make it better. | Quote Rating: 7 | Quote Desc: I would describe them as somewhat vague\n",
      "| Time: 501.6 | Acc: 55 | Max Freq: 30.0 | Rate: 10 | Feedback: no improvents it worked well  | Quote Rating: 9 | Quote Desc: helpful\n",
      "| Time: 540.4 | Acc: 40 | Max Freq: 30.0 | Rate: 10 | Feedback: I don't think it needs improvement | Quote Rating: 6 | Quote Desc: Sometimes they didn't make much sense and sometimes there was not enough context\n",
      "| Time: 523.2 | Acc: 60 | Max Freq: 35.0 | Rate: 10 | Feedback: can't think of anything other than make the passages more relatable | Quote Rating: 6 | Quote Desc: some were helpful, others did not seem to help much\n",
      "| Time: 661.5 | Acc: 30 | Max Freq: 30.0 | Rate: 8 | Feedback: don't know | Quote Rating: 9 | Quote Desc: Some are weird.\n",
      "| Time: 683.1 | Acc: 55 | Max Freq: 30.0 | Rate: 10 | Feedback: The only suggestion is maybe provide clearer passages which make a little more sense. | Quote Rating: 6 | Quote Desc: Limited and confusing\n",
      "| Time: 646.0 | Acc: 55 | Max Freq: 35.0 | Rate: 9 | Feedback: No improvement needed  | Quote Rating: 8 | Quote Desc: Mostly helpful. Some could be open to interpretation in regards to the answer choices, but most of them were clear and easy to understand. \n",
      "| Time: 454.0 | Acc: 60 | Max Freq: 40.0 | Rate: 0 | Feedback: The questions that make no sense, how can they be properly scored for these bonuses? It's frustrating  and the writing parts at the end are going to make people not recommend the hits. | Quote Rating: 5 | Quote Desc: Some of them had nothing to do with the questions so I don't know how they'd ever be scored properly.\n",
      "| Time: 454.6 | Acc: 35 | Max Freq: 40.0 | Rate: 8 | Feedback: can't suggest | Quote Rating: 8 | Quote Desc: interesting and amusing\n",
      "| Time: 482.2 | Acc: 65 | Max Freq: 30.0 | Rate: 8 | Feedback: Make the screen stop shaking.  | Quote Rating: 3 | Quote Desc: Some were easy, some were incredibly vague that had nothing to do with the choices of answers. \n",
      "AQP4PHYDXRBPI 3IHR8NYAM8GLOB8XMII8DMHEZTF4PA | reject_reasons: ['median_duration = 3023'] | block_reasons: ['median_duration = 3023'] | bonus_reasons: []\n",
      "| Time: 319.9 | Acc: 20 | Max Freq: 40.0 | Rate: 10 | Feedback: none | Quote Rating: 9 | Quote Desc: They were easy to understand\n",
      "| Time: 427.5 | Acc: 55 | Max Freq: 35.0 | Rate: 6 | Feedback: better quotes | Quote Rating: 7 | Quote Desc: Some good , others not.\n",
      "| Time: 516.4 | Acc: 75 | Max Freq: 35.0 | Rate: 8 | Feedback: More instructions. | Quote Rating: 8 | Quote Desc: Somewhat nonsense\n",
      "| Time: 496.4 | Acc: 50 | Max Freq: 35.0 | Rate: 10 | Feedback: Do not know the goal so cannot say. | Quote Rating: 7 | Quote Desc: vague\n",
      "| Time: 632.9 | Acc: 70 | Max Freq: 45.0 | Rate: 10 | Feedback: I'm not sure what your goal is so I don't know that I can offer a suggestion for improvement.  I enjoyed it.  Thanks and have a great day! | Quote Rating: 6 | Quote Desc: A bit disconnected and vague sometimes.  Hard to connect the dots.\n",
      "| Time: 301.2 | Acc: 40 | Max Freq: 35.0 | Rate: 3 | Feedback: they did not make much sense. you could provide better opening statements | Quote Rating: C | Quote Desc: odd\n",
      "| Time: 781.3 | Acc: 60 | Max Freq: 35.0 | Rate: 5 | Feedback: have passages that are more connected to the questions | Quote Rating: 3 | Quote Desc: A lot of the time confusing.\n",
      "| Time: 1630.5 | Acc: 55 | Max Freq: 35.0 | Rate: 9 | Feedback: Making the passages a little more clear. | Quote Rating: 6 | Quote Desc: Sometimes they were vague.\n",
      "| Time: 386.6 | Acc: 55 | Max Freq: 30.0 | Rate: 8 | Feedback: no idea | Quote Rating: 6 | Quote Desc: Some were useless, but others made it pretty clear, even if it wasn't obvious.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Time: 1119.6 | Acc: 50 | Max Freq: 40.0 | Rate: 7 | Feedback: i don't know cause i don't know what you're looking for | Quote Rating: 3 | Quote Desc: strange and confusing\n",
      "| Time: 527.2 | Acc: 40 | Max Freq: 45.0 | Rate: 10 | Feedback: No suggestions | Quote Rating: 6 | Quote Desc: Some of them were extremely perplexing and I feel like they weren't in complete sentences. Only a word or two would help sometimes.\n",
      "| Time: 722.3 | Acc: 55 | Max Freq: 35.0 | Rate: 10 | Feedback: No changes, I thought the exercise was great. | Quote Rating: 10 | Quote Desc: The provided passage quotes were a hint for the answer. Some were tough, but others seemed easy.\n",
      "| Time: 726.3 | Acc: 65 | Max Freq: 35.0 | Rate: 3 | Feedback: A few more instructions perhaps. | Quote Rating: 8 | Quote Desc: Some were obvious and some took more inference and deduction.\n",
      "| Time: 468.9 | Acc: 50 | Max Freq: 35.0 | Rate: 10 | Feedback: Nothing, it's fun. | Quote Rating: 8 | Quote Desc: Usually sufficient information, but not so much as to make it simple.\n",
      "| Time: 362.8 | Acc: 45 | Max Freq: 30.0 | Rate: 10 | Feedback: Provide more insightful quotes | Quote Rating: 7 | Quote Desc: The provided passage quotes offered little help at times\n",
      "| Time: 499.0 | Acc: 60 | Max Freq: 40.0 | Rate: 8 | Feedback: I'm not sure. | Quote Rating: 6 | Quote Desc: Some seemed pretty easy and some seemed kind of tricky.\n",
      "| Time: 734.9 | Acc: 55 | Max Freq: 35.0 | Rate: 10 | Feedback: Well, I'm not sure what you're trying to accomplish, so I can't offer a good suggestion for improvement. | Quote Rating: 6 | Quote Desc: Somewhat ambiguous, and occasionally nonsensical, but thought-provoking nonetheless.\n",
      "| Time: 792.8 | Acc: 60 | Max Freq: 30.0 | Rate: 3 | Feedback: Being more descriptive in the passage quotes to help the reader identify what the intended message relates to.  | Quote Rating: 2 | Quote Desc: Very uninformative and confusing. Ineffective at educating a reviewer. \n",
      "| Time: 786.1 | Acc: 60 | Max Freq: 45.0 | Rate: 5 | Feedback: Word it better to enhance understanding. | Quote Rating: 5 | Quote Desc: A little difficult to understand at times\n",
      "| Time: 428.5 | Acc: 65 | Max Freq: 40.0 | Rate: 10 | Feedback: N/A | Quote Rating: 5 | Quote Desc: Vague and sometimes irrelevant to the question.\n",
      "| Time: 344.2 | Acc: 60 | Max Freq: 35.0 | Rate: 10 | Feedback: provide more info for the quotes. | Quote Rating: 5 | Quote Desc: most had some missing info.\n",
      "| Time: 360.6 | Acc: 35 | Max Freq: 35.0 | Rate: 10 | Feedback: Proofread the passages and the questions to make sure they are coherent. | Quote Rating: 4 | Quote Desc: Some where coherent, others were quite vague and had some odd grammar.\n",
      "| Time: 317.8 | Acc: 35 | Max Freq: 45.0 | Rate: 5 | Feedback: More logical quotes. | Quote Rating: 3 | Quote Desc: Often irrelevant to the question.\n",
      "| Time: 479.6 | Acc: 50 | Max Freq: 30.0 | Rate: 5 | Feedback: I'm not sure what the point of this task is... training bots maybe? So I guess the way to make it better would be to make things make more sense. | Quote Rating: 2 | Quote Desc: It's like some of them were translated from multiple languages back into English and missing a lot for context.\n",
      "| Time: 483.6 | Acc: 50 | Max Freq: 35.0 | Rate: 4 | Feedback: Better passages | Quote Rating: 3 | Quote Desc: Interesting and unexpected.\n",
      "| Time: 969.5 | Acc: 30 | Max Freq: 35.0 | Rate: 3 | Feedback: This task should be improved by researcher efforts. | Quote Rating: 8 | Quote Desc: I'm confident somewhat with my answers.\n",
      "| Time: 513.9 | Acc: 70 | Max Freq: 35.0 | Rate: 10 | Feedback: Provide a few more details in some of the quotes. | Quote Rating: 7 | Quote Desc: Most of the provided passage quotes made sense.  However, several of them seemed to be missing information that, in turn, made it difficult to guess.\n",
      "| Time: 644.4 | Acc: 60 | Max Freq: 60.0 | Rate: 8 | Feedback: nothing in particular | Quote Rating: 6 | Quote Desc: Sometimes helpful, and sometimes not so much\n",
      "| Time: 1449.9 | Acc: 45 | Max Freq: 35.0 | Rate: 8 | Feedback: make it easier | Quote Rating: 7 | Quote Desc: creative\n",
      "| Time: 319.5 | Acc: 50 | Max Freq: 45.0 | Rate: 7 | Feedback: Better or more clear quotes.  | Quote Rating: 6 | Quote Desc: Confusing or lacking enough detail to guess an answer. \n",
      "| Time: 365.5 | Acc: 45 | Max Freq: 40.0 | Rate: 9 | Feedback: make the quotes a bit longer or ask questions that you can pick from the quote better | Quote Rating: 6 | Quote Desc: im not sure, they were all very different from each other, and some did not have much information to allow a proper thought process to guess the answer\n",
      "| Time: 569.9 | Acc: 50 | Max Freq: 35.0 | Rate: 8 | Feedback: It was fine | Quote Rating: 6 | Quote Desc: some where good and some were confusing\n",
      "| Time: 334.0 | Acc: 55 | Max Freq: 40.0 | Rate: 1 | Feedback: unsure | Quote Rating: 2 | Quote Desc: barely logical\n",
      "| Time: 344.6 | Acc: 30 | Max Freq: 35.0 | Rate: 10 | Feedback: N/A | Quote Rating: 7 | Quote Desc: Most were helpful, some were confusing and unrelated.\n",
      "| Time: 486.2 | Acc: 65 | Max Freq: 35.0 | Rate: 10 | Feedback: n/a | Quote Rating: 3 | Quote Desc: Quite vague.\n",
      "| Time: 569.1 | Acc: 60 | Max Freq: 40.0 | Rate: 5 | Feedback: no ideas | Quote Rating: 3 | Quote Desc: most times i would consider them vague\n",
      "| Time: 452.3 | Acc: 40 | Max Freq: 50.0 | Rate: 10 | Feedback: It's good as it is.  It makes people think, although I'm embarassed I got so many wrong. | Quote Rating: 4 | Quote Desc: Some were confusing, as expected. But some were relatively simple to understand.\n",
      "| Time: 516.3 | Acc: 50 | Max Freq: 40.0 | Rate: 10 | Feedback: N/A | Quote Rating: 9 | Quote Desc: Essential, the only thing to go by. \n",
      "| Time: 276.1 | Acc: 60 | Max Freq: 30.0 | Rate: 8 | Feedback: I'm not sure | Quote Rating: 9 | Quote Desc: From books maybe\n",
      "| Time: 211.7 | Acc: 30 | Max Freq: 40.0 | Rate: 10 | Feedback: I don't know | Quote Rating: 2 | Quote Desc: Nonsensical\n",
      "| Time: 427.1 | Acc: 45 | Max Freq: 30.0 | Rate: 3 | Feedback: Make the passages make sense | Quote Rating: 3 | Quote Desc: Confusing\n",
      "| Time: 467.6 | Acc: 45 | Max Freq: 35.0 | Rate: 8 | Feedback: make a everyone gets some bonus by making ranges or paying a bonus for each correct answer | Quote Rating: 7 | Quote Desc: Some where more helpful than others, a couple made the choice more difficult and a couple were no help at all\n",
      "| Time: 526.4 | Acc: 60 | Max Freq: 35.0 | Rate: 10 | Feedback: I think the task is pretty cool. | Quote Rating: 8 | Quote Desc: Kind of a word puzzle using logic.\n",
      "| Time: 498.8 | Acc: 35 | Max Freq: 35.0 | Rate: 10 | Feedback: longer passage | Quote Rating: 6 | Quote Desc: interesting\n",
      "| Time: 383.0 | Acc: 50 | Max Freq: 35.0 | Rate: 6 | Feedback: Not sure what your goal is? | Quote Rating: 5 | Quote Desc: Some of the quotes were completely random.\n",
      "| Time: 505.0 | Acc: 50 | Max Freq: 40.0 | Rate: 9 | Feedback: I thought it was interesting, but some questions were difficult.  | Quote Rating: 8 | Quote Desc: They helped to narrow down the scope of question. \n",
      "| Time: 528.6 | Acc: 55 | Max Freq: 25.0 | Rate: 8 | Feedback: No real suggestions, other than improving the quotes to make guessing the answers easier. | Quote Rating: 3 | Quote Desc: They were sometimes relevant to answering the questions, but often the quotes didn't seem to have a strong relation to the overall meaning of passages or the questions being asked.\n",
      "| Time: 343.6 | Acc: 60 | Max Freq: 40.0 | Rate: 8 | Feedback: fine tune the phrases a bit | Quote Rating: 6 | Quote Desc: Disjointed and non-sequitur. \n",
      "| Time: 521.6 | Acc: 35 | Max Freq: 45.0 | Rate: 10 | Feedback: You can improve the task by making passages slightly longer, but I do believe that would not help the nature of this task. | Quote Rating: 8 | Quote Desc: They were very useful in providing key words to help answer the questions, however, a few of them seemed to need more context to be able to answer correctly.\n",
      "| Time: 215.1 | Acc: 70 | Max Freq: 40.0 | Rate: 8 | Feedback: Pay a bit more. | Quote Rating: 7 | Quote Desc: Quotations from various passages.\n",
      "| Time: 810.6 | Acc: 40 | Max Freq: 35.0 | Rate: 10 | Feedback: I'm not sure. | Quote Rating: 7 | Quote Desc: Random and at times confusing to comprehend.\n",
      "| Time: 292.2 | Acc: 60 | Max Freq: 35.0 | Rate: 5 | Feedback: I don't know. | Quote Rating: 7 | Quote Desc: Informational\n",
      "| Time: 489.7 | Acc: 45 | Max Freq: 35.0 | Rate: 10 | Feedback: none | Quote Rating: 9 | Quote Desc: good\n",
      "| Time: 1011.7 | Acc: 50 | Max Freq: 35.0 | Rate: 9 | Feedback: I can't think of a way. | Quote Rating: 7 | Quote Desc: Each seemed like a key quote is the passage.\n",
      "| Time: 321.8 | Acc: 45 | Max Freq: 30.0 | Rate: 10 | Feedback: I don't have an answer but I really enjoyed this task though.  | Quote Rating: 9 | Quote Desc: I would describe the provide passage quotes to be somewhat easy to understand what the context is in terms of the passage. There were some passages that didn't make sense with the answers but it was fun to take a guess.\n",
      "| Time: 336.2 | Acc: 40 | Max Freq: 40.0 | Rate: 8 | Feedback: N/A | Quote Rating: 3 | Quote Desc: Missing information \n",
      "| Time: 837.9 | Acc: 55 | Max Freq: 35.0 | Rate: 8 | Feedback: Possibly make the passages more relevant to the question? | Quote Rating: 7 | Quote Desc: Most of them provided sufficient information, but some passages did not seem to provide enough information to answer the question at all.\n",
      "| Time: 412.4 | Acc: 50 | Max Freq: 30.0 | Rate: 10 | Feedback: Have more of them ;) | Quote Rating: 10 | Quote Desc: They were different then what I've seen\n",
      "| Time: 447.9 | Acc: 70 | Max Freq: 40.0 | Rate: 7 | Feedback: Nothing. It was fine as is.  | Quote Rating: 7 | Quote Desc: Some of them made perfect sense, while others were approximately related, or only partially relevant. \n",
      "| Time: 326.3 | Acc: 65 | Max Freq: 30.0 | Rate: 10 | Feedback: Have the sample questions we are forced to answer be a little more nonsensical to match the real questions. | Quote Rating: 7 | Quote Desc: They forced us to make assumptions because the information was not there.\n",
      "| Time: 668.5 | Acc: 55 | Max Freq: 35.0 | Rate: 8 | Feedback: the screen where you are listing the question shakes. it was bothering me | Quote Rating: 2 | Quote Desc: Brief and for the most part unrelated to the question\n",
      "| Time: 736.8 | Acc: 45 | Max Freq: 35.0 | Rate: 10 | Feedback: I DON'T KNOW | Quote Rating: 6 | Quote Desc: SOME MADE SENSE OTHER WERE WEIRD\n",
      "| Time: 644.0 | Acc: 40 | Max Freq: 40.0 | Rate: 10 | Feedback: Have the answers in view rather than hidden under the drop-down. | Quote Rating: 6 | Quote Desc: They were cliches making them useful under only certain circumstances.\n",
      "| Time: 473.7 | Acc: 40 | Max Freq: 35.0 | Rate: 3 | Feedback: Provide more information from the passage. | Quote Rating: 6 | Quote Desc: Some where irrelevant to the questions.\n",
      "| Time: 482.1 | Acc: 55 | Max Freq: 30.0 | Rate: 8 | Feedback: Better or more clearly relevant quotes.  For example, one was a quote from a mueum employee about how many visitors the museum had, but the question was about a specific  person experiencing German occupation.  There was no relevance.  I did my best. | Quote Rating: 2 | Quote Desc: Frequently they seemed VERY unrelated to the multiple choice options, or contained NO relevant information to the questions asked.\n",
      "| Time: 728.0 | Acc: 55 | Max Freq: 30.0 | Rate: 8 | Feedback: I think it is good since the point is to see how helpful the passages are to the questions so having some that do not help is good | Quote Rating: 4 | Quote Desc: Confusing. Some of them did not help answer the question at all. \n",
      "| Time: 367.9 | Acc: 55 | Max Freq: 40.0 | Rate: 7 | Feedback: it was a little frustrating not knowing if I should know the answers | Quote Rating: 3 | Quote Desc: Often lacking in sufficient information to answer the question\n",
      "| Time: 629.3 | Acc: 35 | Max Freq: 45.0 | Rate: 8 | Feedback: the task is fine | Quote Rating: 6 | Quote Desc: They were written by academic students?\n",
      "| Time: 666.5 | Acc: 40 | Max Freq: 35.0 | Rate: 5 | Feedback: not sure  | Quote Rating: 7 | Quote Desc: some made sense,  others didn't \n",
      "| Time: 688.9 | Acc: 50 | Max Freq: 45.0 | Rate: 8 | Feedback: More pay is always good, but I think it pays fairly well already. | Quote Rating: 5 | Quote Desc: Some useful, some not\n",
      "| Time: 638.5 | Acc: 45 | Max Freq: 40.0 | Rate: 5 | Feedback: pay something small (3-5 cents) for every question answered correctly instead of only bonusing people who score higher than average accuracy. | Quote Rating: 6 | Quote Desc: Not very informative and sometimes they seemed to provide no help at all.\n",
      "| Time: 562.6 | Acc: 50 | Max Freq: 35.0 | Rate: 5 | Feedback: Have better quotes. | Quote Rating: 6 | Quote Desc: Some were very helpful others were not at all helpful.\n",
      "| Time: 369.5 | Acc: 55 | Max Freq: 35.0 | Rate: 8 | Feedback: Add more to the survey | Quote Rating: 8 | Quote Desc: Interesting\n",
      "| Time: 552.8 | Acc: 50 | Max Freq: 45.0 | Rate: 10 | Feedback: I dont know | Quote Rating: 8 | Quote Desc: I would describe as semi informative. \n",
      "| Time: 666.0 | Acc: 55 | Max Freq: 30.0 | Rate: 8 | Feedback: Not sure. | Quote Rating: 9 | Quote Desc: They were interesting.\n",
      "| Time: 535.4 | Acc: 35 | Max Freq: 35.0 | Rate: 8 | Feedback: NA | Quote Rating: 6 | Quote Desc: Sometimes they did not match the options for answers, other times there were pretty clear answers, all seemed pretty cryptic\n",
      "REJECTED: 1\n",
      "INCOMPLETE: 4\n",
      "VALID: 108\n",
      "Median Question Duration: 22.656\n",
      "Mean Question Duration: 24.121241898148146\n",
      "Min/Median/Mean/Max Worker Duration: 3.53 / 8.61 / 9.6 / 33.18\n",
      "Min/Median/Mean/Max Good Worker Durations: 3.58 / 8.72 / 9.73 / 27.18\n",
      "Median Worker Accuracy: 0.5\n",
      "Median Max Response Freq: 0.35\n",
      "Quote Rating: | Mean: 6.09 | Median: 6.0 | Std: 2.16\n",
      "debate_mode_counts: {'Ⅰ': 545, 'Ⅱ': 538, 'Ⅲ': 533, 'Ⅳ': 544, 'ⅰ': 0, 'ⅱ': 0, 'ⅲ': 0, 'ⅳ': 0, None: 0}\n"
     ]
    }
   ],
   "source": [
    "num_valid_hits, num_rejected_hits, num_incomplete_hits = 0, 0, 0\n",
    "metrics = {}\n",
    "task_ratings = {i: 0 for i in range(11)}\n",
    "quote_ratings = []\n",
    "durations = []\n",
    "worker_durations = []\n",
    "accuracy_by_worker = {}\n",
    "max_response_freqs = []\n",
    "worker_ids = []\n",
    "hits_by_qid = {}\n",
    "debate_mode_counts = {debate_mode: 0 for debate_mode in debate_mode_to_option.keys()}\n",
    "\n",
    "for hit_result in hit_results:\n",
    "    if ((len(hit_result['reject_reasons']) > 0) or\n",
    "        (len(hit_result['block_reasons']) > 0)):\n",
    "        num_rejected_hits += 1\n",
    "        print(hit_result['worker_id'], hit_result['assignment_id'],\n",
    "              '| reject_reasons:', hit_result['reject_reasons'],\n",
    "              '| block_reasons:', hit_result['block_reasons'],\n",
    "              '| bonus_reasons: ' + str(hit_result['bonus_reasons']) if 'bonus_reasons' in hit_result else '')\n",
    "    elif hit_result['feedback'] is None:\n",
    "        num_incomplete_hits += 1\n",
    "        continue\n",
    "    \n",
    "    worker_ids.append(hit_result['worker_id'])\n",
    "    num_valid_hits += 1\n",
    "    if (hit_result['task_rating'] is not None) and (hit_result['task_rating'].isdigit()):\n",
    "        task_ratings[int(hit_result['task_rating'])] += 1\n",
    "    if (hit_result.get('quote_rating') is not None) and (hit_result['quote_rating'].isdigit()):\n",
    "        quote_ratings.append(int(hit_result['quote_rating']))\n",
    "    for qtype, qtype_accuracy in hit_result['accuracy'].items():\n",
    "        accuracy_by_worker[qtype] = accuracy_by_worker.get(qtype, []) + [qtype_accuracy]\n",
    "    \n",
    "    hit_durations = []\n",
    "    response_option_counts = {option: 0 for option in options}\n",
    "    responses = []\n",
    "    for prompt in hit_result['data']:\n",
    "        qid = prompt['sample']['qid']\n",
    "        if (split is not None) and (split not in qid):\n",
    "            continue\n",
    "        hits_by_qid[qid] = hits_by_qid.get(qid, [])\n",
    "        hits_by_qid[qid].append(prompt)\n",
    "        debate_mode_counts[prompt['sample']['debate_mode']] += 1\n",
    "        stance = debate_mode_to_option[prompt['sample']['debate_mode']]\n",
    "        answer = prompt['sample']['eval_labels'][0]\n",
    "        human_correct = (prompt['response'] == answer)\n",
    "        assert answer in options, 'Answer must be in options.'\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if qid not in metrics:\n",
    "            metrics[qid] = {\n",
    "                option: {\n",
    "                    'num': 0,\n",
    "                    'num_correct': 0,\n",
    "                    'num_correct_debate_mode': 0,\n",
    "                    'num_incorrect_debate_mode': 0,\n",
    "                    'num_correct_with_correct_debate_mode': 0,\n",
    "                    'num_correct_with_incorrect_debate_mode': 0,\n",
    "                    'num_debate_mode_responses': 0,\n",
    "                    'is_debate_mode_response': []\n",
    "                }\n",
    "                for option in ([None] if stance is None else options)\n",
    "            }\n",
    "#             for qtype in question_type_labels:\n",
    "#                 metrics[qid][qtype] = {\n",
    "#                     'num': 0,\n",
    "#                     'num_correct': 0,\n",
    "#                 }\n",
    "            metrics[qid]['answer'] = answer\n",
    "        metrics[qid]['qtype'] = metrics[qid].get('qtype', set([]))\n",
    "        for qtype in set(''.join(prompt['sample'].get('question_type_labels', []))):\n",
    "            qtype = qtype.lower()\n",
    "            metrics[qid]['qtype'].add(qtype)\n",
    "#             if qtype not in metrics[qid]:\n",
    "#                 print('Did you set `dataset` appropriately?')\n",
    "#             metrics[qid][qtype]['num'] += 1\n",
    "#             metrics[qid][qtype]['num_correct'] += human_correct\n",
    "        prompt_metrics = metrics[qid][stance]\n",
    "        prompt_metrics['num'] += 1\n",
    "        prompt_metrics['num_correct'] += human_correct\n",
    "        if stance == answer:\n",
    "            prompt_metrics['num_correct_with_correct_debate_mode'] += human_correct\n",
    "            prompt_metrics['num_correct_debate_mode'] += 1\n",
    "        else:\n",
    "            prompt_metrics['num_correct_with_incorrect_debate_mode'] += human_correct\n",
    "            prompt_metrics['num_incorrect_debate_mode'] += 1\n",
    "        prompt_metrics['num_debate_mode_responses'] += (prompt['response'] == stance)\n",
    "        prompt_metrics['is_debate_mode_response'].append(prompt['response'] == stance)\n",
    "        \n",
    "        hit_durations.append(prompt['duration'] / 1000.)\n",
    "        response_option_counts[prompt['response']] += 1\n",
    "        responses.append(prompt['response'])\n",
    "    duration = np.sum(np.array(hit_durations))\n",
    "    worker_durations.append(duration)\n",
    "    durations += hit_durations\n",
    "    response_options_array = np.array(list(response_option_counts.values()))\n",
    "    response_options_array = response_options_array / response_options_array.sum()\n",
    "    max_response_freq = response_options_array.max()\n",
    "    max_response_freqs.append(max_response_freq)\n",
    "    acc = round(100 * hit_result['accuracy'][prompt_type])\n",
    "    print('| Time:', round(duration, 1),\n",
    "          '| Acc:', acc,\n",
    "          '| Max Freq:', round(100 * max_response_freq, 1),\n",
    "          '| Rate:', hit_result['task_rating'],\n",
    "          '| Feedback:', hit_result['feedback'],\n",
    "          '| Quote Rating:', None if 'quote_rating' not in hit_result else hit_result['quote_rating'], \n",
    "          '| Quote Desc:', None if 'quote_description' not in hit_result else hit_result['quote_description'])\n",
    "\n",
    "debate_modes_used = list(filter(lambda x: debate_mode_counts[x] > 0, debate_mode_counts.keys()))\n",
    "\n",
    "good_worker_durations = []\n",
    "assert len(worker_durations) == len(accuracy_by_worker[prompt_type])\n",
    "for worker_duration, worker_accuracy in zip(worker_durations, accuracy_by_worker[prompt_type]):\n",
    "    if worker_accuracy > np.median(np.array(accuracy_by_worker[prompt_type])):\n",
    "        good_worker_durations.append(worker_duration)\n",
    "\n",
    "quote_ratings = np.array(quote_ratings)\n",
    "durations = np.array(durations)\n",
    "worker_durations = np.array(worker_durations)\n",
    "good_worker_durations = np.array(good_worker_durations)\n",
    "max_response_freqs = np.array(max_response_freqs)\n",
    "\n",
    "quote_ratings.sort()\n",
    "durations.sort()\n",
    "worker_durations.sort()\n",
    "good_worker_durations.sort()\n",
    "max_response_freqs.sort()\n",
    "\n",
    "for qtype in accuracy_by_worker:\n",
    "    accuracy_by_worker[qtype] = np.array(accuracy_by_worker[qtype])\n",
    "    accuracy_by_worker[qtype].sort()\n",
    "print('REJECTED:', num_rejected_hits)\n",
    "print('INCOMPLETE:', num_incomplete_hits)\n",
    "print('VALID:', num_valid_hits)\n",
    "print('Median Question Duration:', np.median(durations))\n",
    "print('Mean Question Duration:', np.mean(durations[int(durations.shape[0] / 10.):int(9. * durations.shape[0] / 10.)]))\n",
    "print('Min/Median/Mean/Max Worker Duration:',\n",
    "      round(np.min(worker_durations / 60.), 2), '/',\n",
    "      round(np.median(worker_durations / 60.), 2), '/',\n",
    "      round(np.mean(worker_durations / 60.), 2), '/',\n",
    "      round(np.max(worker_durations / 60.), 2))\n",
    "print('Min/Median/Mean/Max Good Worker Durations:',\n",
    "      round(np.min(good_worker_durations / 60.), 2), '/',\n",
    "      round(np.median(good_worker_durations / 60.), 2),'/',\n",
    "      round(np.mean(good_worker_durations / 60.), 2), '/',\n",
    "      round(np.max(good_worker_durations / 60.), 2))\n",
    "print('Median Worker Accuracy:', np.median(accuracy_by_worker[prompt_type]))\n",
    "print('Median Max Response Freq:', np.median(max_response_freqs))\n",
    "print('Quote Rating:',\n",
    "      '| Mean:', round(quote_ratings.mean(), 2),\n",
    "      '| Median:', round(np.median(quote_ratings), 2),\n",
    "      '| Std:', round(np.std(quote_ratings), 2))\n",
    "# pprint(hit_results[0]['data'][0])\n",
    "# pprint(hit_results[0])\n",
    "print('debate_mode_counts:', debate_mode_counts)\n",
    "\n",
    "qids = list(metrics.keys())\n",
    "qids.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPS, Mean: (19.44, 7.8)\n"
     ]
    }
   ],
   "source": [
    "def nps(task_ratings):\n",
    "    num_ratings = sum(list(task_ratings.values()))\n",
    "    if num_ratings == 0:\n",
    "        return None\n",
    "\n",
    "    nps_sum_ratings = 0\n",
    "    sum_ratings = 0\n",
    "    for score, num_raters in task_ratings.items():\n",
    "        sum_ratings += num_raters * score\n",
    "        if score >= 9:\n",
    "            nps_sum_ratings += num_raters\n",
    "        elif score <= 6:\n",
    "            nps_sum_ratings -= num_raters\n",
    "    return round(100 * (nps_sum_ratings / float(num_ratings)), 2), round((sum_ratings / float(num_ratings)), 2)\n",
    "\n",
    "print('NPS, Mean:', nps(task_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': (0.5094618055555555, 96),\n",
      " 'b': (0.5327473958333333, 128),\n",
      " 'c': (0.5411651234567901, 216),\n",
      " 'd': (0.49233490566037735, 212),\n",
      " 'e': (0.41875, 64)}\n",
      "Evals per sample: 5.4\n",
      "Fraction insuffient evals: 0.0\n",
      "Convinced: 42.62 % ( 42.62083333333333 )\n",
      "- Agent is right: 76.07 % ( 76.06666666666666 )\n",
      "- Agent is wrong: 31.47 % ( 31.472222222222218 )\n",
      "24\n",
      "32\n",
      "54\n",
      "53\n",
      "16\n",
      "Accuracy: 50.87 %\n",
      "Accuracy: 50.87291666666667 %\n"
     ]
    }
   ],
   "source": [
    "accuracy_by_qtype = {qtype: [] for qtype in question_type_labels}\n",
    "accuracy_by_sample = []\n",
    "accuracy_by_sample_correct_debate_mode = []\n",
    "accuracy_by_sample_incorrect_debate_mode = []\n",
    "convinced_by_qtype = {qtype: [] for qtype in question_type_labels}\n",
    "convinced_freqs = []\n",
    "convinced_freqs_with_correct_debate_mode = []\n",
    "convinced_freqs_with_incorrect_debate_mode = []\n",
    "convinced_freqs_by_qtype = {qtype: [] for qtype in question_type_labels}\n",
    "convinced_freqs_with_correct_debate_mode_by_qtype = {qtype: [] for qtype in question_type_labels}\n",
    "convinced_freqs_with_incorrect_debate_mode_by_qtype = {qtype: [] for qtype in question_type_labels}\n",
    "num_evals_by_sample = []\n",
    "convinced_by_sample = []\n",
    "# qtypes = []\n",
    "# qtypes_with_correct_debate_mode = []\n",
    "# qtypes_with_incorrect_debate_mode = []\n",
    "\n",
    "for qid in qids:\n",
    "    qid_metrics = metrics[qid]\n",
    "    answer = qid_metrics['answer']\n",
    "    for qid_metric_key, prompt in qid_metrics.items():\n",
    "        if qid_metric_key in question_type_labels:\n",
    "#             qtype = qid_metric_key\n",
    "#             if qid_metrics[qtype]['num'] > 0:\n",
    "#                 accuracy_by_qtype[qtype].append(qid_metrics[qtype]['num_correct'] / qid_metrics[qtype]['num'])\n",
    "#                 convinced_by_qtype[qtype].append(qid_metrics[qtype][])\n",
    "            continue\n",
    "        if not (qid_metric_key in [None] + options):\n",
    "            continue\n",
    "        stance = qid_metric_key\n",
    "\n",
    "        # Q-only stats\n",
    "        prompt_metrics = qid_metrics[stance]\n",
    "        num_evals_by_sample.append(prompt_metrics['num'])\n",
    "        convinced_by_sample.append(prompt_metrics['is_debate_mode_response'])\n",
    "        accuracy_by_sample.append(prompt_metrics['num_correct'] / prompt_metrics['num'])\n",
    "        for qtype in qid_metrics['qtype']:\n",
    "            accuracy_by_qtype[qtype].append(prompt_metrics['num_correct'] / prompt_metrics['num'])\n",
    "        if stance is None:\n",
    "            continue\n",
    "        \n",
    "        # Debater stats\n",
    "#         if 'num_debate_mode_responses' not in prompt_metrics:\n",
    "#             print(qid_metric_key, prompt_metrics)\n",
    "        convinced_freq = prompt_metrics['num_debate_mode_responses'] / prompt_metrics['num']\n",
    "        if stance == answer:\n",
    "            convinced_freqs_with_correct_debate_mode.append(convinced_freq)\n",
    "            for qtype in qid_metrics['qtype']:\n",
    "                convinced_freqs_with_correct_debate_mode_by_qtype[qtype].append(convinced_freq)\n",
    "#             qtypes_with_correct_debate_mode.append(qid_metrics['qtype'])\n",
    "            accuracy_by_sample_correct_debate_mode.append(\n",
    "                prompt_metrics['num_correct_with_correct_debate_mode'] /\n",
    "                prompt_metrics['num_correct_debate_mode'])\n",
    "        else:\n",
    "            convinced_freqs_with_incorrect_debate_mode.append(convinced_freq)\n",
    "            for qtype in qid_metrics['qtype']:\n",
    "                convinced_freqs_with_incorrect_debate_mode_by_qtype[qtype].append(convinced_freq)\n",
    "#             qtypes_with_incorrect_debate_mode.append(qid_metrics['qtype'])\n",
    "            accuracy_by_sample_incorrect_debate_mode.append(\n",
    "                prompt_metrics['num_correct_with_incorrect_debate_mode'] /\n",
    "                prompt_metrics['num_incorrect_debate_mode'])\n",
    "        convinced_freqs.append(convinced_freq)\n",
    "        for qtype in qid_metrics['qtype']:\n",
    "            convinced_freqs_by_qtype[qtype].append(convinced_freq)\n",
    "#         qtypes.append(qid_metrics['qtype'])\n",
    "\n",
    "# qtypes = np.array(qtypes)\n",
    "# qtypes_with_correct_debate_mode = np.array(qtypes_with_correct_debate_mode)\n",
    "# qtypes_with_incorrect_debate_mode = np.array(qtypes_with_incorrect_debate_mode)\n",
    "\n",
    "# print(accuracy_by_qtype)\n",
    "accuracy_by_qtype = {qtype: (np.array(accuracy_by_qtype[qtype]).mean(), len(accuracy_by_qtype[qtype])) for qtype in question_type_labels}\n",
    "pprint(accuracy_by_qtype)\n",
    "\n",
    "num_evals_by_sample = np.array(num_evals_by_sample)\n",
    "print('Evals per sample:', num_evals_by_sample.mean())\n",
    "print('Fraction insuffient evals:', (num_evals_by_sample < 5).mean())\n",
    "\n",
    "convinced_freqs = np.array(convinced_freqs)\n",
    "print('Convinced:', round(100 * convinced_freqs.mean(), 2), '% (', 100 * convinced_freqs.mean(), ')')\n",
    "convinced_freqs_with_correct_debate_mode = np.array(convinced_freqs_with_correct_debate_mode)\n",
    "print('- Agent is right:', round(100 * convinced_freqs_with_correct_debate_mode.mean(), 2), '% (', 100 * convinced_freqs_with_correct_debate_mode.mean(), ')')\n",
    "convinced_freqs_with_incorrect_debate_mode = np.array(convinced_freqs_with_incorrect_debate_mode)\n",
    "print('- Agent is wrong:', round(100 * convinced_freqs_with_incorrect_debate_mode.mean(), 2), '% (', 100 * convinced_freqs_with_incorrect_debate_mode.mean(), ')')\n",
    "\n",
    "for qtype in question_type_labels:\n",
    "#     print(len(convinced_freqs_by_qtype[qtype]))\n",
    "    convinced_freqs_by_qtype[qtype] = np.array(convinced_freqs_by_qtype[qtype]).mean()\n",
    "    print(len(convinced_freqs_with_correct_debate_mode_by_qtype[qtype]))\n",
    "    convinced_freqs_with_correct_debate_mode_by_qtype[qtype] = np.array(convinced_freqs_with_correct_debate_mode_by_qtype[qtype]).mean()\n",
    "#     print(len(convinced_freqs_with_incorrect_debate_mode_by_qtype[qtype]))\n",
    "    convinced_freqs_with_incorrect_debate_mode_by_qtype[qtype] = np.array(convinced_freqs_with_incorrect_debate_mode_by_qtype[qtype]).mean()\n",
    "\n",
    "accuracy_by_sample = np.array(accuracy_by_sample)\n",
    "print('Accuracy:', round(100 * accuracy_by_sample.mean(), 2), '%')\n",
    "print('Accuracy:', 100 * accuracy_by_sample.mean(), '%')\n",
    "accuracy_by_sample_correct_debate_mode = np.array(accuracy_by_sample_correct_debate_mode)\n",
    "\n",
    "num_target_evals = 5\n",
    "# print('Extra Evals:', round(((100. * (num_evals_by_sample - num_target_evals).sum()) / num_evals_by_sample.sum()), 2), '%')\n",
    "# num_evals_by_sample.sort()\n",
    "# print('Evals per sample distribution:', num_evals_by_sample)\n",
    "# 1.5*3.1*60/(917.5684545454544*26/(20*60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Human 2': array([37.75, 46.25, 45.25, 45.5 , 44.25]),\n",
      " 'Human 3': array([44.  , 42.  , 43.  , 40.  , 43.75])}\n",
      "***** Human 2 *****\n",
      "MEAN: 43.8\n",
      "STD: 3.09\n",
      "STDERR: 1.38\n",
      "\n",
      "***** Human 3 *****\n",
      "MEAN: 42.6\n",
      "STD: 1.45\n",
      "STDERR: 0.65\n",
      "\n",
      "Human 2 / Human 2 : 1.0\n",
      "Human 2 / Human 3 : 0.4933\n",
      "Human 3 / Human 2 : 0.4933\n",
      "Human 3 / Human 3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "evals[name] = []\n",
    "for eval_no in range(num_evals):\n",
    "    evals[name].append([convinced_array[eval_no] for convinced_array in convinced_by_sample])\n",
    "\n",
    "evals[name] = 100. * np.array(evals[name]).mean(axis=1)\n",
    "pprint(evals)\n",
    "\n",
    "for n, eval_values in evals.items():\n",
    "    print('*****', n, '*****')\n",
    "    print('MEAN:', round(eval_values.mean(), 1))\n",
    "    print('STD:', round(eval_values.std(), 2))\n",
    "    print('STDERR:', round(eval_values.std() / np.sqrt(eval_values.shape[0]), 2))\n",
    "    print()\n",
    "\n",
    "for n1, eval_values1 in evals.items():\n",
    "    for n2, eval_values2 in evals.items():\n",
    "        print(n1, '/', n2, ':', round(ttest_ind(eval_values1, eval_values2, equal_var=False)[1], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.95\n",
      "53.27\n",
      "54.12\n",
      "49.23\n",
      "41.88\n"
     ]
    }
   ],
   "source": [
    "# print('Accuracy/Num-Samples by Q Type:')\n",
    "if len(accuracy_by_qtype) > 0:\n",
    "    for qtype in question_type_labels:\n",
    "        print(round(100. * accuracy_by_qtype[qtype][0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(100. * convinced_freqs.mean())\n",
    "# print(100. * convinced_freqs_with_correct_debate_mode.mean())\n",
    "# print(100. * convinced_freqs_with_incorrect_debate_mode.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for qtype in question_type_labels:\n",
    "#     print(100. * convinced_freqs[qtypes == qtype].mean(), convinced_freqs[qtypes == qtype].sum())\n",
    "    \n",
    "# for qtype in question_type_labels:\n",
    "#     print(100. * convinced_freqs_with_correct_debate_mode[qtypes_with_correct_debate_mode == qtype].mean(), convinced_freqs_with_correct_debate_mode[qtypes_with_correct_debate_mode == qtype].sum())\n",
    "    \n",
    "# for qtype in question_type_labels:\n",
    "#     print(100. * convinced_freqs_with_incorrect_debate_mode[qtypes_with_incorrect_debate_mode == qtype].mean(), convinced_freqs_with_incorrect_debate_mode[qtypes_with_incorrect_debate_mode == qtype].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.204861111111114\n",
      "41.06770833333333\n",
      "42.34567901234568\n",
      "42.31525157232704\n",
      "42.630208333333336\n",
      "82.53472222222223\n",
      "74.42708333333333\n",
      "84.12037037037038\n",
      "71.91823899371069\n",
      "56.40625\n",
      "35.42824074074074\n",
      "29.947916666666668\n",
      "28.420781893004115\n",
      "32.4475890985325\n",
      "38.03819444444444\n"
     ]
    }
   ],
   "source": [
    "for qtype in question_type_labels:\n",
    "    print(100. * convinced_freqs_by_qtype[qtype])\n",
    "for qtype in question_type_labels:\n",
    "    print(100. * convinced_freqs_with_correct_debate_mode_by_qtype[qtype])\n",
    "for qtype in question_type_labels:\n",
    "    print(100. * convinced_freqs_with_incorrect_debate_mode_by_qtype[qtype])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.87291666666667\n",
      "50.94618055555556\n",
      "53.27473958333333\n",
      "54.11651234567901\n",
      "49.23349056603774\n",
      "41.875\n"
     ]
    }
   ],
   "source": [
    "print(100. * accuracy_by_sample.mean())\n",
    "for qtype in question_type_labels:\n",
    "    print(100. * accuracy_by_qtype[qtype][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.12414965986394\n"
     ]
    }
   ],
   "source": [
    "print(100 * convinced_freqs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Convinced: 38.14 % ( 38.14375 )\n",
    "- Agent is right: 71.74 % ( 71.74166666666667 )\n",
    "- Agent is wrong: 26.94 % ( 26.94444444444445 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Convinced: 43.89 % ( 43.89285714285714 )\n",
    "- Agent is right: 77.53 % ( 77.53333333333333 )\n",
    "- Agent is wrong: 32.68 % ( 32.67936507936508 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Convinced: 42.62 % ( 42.62083333333333 )\n",
    "- Agent is right: 76.07 % ( 76.06666666666666 )\n",
    "- Agent is wrong: 31.47 % ( 31.472222222222218 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.552480158730155"
      ]
     },
     "execution_count": 909,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(38.14375+43.89285714285714+42.62083333333333)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.1138888888889"
      ]
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(71.74166666666667+77.53333333333333+76.06666666666666)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.365343915343914"
      ]
     },
     "execution_count": 911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(26.94444444444445+32.67936507936508+31.472222222222218)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

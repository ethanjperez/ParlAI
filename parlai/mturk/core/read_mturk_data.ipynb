{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from pprint import pprint\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "num_evals = 5\n",
    "evals = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HIT Files: 325\n",
      "# Passed Test: 115 / 210 = 54.76 %\n"
     ]
    }
   ],
   "source": [
    "task_dir = '/Users/ethanperez/research/ParlAI/parlai/mturk/core/run_data/live/context_evaluator_'\n",
    "\n",
    "### RACE: Unfiltered Workers\n",
    "# prompt_type, task_id = 'question', '1553982706'  # Q-only\n",
    "# prompt_type, task_id = 'context_question', 1553790696  # TFIDF\n",
    "# prompt_type, task_id = 'context_question', 1553901953  # FastText\n",
    "### RACE: Filtered Workers\n",
    "# prompt_type, task_id = 'question', '1554052233'  # Q-only\n",
    "# prompt_type, task_id = 'quote and question', 1554006689  # TFIDF-QA\n",
    "# prompt_type, task_id = 'quote and question', 1554130485  # TFIDF-A\n",
    "# prompt_type, task_id = 'quote and question', 1554069931  # Cross-Ranker\n",
    "# prompt_type, task_id = 'quote and question', 1554072277  # Predicting Search\n",
    "# prompt_type, task_id = 'quote and question', 1554132868  # Predicting ΔP(A)\n",
    "\n",
    "### RACE Test\n",
    "## Persuading\n",
    "# prompt_type, task_id, name = 'quote and question', 1556832343, 'Pred Search (Almost complete)'\n",
    "# prompt_type, task_id, name = 'quote and question', 1556671432, 'TFIDF-QA'\n",
    "# prompt_type, task_id, name = 'quote and question', 1556725767, 'TFIDF-A'\n",
    "# prompt_type, task_id, name = 'quote and question', 1556739336, 'BoW-A'\n",
    "prompt_type, task_id, name = 'quote and question', 1557155351, 'Bi-Ranker'\n",
    "# prompt_type, task_id, name = 'quote and question', 1557144204, 'Cross-Ranker'\n",
    "# prompt_type, task_id, name = 'quote and question', 1556892630, 'Pred Search'\n",
    "# prompt_type, task_id, name = 'quote and question', 1556809031, 'Pred P(A)'\n",
    "# prompt_type, task_id, name = 'quote and question', 1556756789, 'Pred ΔP(A)'  # (race.m=sl-sents.i.best.e)\n",
    "## Acc on Summary\n",
    "# prompt_type, task_id, name = 'passage and question', 1555823963, 'Full Passage'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1555946909, 'BoW-A'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1555952058, 'Cross-Ranker Best Epoch'  # (6-10 sentence incorrectly placed at end)\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556939750, 'Pred ΔP(A) (lower pay)'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556977072, 'Pred P(A)'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556987177, 'Pred Search'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556999857, 'Pred ΔP(A)'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1557085110, 'Cross-Ranker'  # Last Epoch\n",
    "# prompt_type, task_id, name = 'quotes and question', 1557093902, 'Bi-Ranker'\n",
    "dataset = 'race'\n",
    "\n",
    "### DREAM\n",
    "## Persuading\n",
    "# prompt_type, task_id, name = 'question', 1554582693, 'Q-only'\n",
    "# prompt_type, task_id, name = 'quote and question', 1554596686, 'TFIDF-QA'\n",
    "# prompt_type, task_id, name = 'quote and question', 1554587404, 'TFIDF-A'\n",
    "# prompt_type, task_id, name = 'quote and question', 1554662280, 'BoW-A'\n",
    "# prompt_type, task_id, name = 'quote and question', 1556670413, 'Bi-Ranker'\n",
    "# prompt_type, task_id, name = 'quote and question', 1554675304, 'Cross-Ranker'\n",
    "# prompt_type, task_id, name = 'quote and question', 1554685131, 'Pred Search'\n",
    "# prompt_type, task_id, name = 'quote and question', 1554692472, 'Pred P(A)'\n",
    "# prompt_type, task_id, name = 'quote and question', 1554729998, 'Pred ΔP(A)'\n",
    "# prompt_type, task_id, name = 'quote and question', 1555333992, 'Pred Search (ToM)'\n",
    "## Acc on Summary\n",
    "# prompt_type, task_id, name = 'question, answers, and quotes', 1555707929, 'TFIDF-A'  # 64.21%: (Less filter / no feedback)\n",
    "# prompt_type, task_id, name = 'question, answers, and quotes', 1555722489, 'Cross-Ranker'  # 65.38%: (Less filter / no feedback)\n",
    "# prompt_type, task_id, name = 'question and quotes', 1555789302, 'Pred Search'  # 75.17% (4/5 filter)\n",
    "# prompt_type, task_id, name = 'question and quotes', 1555812443, 'Pred Search'  # 79.32% Actually: quotes and question (4/5 filter)\n",
    "# prompt_type, task_id, name = 'passage and question', 1555804551, 'Full Passage'  # 92.97%\n",
    "# prompt_type, task_id, name = 'quotes and question', 1555823257, 'FastText'  # (5/5 filter) (77.33%)\n",
    "# prompt_type, task_id, name = 'quotes and question', 1555946647, 'RACE Cross-Ranker'  # (4 sentences incorrectly placed at end) (80.84%)\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556727396, 'Cross-Ranker'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556740293, 'Bi-Ranker'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556757043, 'TFIDF-A'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556811067, 'TFIDF-QA'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556832115, 'Predicting Search'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556892896, 'Predicting P(A)'\n",
    "# prompt_type, task_id, name = 'quotes and question', 1556938429, 'Predicting ΔP(A)'\n",
    "# dataset = 'dream'\n",
    "\n",
    "\n",
    "split = None  # 'middle', 'high', None\n",
    "\n",
    "\n",
    "# Set useful variables\n",
    "task_dir += str(task_id)\n",
    "if dataset != 'race':\n",
    "    split = None\n",
    "num_options = 3 if dataset == 'dream' else 4\n",
    "options = ['A', 'B', 'C', 'D'][:num_options]\n",
    "debate_mode_to_option = {'Ⅰ': 'A', 'Ⅱ': 'B', 'Ⅲ': 'C', 'Ⅳ': 'D', 'ⅰ': 'A', 'ⅱ': 'B', 'ⅲ': 'C', 'ⅳ': 'D', None: None}\n",
    "question_type_labels = ['a', 'c', 'l', 'm', 's'] if dataset == 'dream' else ['a', 'b', 'c', 'd', 'e']\n",
    "\n",
    "# if (dataset == 'dream') and (prompt_type == 'quote and question'):\n",
    "#     question_type_labels = []\n",
    "\n",
    "# Read HIT data\n",
    "print('# HIT Files:', len(os.listdir(task_dir)))\n",
    "hit_results = []\n",
    "num_passed_test = 0\n",
    "for hit_dir in os.listdir(task_dir):\n",
    "    if hit_dir.startswith('o_'):\n",
    "        continue\n",
    "    num_passed_test += 1\n",
    "    with open(os.path.join(task_dir, hit_dir, 'custom/data.json'), 'r') as file:\n",
    "        hit_results.append(json.load(file))\n",
    "        file.close()\n",
    "if len(os.listdir(task_dir)) != num_passed_test:\n",
    "    num_total_tested = len(os.listdir(task_dir)) - num_passed_test\n",
    "    print('# Passed Test:', num_passed_test, '/', num_total_tested, '=', round((100. * num_passed_test) / num_total_tested, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Time: 995.1 | Acc: 60 | Max Freq: 35.0 | Rate: 10 | Feedback: I don't see any improvements. The task was interesting. | Quote Rating: 4 | Quote Desc: Sometimes random or confusing.\n",
      "| Time: 369.3 | Acc: 45 | Max Freq: 40.0 | Rate: 3 | Feedback: N/A | Quote Rating: 3 | Quote Desc: Interesting\n",
      "| Time: 572.4 | Acc: 55 | Max Freq: 35.0 | Rate: 10 | Feedback: Provide more information | Quote Rating: 6 | Quote Desc: Some of them didn't provide enough information.\n",
      "| Time: 415.1 | Acc: 50 | Max Freq: 30.0 | Rate: 1 | Feedback: Make better passages and also a progress bar | Quote Rating: 2 | Quote Desc: Vague and wordy\n",
      "| Time: 707.8 | Acc: 40 | Max Freq: 30.0 | Rate: 10 | Feedback: I don't think it needs any improvement. | Quote Rating: 6 | Quote Desc: Some were helpful,  some were not.\n",
      "| Time: 777.9 | Acc: 65 | Max Freq: 40.0 | Rate: 9 | Feedback: Nothing. It is well designed. | Quote Rating: 6 | Quote Desc: Confusing\n",
      "| Time: 331.3 | Acc: 55 | Max Freq: 40.0 | Rate: 10 | Feedback: N/A | Quote Rating: 3 | Quote Desc: They didn't make much sense in answering the questions most of the time.\n",
      "| Time: 345.5 | Acc: 55 | Max Freq: 30.0 | Rate: 8 | Feedback: Better grammar | Quote Rating: 7 | Quote Desc: Unusual\n",
      "| Time: 348.4 | Acc: 55 | Max Freq: 30.0 | Rate: 10 | Feedback: not sure. it worked pretty well. | Quote Rating: 8 | Quote Desc: some non-sensical, others good at direction\n",
      "| Time: 807.3 | Acc: 45 | Max Freq: 30.0 | Rate: 10 | Feedback: none | Quote Rating: 8 | Quote Desc: somewhat confusing. Perhaps someone good a travia would be excellent at this. \n",
      "| Time: 539.6 | Acc: 50 | Max Freq: 35.0 | Rate: 3 | Feedback: Better quotes, some were super ambiguous. Otherwise slightly higher pay so even without the bonus I can make 6+ dollars an hour.  | Quote Rating: 4 | Quote Desc: Useless half the time and perfect the others.\n",
      "| Time: 935.4 | Acc: 45 | Max Freq: 35.0 | Rate: 7 | Feedback: more logical quotes  | Quote Rating: 3 | Quote Desc: Hard to guess answers based on passages \n",
      "| Time: 243.0 | Acc: 55 | Max Freq: 35.0 | Rate: 7 | Feedback: It depends on what the point of it is.  | Quote Rating: 6 | Quote Desc: Out of context\n",
      "| Time: 454.2 | Acc: 30 | Max Freq: 40.0 | Rate: 5 | Feedback: making things clearer somehow | Quote Rating: 4 | Quote Desc: Confusing and incomplete at times\n",
      "| Time: 431.0 | Acc: 40 | Max Freq: 30.0 | Rate: 3 | Feedback: Make the passages related to the question | Quote Rating: 2 | Quote Desc: Unrelated tp question for for most part\n",
      "| Time: 863.6 | Acc: 60 | Max Freq: 35.0 | Rate: 10 | Feedback: I think it is fine just the way it is, I don't necessarily see a need for improvement | Quote Rating: 2 | Quote Desc: They were very vague, and sounded as if they could have been a passage about another subject in some cases\n",
      "| Time: 405.0 | Acc: 60 | Max Freq: 40.0 | Rate: 10 | Feedback: Make some of the quotes more informative  | Quote Rating: 10 | Quote Desc: They helped me when choosing the answer.\n",
      "| Time: 446.0 | Acc: 50 | Max Freq: 35.0 | Rate: 10 | Feedback: It seems to run smooth to me. I don't know how you could improve it. | Quote Rating: 4 | Quote Desc: Some were descriptive and helpful in answering the questions, while some were very vague and ambigious and were no help whatsoever in answering the questions.\n",
      "| Time: 447.7 | Acc: 60 | Max Freq: 35.0 | Rate: 7 | Feedback: Keep it from shaking the entire time. | Quote Rating: 2 | Quote Desc: Cryptic\n",
      "| Time: 471.3 | Acc: 65 | Max Freq: 30.0 | Rate: 8 | Feedback: Everything seemed to work well. I do not have suggestions for improvement at this time.  | Quote Rating: 4 | Quote Desc: The passage quotes seemed like random excepts from larger articles, and some made very little sense out of context.\n",
      "| Time: 509.5 | Acc: 55 | Max Freq: 35.0 | Rate: 8 | Feedback: it's fine | Quote Rating: 4 | Quote Desc: Somewhat ambiguous\n",
      "| Time: 532.8 | Acc: 70 | Max Freq: 35.0 | Rate: 8 | Feedback: Nothing comes to mind. | Quote Rating: 5 | Quote Desc: Helpful, with a generous sprinkling of funny non-sequiturs.\n",
      "| Time: 626.9 | Acc: 50 | Max Freq: 30.0 | Rate: 5 | Feedback: I don't know. | Quote Rating: 0 | Quote Desc: many times they were irrelevant \n",
      "| Time: 368.8 | Acc: 50 | Max Freq: 40.0 | Rate: 10 | Feedback: longer quotes | Quote Rating: 7 | Quote Desc: informative\n",
      "| Time: 304.0 | Acc: 60 | Max Freq: 35.0 | Rate: 5 | Feedback: keep it the way it is | Quote Rating: 3 | Quote Desc: some where helpful tho most were not\n",
      "| Time: 1554.5 | Acc: 55 | Max Freq: 35.0 | Rate: 5 | Feedback: Maybe by providing a bit more informative passage quotes for some of them? | Quote Rating: 6 | Quote Desc: Some of them felt clueless.\n",
      "| Time: 413.3 | Acc: 65 | Max Freq: 30.0 | Rate: 7 | Feedback: Give a bit more detail about the passage. | Quote Rating: 6 | Quote Desc: Some of them made sense, and yet others made no sense in context with the question asked.\n",
      "| Time: 493.5 | Acc: 40 | Max Freq: 35.0 | Rate: 6 | Feedback: Some things was still tough to answer | Quote Rating: 8 | Quote Desc: Interesting\n",
      "| Time: 779.7 | Acc: 45 | Max Freq: 40.0 | Rate: 5 | Feedback: Add a little bit more context and avoid empty quotes. | Quote Rating: 4 | Quote Desc: Many lacked context and were ambiguous. Some made absolutely no sense at all. One was nothing but '<<>>'.\n",
      "| Time: 366.9 | Acc: 35 | Max Freq: 35.0 | Rate: 4 | Feedback: Make sure the quotes and answers somewhat make sense. | Quote Rating: 3 | Quote Desc: They barely make sense.\n",
      "| Time: 834.8 | Acc: 40 | Max Freq: 30.0 | Rate: 5 | Feedback: Im not sure | Quote Rating: 3 | Quote Desc: Confusing\n",
      "| Time: 268.6 | Acc: 50 | Max Freq: 30.0 | Rate: 10 | Feedback: It is great as it is | Quote Rating: 7 | Quote Desc: helpful\n",
      "| Time: 339.3 | Acc: 35 | Max Freq: 30.0 | Rate: 5 | Feedback: Make the questions and passages relate more clearly to each other. | Quote Rating: 3 | Quote Desc: Nonsensical\n",
      "| Time: 1201.9 | Acc: 50 | Max Freq: 45.0 | Rate: 10 | Feedback: i am not sure | Quote Rating: 1 | Quote Desc: The quotes were very off the wall, and made me think a bit more to consider which answer was most relevant.\n",
      "| Time: 388.1 | Acc: 35 | Max Freq: 30.0 | Rate: 9 | Feedback: I have no opinion. I think it was fun. | Quote Rating: 5 | Quote Desc: Some of them were fun.  Also, some of them were not very helpful.\n",
      "| Time: 315.9 | Acc: 60 | Max Freq: 40.0 | Rate: 7 | Feedback: n/a | Quote Rating: 4 | Quote Desc: some were helpful, most did not provide any clues for the answers\n",
      "| Time: 686.3 | Acc: 55 | Max Freq: 50.0 | Rate: 5 | Feedback: na | Quote Rating: 7 | Quote Desc: n/a\n",
      "| Time: 292.8 | Acc: 50 | Max Freq: 35.0 | Rate: 10 | Feedback: It seems good to me as is. | Quote Rating: 4 | Quote Desc: Usually unrelated or incomplete; occasionally helpful.\n",
      "| Time: 322.7 | Acc: 30 | Max Freq: 35.0 | Rate: 3 | Feedback: Not sure | Quote Rating: 2 | Quote Desc: A lot of them didn't make sense for what they were going with\n",
      "| Time: 540.3 | Acc: 65 | Max Freq: 40.0 | Rate: 5 | Feedback: By making passages more relevant to topic so that the questions are answered more correctly. | Quote Rating: 5 | Quote Desc: Every once in awhile they were relevant but for the most part they tended to be nonsensical.\n",
      "| Time: 445.5 | Acc: 55 | Max Freq: 40.0 | Rate: 7 | Feedback: let me see more of the passage | Quote Rating: 2 | Quote Desc: vague\n",
      "| Time: 590.8 | Acc: 65 | Max Freq: 50.0 | Rate: 7 | Feedback: it's good as is.  | Quote Rating: 7 | Quote Desc: They were sentences or groups of sentences taken out of context. \n",
      "| Time: 377.4 | Acc: 55 | Max Freq: 35.0 | Rate: 7 | Feedback: Make better context quotes | Quote Rating: 3 | Quote Desc: Some of them provided context clues for the questions, but a lot of them were no help at all. This required me to pretty much guess but I attempted to connect the two as much as possible. \n",
      "| Time: 767.6 | Acc: 30 | Max Freq: 30.0 | Rate: 6 | Feedback: Make the passages a little clearer. | Quote Rating: 6 | Quote Desc: Some were not related to the question.\n",
      "| Time: 520.7 | Acc: 45 | Max Freq: 35.0 | Rate: 7 | Feedback: It good as is. | Quote Rating: 7 | Quote Desc: intriguing\n",
      "| Time: 514.1 | Acc: 65 | Max Freq: 55.0 | Rate: 7 | Feedback: Provide slightly more information in the passages. | Quote Rating: 4 | Quote Desc: Some lacked any helpful information.\n",
      "| Time: 436.7 | Acc: 30 | Max Freq: 45.0 | Rate: 9 | Feedback: Remind people to read the instructions on the left first. | Quote Rating: 2 | Quote Desc: Random\n",
      "| Time: 687.2 | Acc: 60 | Max Freq: 45.0 | Rate: 7 | Feedback: Nothing comes to mind except to notify me when these tasks are available. | Quote Rating: 5 | Quote Desc: Inconsistent , sometimes helpful, sometimes irrelevant.\n",
      "| Time: 667.4 | Acc: 65 | Max Freq: 30.0 | Rate: 6 | Feedback: Make the clues/narrative reflect the information the question is asking | Quote Rating: 2 | Quote Desc: They didn't really give me any clues to what was being talked about most of the time, at least in the context of the answers.\n",
      "| Time: 322.2 | Acc: 50 | Max Freq: 35.0 | Rate: 6 | Feedback: More questions | Quote Rating: 4 | Quote Desc: Good but not great\n",
      "| Time: 644.7 | Acc: 25 | Max Freq: 35.0 | Rate: 5 | Feedback: NA | Quote Rating: 6 | Quote Desc: NA\n",
      "| Time: 342.9 | Acc: 55 | Max Freq: 50.0 | Rate: 8 | Feedback: You can't improve. | Quote Rating: 9 | Quote Desc: They seemed to fit the questions being asked.\n",
      "| Time: 407.6 | Acc: 70 | Max Freq: 50.0 | Rate: 4 | Feedback: Provide more pay and bonuses | Quote Rating: 4 | Quote Desc: Sometimes the quotes seemed unrelated to the multiple choice responses\n",
      "| Time: 410.2 | Acc: 50 | Max Freq: 40.0 | Rate: 9 | Feedback: make the passages more clear | Quote Rating: 7 | Quote Desc: Some were confusing \n",
      "| Time: 324.3 | Acc: 45 | Max Freq: 25.0 | Rate: 0 | Feedback: Just be better with quotes | Quote Rating: 3 | Quote Desc: Very vague and unhelpful\n",
      "| Time: 587.4 | Acc: 55 | Max Freq: 35.0 | Rate: 5 | Feedback: I'm not sure. | Quote Rating: 6 | Quote Desc: Some of them seemed unrelated to the question and I felt like I was guessing on those ones. Others made more sense or had enough context that I could answer more confidently.\n",
      "| Time: 300.0 | Acc: 55 | Max Freq: 30.0 | Rate: 6 | Feedback: I don't know. | Quote Rating: 6 | Quote Desc: confusing\n",
      "| Time: 535.2 | Acc: 60 | Max Freq: 30.0 | Rate: 10 | Feedback: Use more helpful quotes.  | Quote Rating: 4 | Quote Desc: Most were not helpful. \n",
      "| Time: 412.5 | Acc: 45 | Max Freq: 45.0 | Rate: 8 | Feedback: Pay a little more | Quote Rating: 7 | Quote Desc: Kind of interesting\n",
      "| Time: 616.8 | Acc: 30 | Max Freq: 40.0 | Rate: 5 | Feedback: More information | Quote Rating: 3 | Quote Desc: Weird and vague\n",
      "| Time: 942.9 | Acc: 55 | Max Freq: 30.0 | Rate: 3 | Feedback: it is vague which is higher rating when you ask scale of 0-10. | Quote Rating: 4 | Quote Desc: it is basically missing something.\n",
      "| Time: 923.6 | Acc: 65 | Max Freq: 30.0 | Rate: 5 | Feedback: The content was unrelated/couldn't be used for the answers in many of these questions.  | Quote Rating: 3 | Quote Desc: Quite a few had absolutely no context to help answer the questions.\n",
      "| Time: 433.3 | Acc: 40 | Max Freq: 45.0 | Rate: 9 | Feedback: Some questions, there was no reference about any of the answers | Quote Rating: 7 | Quote Desc: Interesting\n",
      "| Time: 490.4 | Acc: 50 | Max Freq: 40.0 | Rate: 10 | Feedback: n/a | Quote Rating: 6 | Quote Desc: brief and sometimes lacking clues\n",
      "| Time: 664.3 | Acc: 50 | Max Freq: 55.0 | Rate: 8 | Feedback: I think everything was great in trying to achieve the results of the study. | Quote Rating: 5 | Quote Desc: Some of the quotes were easy to understand what was being said in the whole passage. But, there were some quotes that I did not understand at all and I was petty much guessing about what the answer would be.\n",
      "| Time: 487.1 | Acc: 45 | Max Freq: 35.0 | Rate: 1 | Feedback: longer timer. | Quote Rating: 4 | Quote Desc: confusing\n",
      "| Time: 506.2 | Acc: 55 | Max Freq: 35.0 | Rate: 8 | Feedback: let us know how close to being done we are. | Quote Rating: 8 | Quote Desc: easy to read\n",
      "| Time: 552.5 | Acc: 30 | Max Freq: 40.0 | Rate: 7 | Feedback: I'm not sure what the goal of the task is, so I'm not sure if my suggestions would defeat the purpose. Obviously, the passages were too small to draw reliable connections from in many cases. | Quote Rating: 3 | Quote Desc: All across the board, conceptually. Sometimes straightforward to draw connections from, and other times a complete mystery.\n",
      "| Time: 253.7 | Acc: 60 | Max Freq: 30.0 | Rate: 10 | Feedback: Provide more helpful quotes. | Quote Rating: 4 | Quote Desc: Most of the quotes did not pertain to the questions, so I would describe them as irrelevant.\n",
      "| Time: 496.5 | Acc: 45 | Max Freq: 35.0 | Rate: 7 | Feedback: N/A | Quote Rating: 5 | Quote Desc: Semi useful\n",
      "| Time: 243.7 | Acc: 60 | Max Freq: 35.0 | Rate: 8 | Feedback: N/A | Quote Rating: 4 | Quote Desc: Sometimes they did not make sense in regards to the question. But, some were also interesting on their own.\n",
      "| Time: 609.8 | Acc: 35 | Max Freq: 30.0 | Rate: 8 | Feedback: It's good as is. Meant to be fun. | Quote Rating: 2 | Quote Desc: Mostly not pertaining to the question.\n",
      "| Time: 505.6 | Acc: 45 | Max Freq: 40.0 | Rate: 8 | Feedback: Maybe by explaining what the goal of the research is in a more elaborate way; with examples maybe. | Quote Rating: 6 | Quote Desc: Some were clearly related to the questions, others not at all. Some would seem totally random.\n",
      "| Time: 563.6 | Acc: 60 | Max Freq: 35.0 | Rate: 6 | Feedback: I enjoyed it the way it was | Quote Rating: 4 | Quote Desc: Vague, thought provoking \n",
      "| Time: 418.5 | Acc: 65 | Max Freq: 35.0 | Rate: 6 | Feedback: Make the quotes more applicable | Quote Rating: 2 | Quote Desc: Most of them seemed quite random\n",
      "| Time: 515.0 | Acc: 45 | Max Freq: 30.0 | Rate: 10 | Feedback: give a few more clues in the passages | Quote Rating: 8 | Quote Desc: Some were far fetched but it was a fun task.\n",
      "| Time: 531.1 | Acc: 35 | Max Freq: 35.0 | Rate: 3 | Feedback: not sure.  feed back while answering  the questions, rather than at the end. | Quote Rating: 5 | Quote Desc: interesting, and unrelated\n",
      "| Time: 644.8 | Acc: 40 | Max Freq: 30.0 | Rate: 9 | Feedback: I think it's well designed as is. | Quote Rating: 7 | Quote Desc: Some were intuitive. Others were difficult.\n",
      "| Time: 406.7 | Acc: 60 | Max Freq: 30.0 | Rate: 10 | Feedback: n/a | Quote Rating: 9 | Quote Desc: Most included useful information that was helpful in the questions or enough information to infer what the purpose of the passage was\n",
      "| Time: 463.5 | Acc: 70 | Max Freq: 40.0 | Rate: 7 | Feedback: Make the passages and quotes more cohesive.  | Quote Rating: 2 | Quote Desc: Most of the times, they were irrelevant in guessing the quotes.\n",
      "| Time: 611.2 | Acc: 60 | Max Freq: 35.0 | Rate: 8 | Feedback: Use related passages that answer the questions \"Within\" them, like your example questions. | Quote Rating: 4 | Quote Desc: Unrelated half of the time. Guesswork\n",
      "| Time: 518.9 | Acc: 30 | Max Freq: 30.0 | Rate: 6 | Feedback: the passage quotes could provide more hints | Quote Rating: 4 | Quote Desc: Irrelevant\n",
      "| Time: 556.1 | Acc: 65 | Max Freq: 35.0 | Rate: 10 | Feedback: It's your study so I don't know. I feel like i should have done better than 65 percent. | Quote Rating: 7 | Quote Desc: I did not think they would be that challenging. I loved the critical thinking hit, and would love to do more.\n",
      "| Time: 536.2 | Acc: 50 | Max Freq: 35.0 | Rate: 1 | Feedback: Review the passages and provide more information and more likely responses. Also, check spelling. | Quote Rating: 1 | Quote Desc: The were poorly worded and were missing information. Also, they had many misspellings. \n",
      "| Time: 335.3 | Acc: 45 | Max Freq: 35.0 | Rate: 7 | Feedback: have better passages | Quote Rating: 3 | Quote Desc: the passages where unclear\n",
      "| Time: 461.6 | Acc: 45 | Max Freq: 45.0 | Rate: 3 | Feedback: Some of those questions were impossible and completely unrelated, there is no way you could relate some of the answers to the question. | Quote Rating: 3 | Quote Desc: Nonsensical\n",
      "| Time: 392.0 | Acc: 40 | Max Freq: 40.0 | Rate: 10 | Feedback: I LIKED IT | Quote Rating: 8 | Quote Desc: SOME WERE EASY TO  UNDERSTAND AND SOME WERE DIFFICULT\n",
      "| Time: 1746.0 | Acc: 40 | Max Freq: 40.0 | Rate: 6 | Feedback: i think the task is fine | Quote Rating: 3 | Quote Desc: Some of them were useful while others seemed completely out of place\n",
      "| Time: 501.2 | Acc: 25 | Max Freq: 35.0 | Rate: 9 | Feedback: No comments.  | Quote Rating: 4 | Quote Desc: plain, simple \n",
      "| Time: 557.4 | Acc: 30 | Max Freq: 30.0 | Rate: 8 | Feedback: Not sure what your goal is, it was interesting and fun however. | Quote Rating: 3 | Quote Desc: Rather vague and a bit confusing.\n",
      "| Time: 415.2 | Acc: 45 | Max Freq: 30.0 | Rate: 5 | Feedback: don't know | Quote Rating: 3 | Quote Desc: don't know\n",
      "| Time: 470.4 | Acc: 55 | Max Freq: 35.0 | Rate: 6 | Feedback: Some answers seem really out of place. | Quote Rating: 4 | Quote Desc: Short phrases \n",
      "| Time: 363.5 | Acc: 55 | Max Freq: 30.0 | Rate: 9 | Feedback: all good | Quote Rating: 3 | Quote Desc: some good and some way out there\n",
      "| Time: 262.5 | Acc: 45 | Max Freq: 35.0 | Rate: 9 | Feedback: I think it is fine. | Quote Rating: 7 | Quote Desc: Somewhat helpful to answering the questions.\n",
      "| Time: 855.6 | Acc: 40 | Max Freq: 35.0 | Rate: 10 | Feedback: Better passages | Quote Rating: 5 | Quote Desc: About 50/50 between helpful and completely off topic \n",
      "| Time: 392.6 | Acc: 80 | Max Freq: 45.0 | Rate: 10 | Feedback: Provide better quotes | Quote Rating: 6 | Quote Desc: Some were useful, but many were very short and vague\n",
      "| Time: 424.7 | Acc: 30 | Max Freq: 35.0 | Rate: 7 | Feedback: Include passages that are more relevant to the questions. | Quote Rating: 4 | Quote Desc: I would describe most of them as being irrelevant to answering the question and some were bizarre.\n",
      "| Time: 764.8 | Acc: 50 | Max Freq: 50.0 | Rate: 8 | Feedback: Maybe have passage quotes that are little more related to the question. | Quote Rating: 7 | Quote Desc: Most of them were very loosely related but a couple were very straightforward and helpful.\n",
      "| Time: 428.0 | Acc: 55 | Max Freq: 40.0 | Rate: 6 | Feedback: It's pretty good.  | Quote Rating: 4 | Quote Desc: They were all pretty short and vague. \n",
      "| Time: 373.1 | Acc: 40 | Max Freq: 40.0 | Rate: 2 | Feedback: Not make it so random where there is no cleat answer | Quote Rating: 4 | Quote Desc: So were so random there was no way of guessing the answer confidently\n",
      "| Time: 556.2 | Acc: 50 | Max Freq: 45.0 | Rate: 6 | Feedback: Task was good | Quote Rating: 7 | Quote Desc: Some did not make sense but others were spot on. \n",
      "| Time: 417.2 | Acc: 45 | Max Freq: 35.0 | Rate: 5 | Feedback: I DON'T KNOW | Quote Rating: 5 | Quote Desc: SOME WERE VERY HELPFUL, A COUPLE MADE NO SENSE TO THE HELP ANSWER THE QUESTION\n",
      "| Time: 281.3 | Acc: 40 | Max Freq: 30.0 | Rate: 0 | Feedback: Idk | Quote Rating: 3 | Quote Desc: Confusing\n",
      "| Time: 374.2 | Acc: 45 | Max Freq: 30.0 | Rate: 8 | Feedback: depending on what the purpose of the task is, having more information would have been better. | Quote Rating: 6 | Quote Desc: Vague or lacking information, necessary information.\n",
      "| Time: 373.7 | Acc: 35 | Max Freq: 35.0 | Rate: 5 | Feedback: Nothing | Quote Rating: 6 | Quote Desc: Skimpy\n",
      "| Time: 378.4 | Acc: 50 | Max Freq: 30.0 | Rate: 7 | Feedback: I would say making the choices more relevant however Im assuming that is part of the whole point of this assignment. | Quote Rating: 4 | Quote Desc: Some of the quotes seemed relevant to the multiple choice answers provided while others seemed utterly irrelevant.  However, i answered as best as i could since that was the instructions given to me.  Thanks for the interesting HIT.\n",
      "| Time: 460.2 | Acc: 55 | Max Freq: 30.0 | Rate: 10 | Feedback: Looks good to me. | Quote Rating: 7 | Quote Desc: They descibed a part of the situation that was to be used to selecting the answer.\n",
      "| Time: 330.1 | Acc: 30 | Max Freq: 30.0 | Rate: 5 | Feedback: More relevant quotes.  | Quote Rating: 2 | Quote Desc: Confusing, most of the time.\n",
      "| Time: 350.9 | Acc: 45 | Max Freq: 35.0 | Rate: 7 | Feedback: I really don't know | Quote Rating: 7 | Quote Desc: Sometimes relevant and sometimes not\n",
      "| Time: 566.1 | Acc: 60 | Max Freq: 30.0 | Rate: 9 | Feedback: Give better answers on some of the questions | Quote Rating: 7 | Quote Desc: Some didn't make sense and some did\n",
      "| Time: 771.4 | Acc: 40 | Max Freq: 35.0 | Rate: 10 | Feedback: More information in the statements. | Quote Rating: 5 | Quote Desc: A little difficult to understand what was wanted from the information given at times.\n",
      "| Time: 491.2 | Acc: 50 | Max Freq: 35.0 | Rate: 10 | Feedback: I think it is fine the way it is | Quote Rating: 2 | Quote Desc: Pretty irrelevant to the questions\n",
      "REJECTED: 0\n",
      "INCOMPLETE: 3\n",
      "VALID: 112\n",
      "Median Question Duration: 20.017\n",
      "Mean Question Duration: 22.158332589285717\n",
      "Min/Median/Mean/Max Worker Duration: 4.05 / 7.85 / 8.77 / 29.1\n",
      "Min/Median/Mean/Max Good Worker Durations: 4.05 / 7.84 / 8.75 / 25.91\n",
      "Median Worker Accuracy: 0.5\n",
      "Median Max Response Freq: 0.35\n",
      "Quote Rating: | Mean: 4.68 | Median: 4.0 | Std: 2.02\n"
     ]
    }
   ],
   "source": [
    "num_valid_hits, num_rejected_hits, num_incomplete_hits = 0, 0, 0\n",
    "metrics = {}\n",
    "task_ratings = {i: 0 for i in range(11)}\n",
    "quote_ratings = []\n",
    "durations = []\n",
    "worker_durations = []\n",
    "accuracy_by_worker = {}\n",
    "max_response_freqs = []\n",
    "worker_ids = []\n",
    "hits_by_qid = {}\n",
    "\n",
    "for hit_result in hit_results:\n",
    "    if ((len(hit_result['reject_reasons']) > 0) or\n",
    "        (len(hit_result['block_reasons']) > 0)):\n",
    "        num_rejected_hits += 1\n",
    "        print(hit_result['worker_id'], hit_result['assignment_id'],\n",
    "              '| reject_reasons:', hit_result['reject_reasons'],\n",
    "              '| block_reasons:', hit_result['block_reasons'],\n",
    "              '| bonus_reasons: ' + str(hit_result['bonus_reasons']) if 'bonus_reasons' in hit_result else '')\n",
    "    elif hit_result['feedback'] is None:\n",
    "        num_incomplete_hits += 1\n",
    "        continue\n",
    "    \n",
    "    worker_ids.append(hit_result['worker_id'])\n",
    "    num_valid_hits += 1\n",
    "    if (hit_result['task_rating'] is not None) and (hit_result['task_rating'].isdigit()):\n",
    "        task_ratings[int(hit_result['task_rating'])] += 1\n",
    "    if (hit_result.get('quote_rating') is not None) and (hit_result['quote_rating'].isdigit()):\n",
    "        quote_ratings.append(int(hit_result['quote_rating']))\n",
    "    for qtype, qtype_accuracy in hit_result['accuracy'].items():\n",
    "        accuracy_by_worker[qtype] = accuracy_by_worker.get(qtype, []) + [qtype_accuracy]\n",
    "    \n",
    "    hit_durations = []\n",
    "    response_option_counts = {option: 0 for option in options}\n",
    "    responses = []\n",
    "    for prompt in hit_result['data']:\n",
    "        qid = prompt['sample']['qid']\n",
    "        if (split is not None) and (split not in qid):\n",
    "            continue\n",
    "        hits_by_qid[qid] = hits_by_qid.get(qid, [])\n",
    "        hits_by_qid[qid].append(prompt)\n",
    "        model_stance = debate_mode_to_option[prompt['sample']['debate_mode']]\n",
    "        answer = prompt['sample']['eval_labels'][0]\n",
    "        human_correct = (prompt['response'] == answer)\n",
    "        assert answer in options, 'Answer must be in options.'\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if qid not in metrics:\n",
    "            metrics[qid] = {\n",
    "                option: {\n",
    "                    'num': 0,\n",
    "                    'num_correct': 0,\n",
    "                    'num_correct_debate_mode': 0,\n",
    "                    'num_incorrect_debate_mode': 0,\n",
    "                    'num_correct_with_correct_debate_mode': 0,\n",
    "                    'num_correct_with_incorrect_debate_mode': 0,\n",
    "                    'num_debate_mode_responses': 0,\n",
    "                    'is_debate_mode_response': []\n",
    "                }\n",
    "                for option in ([None] if model_stance is None else options)\n",
    "            }\n",
    "            for qtype in question_type_labels:\n",
    "                metrics[qid][qtype] = {\n",
    "                    'num': 0,\n",
    "                    'num_correct': 0,\n",
    "                }\n",
    "            metrics[qid]['answer'] = answer\n",
    "        for qtype in set(''.join(prompt['sample'].get('question_type_labels', []))):\n",
    "            qtype = qtype.lower()\n",
    "            metrics[qid][qtype]['num'] += 1\n",
    "            metrics[qid][qtype]['num_correct'] += human_correct\n",
    "        prompt_metrics = metrics[qid][model_stance]\n",
    "        prompt_metrics['num'] += 1\n",
    "        prompt_metrics['num_correct'] += human_correct\n",
    "        if model_stance == answer:\n",
    "            prompt_metrics['num_correct_with_correct_debate_mode'] += human_correct\n",
    "            prompt_metrics['num_correct_debate_mode'] += 1\n",
    "        else:\n",
    "            prompt_metrics['num_correct_with_incorrect_debate_mode'] += human_correct\n",
    "            prompt_metrics['num_incorrect_debate_mode'] += 1\n",
    "        prompt_metrics['num_debate_mode_responses'] += (prompt['response'] == model_stance)\n",
    "        prompt_metrics['is_debate_mode_response'].append(prompt['response'] == model_stance)\n",
    "        \n",
    "        hit_durations.append(prompt['duration'] / 1000.)\n",
    "        response_option_counts[prompt['response']] += 1\n",
    "        responses.append(prompt['response'])\n",
    "    duration = np.sum(np.array(hit_durations))\n",
    "    worker_durations.append(duration)\n",
    "    durations += hit_durations\n",
    "    response_options_array = np.array(list(response_option_counts.values()))\n",
    "    response_options_array = response_options_array / response_options_array.sum()\n",
    "    max_response_freq = response_options_array.max()\n",
    "    max_response_freqs.append(max_response_freq)\n",
    "    acc = round(100 * hit_result['accuracy'][prompt_type])\n",
    "    print('| Time:', round(duration, 1),\n",
    "          '| Acc:', acc,\n",
    "          '| Max Freq:', round(100 * max_response_freq, 1),\n",
    "          '| Rate:', hit_result['task_rating'],\n",
    "          '| Feedback:', hit_result['feedback'],\n",
    "          '| Quote Rating:', None if 'quote_rating' not in hit_result else hit_result['quote_rating'], \n",
    "          '| Quote Desc:', None if 'quote_description' not in hit_result else hit_result['quote_description'])\n",
    "\n",
    "good_worker_durations = []\n",
    "assert len(worker_durations) == len(accuracy_by_worker[prompt_type])\n",
    "for worker_duration, worker_accuracy in zip(worker_durations, accuracy_by_worker[prompt_type]):\n",
    "    if worker_accuracy > np.median(np.array(accuracy_by_worker[prompt_type])):\n",
    "        good_worker_durations.append(worker_duration)\n",
    "\n",
    "quote_ratings = np.array(quote_ratings)\n",
    "durations = np.array(durations)\n",
    "worker_durations = np.array(worker_durations)\n",
    "good_worker_durations = np.array(good_worker_durations)\n",
    "max_response_freqs = np.array(max_response_freqs)\n",
    "\n",
    "quote_ratings.sort()\n",
    "durations.sort()\n",
    "worker_durations.sort()\n",
    "good_worker_durations.sort()\n",
    "max_response_freqs.sort()\n",
    "\n",
    "for qtype in accuracy_by_worker:\n",
    "    accuracy_by_worker[qtype] = np.array(accuracy_by_worker[qtype])\n",
    "    accuracy_by_worker[qtype].sort()\n",
    "print('REJECTED:', num_rejected_hits)\n",
    "print('INCOMPLETE:', num_incomplete_hits)\n",
    "print('VALID:', num_valid_hits)\n",
    "print('Median Question Duration:', np.median(durations))\n",
    "print('Mean Question Duration:', np.mean(durations[int(durations.shape[0] / 10.):int(9. * durations.shape[0] / 10.)]))\n",
    "print('Min/Median/Mean/Max Worker Duration:',\n",
    "      round(np.min(worker_durations / 60.), 2), '/',\n",
    "      round(np.median(worker_durations / 60.), 2), '/',\n",
    "      round(np.mean(worker_durations / 60.), 2), '/',\n",
    "      round(np.max(worker_durations / 60.), 2))\n",
    "print('Min/Median/Mean/Max Good Worker Durations:',\n",
    "      round(np.min(good_worker_durations / 60.), 2), '/',\n",
    "      round(np.median(good_worker_durations / 60.), 2),'/',\n",
    "      round(np.mean(good_worker_durations / 60.), 2), '/',\n",
    "      round(np.max(good_worker_durations / 60.), 2))\n",
    "print('Median Worker Accuracy:', np.median(accuracy_by_worker[prompt_type]))\n",
    "print('Median Max Response Freq:', np.median(max_response_freqs))\n",
    "print('Quote Rating:',\n",
    "      '| Mean:', round(quote_ratings.mean(), 2),\n",
    "      '| Median:', round(np.median(quote_ratings), 2),\n",
    "      '| Std:', round(np.std(quote_ratings), 2))\n",
    "# pprint(hit_results[0]['data'][0])\n",
    "# pprint(hit_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evals per sample: 5.6\n",
      "Fraction insuffient evals: 0.0\n",
      "Convinced: 26.13 %\n",
      "- Correct debater: 49.71 %\n",
      "- Incorrect debater: 18.27 %\n",
      "Accuracy: 49.29 %\n",
      "- Correct debater: 49.71 %\n",
      "- Incorrect debater: 49.15 %\n",
      "Extra Evals: 10.71 %\n",
      "Evals per sample distribution: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "Accuracy/Num-Samples by Q Type:\n",
      "{'a': (0.44915674603174605, 24),\n",
      " 'b': (0.5259300595238094, 32),\n",
      " 'c': (0.5125, 54),\n",
      " 'd': (0.5230682839173406, 53),\n",
      " 'e': (0.45669642857142856, 16)}\n"
     ]
    }
   ],
   "source": [
    "accuracy_by_qtype = {qtype: [] for qtype in question_type_labels}\n",
    "accuracy_by_sample = []\n",
    "accuracy_by_sample_correct_debate_mode = []\n",
    "accuracy_by_sample_incorrect_debate_mode = []\n",
    "convinced_freqs = []\n",
    "convinced_freqs_with_correct_debate_mode = []\n",
    "convinced_freqs_with_incorrect_debate_mode = []\n",
    "num_evals_by_sample = []\n",
    "convinced_by_sample = []\n",
    "for qid, qid_metrics in metrics.items():\n",
    "    answer = metrics[qid]['answer']\n",
    "    for qid_metric_key, prompt in qid_metrics.items():\n",
    "        if qid_metric_key in question_type_labels:\n",
    "            qtype = qid_metric_key\n",
    "            if qid_metrics[qtype]['num'] > 0:\n",
    "                accuracy_by_qtype[qtype].append(qid_metrics[qtype]['num_correct'] / qid_metrics[qtype]['num'])\n",
    "            continue\n",
    "        if not (qid_metric_key in [None] + options):\n",
    "            continue\n",
    "        model_stance = qid_metric_key\n",
    "\n",
    "        # Q-only stats\n",
    "        prompt_metrics = metrics[qid][model_stance]\n",
    "        num_evals_by_sample.append(prompt_metrics['num'])\n",
    "        convinced_by_sample.append(prompt_metrics['is_debate_mode_response'])\n",
    "        accuracy_by_sample.append(prompt_metrics['num_correct'] / prompt_metrics['num'])\n",
    "        if model_stance is None:\n",
    "            continue\n",
    "        \n",
    "        # Debater stats\n",
    "#         if 'num_debate_mode_responses' not in prompt_metrics:\n",
    "#             print(qid_metric_key, prompt_metrics)\n",
    "        convinced_freq = prompt_metrics['num_debate_mode_responses'] / prompt_metrics['num']\n",
    "        if model_stance == answer:\n",
    "            convinced_freqs_with_correct_debate_mode.append(convinced_freq)\n",
    "            accuracy_by_sample_correct_debate_mode.append(\n",
    "                prompt_metrics['num_correct_with_correct_debate_mode'] /\n",
    "                prompt_metrics['num_correct_debate_mode'])\n",
    "        else:\n",
    "            convinced_freqs_with_incorrect_debate_mode.append(convinced_freq)\n",
    "            accuracy_by_sample_incorrect_debate_mode.append(\n",
    "                prompt_metrics['num_correct_with_incorrect_debate_mode'] /\n",
    "                prompt_metrics['num_incorrect_debate_mode'])\n",
    "        convinced_freqs.append(convinced_freq)\n",
    "\n",
    "accuracy_by_qtype = {qtype: (np.array(accuracy_by_qtype[qtype]).mean(), len(accuracy_by_qtype[qtype])) for qtype in question_type_labels}\n",
    "worker_ids = set(worker_ids)\n",
    "        \n",
    "num_evals_by_sample = np.array(num_evals_by_sample)\n",
    "print('Evals per sample:', num_evals_by_sample.mean())\n",
    "print('Fraction insuffient evals:', (num_evals_by_sample < 5).mean())\n",
    "\n",
    "convinced_freqs = np.array(convinced_freqs)\n",
    "print('Convinced:', round(100 * convinced_freqs.mean(), 2), '%')\n",
    "convinced_freqs_with_correct_debate_mode = np.array(convinced_freqs_with_correct_debate_mode)\n",
    "print('- Correct debater:', round(100 * convinced_freqs_with_correct_debate_mode.mean(), 2), '%')\n",
    "convinced_freqs_with_incorrect_debate_mode = np.array(convinced_freqs_with_incorrect_debate_mode)\n",
    "print('- Incorrect debater:', round(100 * convinced_freqs_with_incorrect_debate_mode.mean(), 2), '%')\n",
    "\n",
    "accuracy_by_sample = np.array(accuracy_by_sample)\n",
    "print('Accuracy:', round(100 * accuracy_by_sample.mean(), 2), '%')\n",
    "accuracy_by_sample_correct_debate_mode = np.array(accuracy_by_sample_correct_debate_mode)\n",
    "print('- Correct debater:', round(100 * accuracy_by_sample_correct_debate_mode.mean(), 2), '%')\n",
    "accuracy_by_sample_incorrect_debate_mode = np.array(accuracy_by_sample_incorrect_debate_mode)\n",
    "print('- Incorrect debater:', round(100 * accuracy_by_sample_incorrect_debate_mode.mean(), 2), '%')\n",
    "\n",
    "num_target_evals = 5\n",
    "print('Extra Evals:', round(((100. * (num_evals_by_sample - num_target_evals).sum()) / num_evals_by_sample.sum()), 2), '%')\n",
    "num_evals_by_sample.sort()\n",
    "print('Evals per sample distribution:', num_evals_by_sample)\n",
    "\n",
    "print('Accuracy/Num-Samples by Q Type:')\n",
    "pprint(accuracy_by_qtype)\n",
    "# 1.5*3.1*60/(917.5684545454544*26/(20*60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPS, Mean: (-8.04, 6.94)\n"
     ]
    }
   ],
   "source": [
    "def nps(task_ratings):\n",
    "    num_ratings = sum(list(task_ratings.values()))\n",
    "    if num_ratings == 0:\n",
    "        return None\n",
    "\n",
    "    nps_sum_ratings = 0\n",
    "    sum_ratings = 0\n",
    "    for score, num_raters in task_ratings.items():\n",
    "        sum_ratings += num_raters * score\n",
    "        if score >= 9:\n",
    "            nps_sum_ratings += num_raters\n",
    "        elif score <= 6:\n",
    "            nps_sum_ratings -= num_raters\n",
    "    return round(100 * (nps_sum_ratings / float(num_ratings)), 2), round((sum_ratings / float(num_ratings)), 2)\n",
    "\n",
    "print('NPS, Mean:', nps(task_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bi-Ranker': array([25.  , 26.  , 26.  , 25.25, 29.75]),\n",
      " 'BoW-A': array([36.75, 35.75, 38.  , 36.5 , 36.25]),\n",
      " 'Cross-Ranker': array([41.25, 39.25, 36.5 , 36.  , 39.  ]),\n",
      " 'Pred P(A)': array([41.25, 41.25, 44.25, 42.25, 40.25]),\n",
      " 'Pred Search': array([37.5 , 40.5 , 40.75, 39.75, 41.5 ]),\n",
      " 'Pred ΔP(A)': array([38.75, 41.5 , 41.  , 42.5 , 42.5 ]),\n",
      " 'TFIDF-A': array([37.75, 39.75, 36.75, 38.5 , 37.25]),\n",
      " 'TFIDF-QA': array([33.75, 33.5 , 31.  , 34.5 , 34.  ])}\n"
     ]
    }
   ],
   "source": [
    "evals[name] = []\n",
    "for eval_no in range(num_evals):\n",
    "    evals[name].append([convinced_array[eval_no] for convinced_array in convinced_by_sample])\n",
    "\n",
    "evals[name] = 100. * np.array(evals[name]).mean(axis=1)\n",
    "pprint(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** TFIDF-QA *****\n",
      "MEAN: 33.4\n",
      "STD: 1.22\n",
      "STDERR: 0.55\n",
      "\n",
      "***** TFIDF-A *****\n",
      "MEAN: 38.0\n",
      "STD: 1.05\n",
      "STDERR: 0.47\n",
      "\n",
      "***** BoW-A *****\n",
      "MEAN: 36.6\n",
      "STD: 0.75\n",
      "STDERR: 0.34\n",
      "\n",
      "***** Cross-Ranker *****\n",
      "MEAN: 38.4\n",
      "STD: 1.93\n",
      "STDERR: 0.86\n",
      "\n",
      "***** Pred Search *****\n",
      "MEAN: 40.0\n",
      "STD: 1.37\n",
      "STDERR: 0.61\n",
      "\n",
      "***** Pred P(A) *****\n",
      "MEAN: 41.8\n",
      "STD: 1.36\n",
      "STDERR: 0.61\n",
      "\n",
      "***** Pred ΔP(A) *****\n",
      "MEAN: 41.2\n",
      "STD: 1.38\n",
      "STDERR: 0.62\n",
      "\n",
      "***** Bi-Ranker *****\n",
      "MEAN: 26.4\n",
      "STD: 1.72\n",
      "STDERR: 0.77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n, eval_values in evals.items():\n",
    "    print('*****', n, '*****')\n",
    "    print('MEAN:', round(eval_values.mean(), 1))\n",
    "    print('STD:', round(eval_values.std(), 2))\n",
    "    print('STDERR:', round(eval_values.std() / np.sqrt(eval_values.shape[0]), 2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF-QA / TFIDF-QA : 1.0\n",
      "TFIDF-QA / TFIDF-A : 0.0005\n",
      "TFIDF-QA / BoW-A : 0.0028\n",
      "TFIDF-QA / Cross-Ranker : 0.0033\n",
      "TFIDF-QA / Pred Search : 0.0001\n",
      "TFIDF-QA / Pred P(A) : 0.0\n",
      "TFIDF-QA / Pred ΔP(A) : 0.0\n",
      "TFIDF-QA / Bi-Ranker : 0.0003\n",
      "TFIDF-A / TFIDF-QA : 0.0005\n",
      "TFIDF-A / TFIDF-A : 1.0\n",
      "TFIDF-A / BoW-A : 0.0733\n",
      "TFIDF-A / Cross-Ranker : 0.7276\n",
      "TFIDF-A / Pred Search : 0.0511\n",
      "TFIDF-A / Pred P(A) : 0.0024\n",
      "TFIDF-A / Pred ΔP(A) : 0.0063\n",
      "TFIDF-A / Bi-Ranker : 0.0\n",
      "BoW-A / TFIDF-QA : 0.0028\n",
      "BoW-A / TFIDF-A : 0.0733\n",
      "BoW-A / BoW-A : 1.0\n",
      "BoW-A / Cross-Ranker : 0.1493\n",
      "BoW-A / Pred Search : 0.0048\n",
      "BoW-A / Pred P(A) : 0.0005\n",
      "BoW-A / Pred ΔP(A) : 0.001\n",
      "BoW-A / Bi-Ranker : 0.0001\n",
      "Cross-Ranker / TFIDF-QA : 0.0033\n",
      "Cross-Ranker / TFIDF-A : 0.7276\n",
      "Cross-Ranker / BoW-A : 0.1493\n",
      "Cross-Ranker / Cross-Ranker : 1.0\n",
      "Cross-Ranker / Pred Search : 0.2168\n",
      "Cross-Ranker / Pred P(A) : 0.0215\n",
      "Cross-Ranker / Pred ΔP(A) : 0.0459\n",
      "Cross-Ranker / Bi-Ranker : 0.0\n",
      "Pred Search / TFIDF-QA : 0.0001\n",
      "Pred Search / TFIDF-A : 0.0511\n",
      "Pred Search / BoW-A : 0.0048\n",
      "Pred Search / Cross-Ranker : 0.2168\n",
      "Pred Search / Pred Search : 1.0\n",
      "Pred Search / Pred P(A) : 0.0912\n",
      "Pred Search / Pred ΔP(A) : 0.2342\n",
      "Pred Search / Bi-Ranker : 0.0\n",
      "Pred P(A) / TFIDF-QA : 0.0\n",
      "Pred P(A) / TFIDF-A : 0.0024\n",
      "Pred P(A) / BoW-A : 0.0005\n",
      "Pred P(A) / Cross-Ranker : 0.0215\n",
      "Pred P(A) / Pred Search : 0.0912\n",
      "Pred P(A) / Pred P(A) : 1.0\n",
      "Pred P(A) / Pred ΔP(A) : 0.5522\n",
      "Pred P(A) / Bi-Ranker : 0.0\n",
      "Pred ΔP(A) / TFIDF-QA : 0.0\n",
      "Pred ΔP(A) / TFIDF-A : 0.0063\n",
      "Pred ΔP(A) / BoW-A : 0.001\n",
      "Pred ΔP(A) / Cross-Ranker : 0.0459\n",
      "Pred ΔP(A) / Pred Search : 0.2342\n",
      "Pred ΔP(A) / Pred P(A) : 0.5522\n",
      "Pred ΔP(A) / Pred ΔP(A) : 1.0\n",
      "Pred ΔP(A) / Bi-Ranker : 0.0\n",
      "Bi-Ranker / TFIDF-QA : 0.0003\n",
      "Bi-Ranker / TFIDF-A : 0.0\n",
      "Bi-Ranker / BoW-A : 0.0001\n",
      "Bi-Ranker / Cross-Ranker : 0.0\n",
      "Bi-Ranker / Pred Search : 0.0\n",
      "Bi-Ranker / Pred P(A) : 0.0\n",
      "Bi-Ranker / Pred ΔP(A) : 0.0\n",
      "Bi-Ranker / Bi-Ranker : 1.0\n"
     ]
    }
   ],
   "source": [
    "for n1, eval_values1 in evals.items():\n",
    "    for n2, eval_values2 in evals.items():\n",
    "        print(n1, '/', n2, ':', round(ttest_ind(eval_values1, eval_values2, equal_var=False)[1], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
